{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import ast\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.impute import SimpleImputer\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn as nn\n",
    "import keras.backend as K\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import GRU, Dense, Input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Merge Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Datasets\n",
    "\n",
    "# Training datasets\n",
    "cgm_train = pd.read_csv('cgm_train.csv')\n",
    "image_train = pd.read_csv('img_train.csv')\n",
    "demo_viome_train = pd.read_csv('demo_viome_train.csv')\n",
    "label_train = pd.read_csv('label_train.csv')\n",
    "\n",
    "# Test datasets\n",
    "cgm_test = pd.read_csv('cgm_test.csv')\n",
    "image_test = pd.read_csv('img_test.csv')\n",
    "demo_viome_test = pd.read_csv('demo_viome_test.csv')\n",
    "label_test = pd.read_csv('label_test_breakfast_only.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge CGM and Image datasets\n",
    "data_train = pd.merge(image_train, cgm_train, on=['Subject ID', 'Day'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject ID</th>\n",
       "      <th>Day</th>\n",
       "      <th>Image Before Breakfast</th>\n",
       "      <th>Image Before Lunch</th>\n",
       "      <th>Breakfast Time</th>\n",
       "      <th>Lunch Time</th>\n",
       "      <th>CGM Data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[[[140, 122, 108], [135, 118, 104], [118, 104,...</td>\n",
       "      <td>[[[41, 152, 201], [77, 164, 205], [88, 157, 13...</td>\n",
       "      <td>2021-09-19 08:41:00</td>\n",
       "      <td>2021-09-19 12:24:00</td>\n",
       "      <td>[('2021-09-19 08:20:00', 98.26666666666667), (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>[[[67, 58, 47], [59, 52, 41], [51, 45, 35], [4...</td>\n",
       "      <td>[[[40, 59, 77], [35, 56, 72], [20, 36, 47], [9...</td>\n",
       "      <td>2021-09-20 09:50:00</td>\n",
       "      <td>2021-09-20 15:20:00</td>\n",
       "      <td>[('2021-09-20 09:10:00', 97.18333333333334), (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>[[[199, 195, 193], [198, 193, 192], [196, 192,...</td>\n",
       "      <td>[[[53, 44, 38], [51, 43, 36], [54, 47, 39], [4...</td>\n",
       "      <td>2021-09-21 09:34:00</td>\n",
       "      <td>2021-09-21 13:09:00</td>\n",
       "      <td>[('2021-09-21 09:20:00', 107.36666666666666), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>[[[149, 121, 80], [157, 128, 86], [159, 130, 8...</td>\n",
       "      <td>[[[30, 28, 28], [20, 18, 17], [31, 27, 23], [2...</td>\n",
       "      <td>2021-09-22 09:46:00</td>\n",
       "      <td>2021-09-22 13:50:00</td>\n",
       "      <td>[('2021-09-22 09:25:00', 107.28333333333333), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>[[[175, 184, 198], [192, 206, 219], [160, 165,...</td>\n",
       "      <td>[[[74, 85, 100], [59, 69, 81], [73, 84, 96], [...</td>\n",
       "      <td>2021-09-23 09:07:00</td>\n",
       "      <td>2021-09-23 13:17:00</td>\n",
       "      <td>[('2021-09-23 08:55:00', 103.0), ('2021-09-23 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>[[[68, 34, 35], [82, 60, 51], [63, 55, 38], [3...</td>\n",
       "      <td>[[[90, 77, 75], [92, 78, 75], [94, 83, 81], [9...</td>\n",
       "      <td>2021-12-18 08:52:00</td>\n",
       "      <td>2021-12-18 12:28:00</td>\n",
       "      <td>[('2021-12-18 08:50:00', 101.36), ('2021-12-18...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>[[[26, 26, 22], [17, 17, 13], [18, 19, 14], [9...</td>\n",
       "      <td>[[[17, 9, 8], [10, 7, 7], [3, 3, 4], [3, 3, 3]...</td>\n",
       "      <td>2021-12-19 08:43:00</td>\n",
       "      <td>2021-12-19 13:13:00</td>\n",
       "      <td>[('2021-12-19 08:40:00', 100.68), ('2021-12-19...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>[[[43, 37, 33], [42, 36, 31], [42, 37, 33], [4...</td>\n",
       "      <td>[[[122, 108, 107], [124, 110, 108], [124, 111,...</td>\n",
       "      <td>2021-12-20 09:06:00</td>\n",
       "      <td>2021-12-20 12:46:00</td>\n",
       "      <td>[('2021-12-20 09:00:00', 104.04), ('2021-12-20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>[[[41, 38, 33], [41, 38, 33], [41, 38, 33], [4...</td>\n",
       "      <td>[[[59, 46, 32], [63, 51, 41], [57, 42, 28], [6...</td>\n",
       "      <td>2021-12-21 08:34:00</td>\n",
       "      <td>2021-12-21 12:38:00</td>\n",
       "      <td>[('2021-12-21 08:25:00', 96.4), ('2021-12-21 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>[[[115, 90, 85], [115, 90, 86], [111, 86, 82],...</td>\n",
       "      <td>[[[66, 53, 44], [77, 67, 62], [70, 57, 48], [6...</td>\n",
       "      <td>2021-12-22 08:44:00</td>\n",
       "      <td>2021-12-22 12:34:00</td>\n",
       "      <td>[('2021-12-22 08:35:00', 96.68), ('2021-12-22 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>324 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Subject ID  Day                             Image Before Breakfast  \\\n",
       "0             1    2  [[[140, 122, 108], [135, 118, 104], [118, 104,...   \n",
       "1             1    3  [[[67, 58, 47], [59, 52, 41], [51, 45, 35], [4...   \n",
       "2             1    4  [[[199, 195, 193], [198, 193, 192], [196, 192,...   \n",
       "3             1    5  [[[149, 121, 80], [157, 128, 86], [159, 130, 8...   \n",
       "4             1    6  [[[175, 184, 198], [192, 206, 219], [160, 165,...   \n",
       "..          ...  ...                                                ...   \n",
       "319           7    6  [[[68, 34, 35], [82, 60, 51], [63, 55, 38], [3...   \n",
       "320           7    7  [[[26, 26, 22], [17, 17, 13], [18, 19, 14], [9...   \n",
       "321           7    8  [[[43, 37, 33], [42, 36, 31], [42, 37, 33], [4...   \n",
       "322           7    9  [[[41, 38, 33], [41, 38, 33], [41, 38, 33], [4...   \n",
       "323           7   10  [[[115, 90, 85], [115, 90, 86], [111, 86, 82],...   \n",
       "\n",
       "                                    Image Before Lunch       Breakfast Time  \\\n",
       "0    [[[41, 152, 201], [77, 164, 205], [88, 157, 13...  2021-09-19 08:41:00   \n",
       "1    [[[40, 59, 77], [35, 56, 72], [20, 36, 47], [9...  2021-09-20 09:50:00   \n",
       "2    [[[53, 44, 38], [51, 43, 36], [54, 47, 39], [4...  2021-09-21 09:34:00   \n",
       "3    [[[30, 28, 28], [20, 18, 17], [31, 27, 23], [2...  2021-09-22 09:46:00   \n",
       "4    [[[74, 85, 100], [59, 69, 81], [73, 84, 96], [...  2021-09-23 09:07:00   \n",
       "..                                                 ...                  ...   \n",
       "319  [[[90, 77, 75], [92, 78, 75], [94, 83, 81], [9...  2021-12-18 08:52:00   \n",
       "320  [[[17, 9, 8], [10, 7, 7], [3, 3, 4], [3, 3, 3]...  2021-12-19 08:43:00   \n",
       "321  [[[122, 108, 107], [124, 110, 108], [124, 111,...  2021-12-20 09:06:00   \n",
       "322  [[[59, 46, 32], [63, 51, 41], [57, 42, 28], [6...  2021-12-21 08:34:00   \n",
       "323  [[[66, 53, 44], [77, 67, 62], [70, 57, 48], [6...  2021-12-22 08:44:00   \n",
       "\n",
       "              Lunch Time                                           CGM Data  \n",
       "0    2021-09-19 12:24:00  [('2021-09-19 08:20:00', 98.26666666666667), (...  \n",
       "1    2021-09-20 15:20:00  [('2021-09-20 09:10:00', 97.18333333333334), (...  \n",
       "2    2021-09-21 13:09:00  [('2021-09-21 09:20:00', 107.36666666666666), ...  \n",
       "3    2021-09-22 13:50:00  [('2021-09-22 09:25:00', 107.28333333333333), ...  \n",
       "4    2021-09-23 13:17:00  [('2021-09-23 08:55:00', 103.0), ('2021-09-23 ...  \n",
       "..                   ...                                                ...  \n",
       "319  2021-12-18 12:28:00  [('2021-12-18 08:50:00', 101.36), ('2021-12-18...  \n",
       "320  2021-12-19 13:13:00  [('2021-12-19 08:40:00', 100.68), ('2021-12-19...  \n",
       "321  2021-12-20 12:46:00  [('2021-12-20 09:00:00', 104.04), ('2021-12-20...  \n",
       "322  2021-12-21 12:38:00  [('2021-12-21 08:25:00', 96.4), ('2021-12-21 0...  \n",
       "323  2021-12-22 12:34:00  [('2021-12-22 08:35:00', 96.68), ('2021-12-22 ...  \n",
       "\n",
       "[324 rows x 7 columns]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Process Food Pictures (Image Dataset) - COMPLETE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholder for missing images (a blank black image)\n",
    "def create_placeholder_image(size=(64, 64, 3)):\n",
    "    return np.zeros(size, dtype=np.float32)  # Normalized [0, 1] range\n",
    "\n",
    "# Function to preprocess image data\n",
    "def preprocess_image(img_data, size=(64, 64)):\n",
    "    try:\n",
    "        img_array = np.array(img_data, dtype=np.uint8)  # Ensure valid data type\n",
    "\n",
    "        # Check for empty image\n",
    "        if img_array.size == 0 or img_array.ndim != 3 or img_array.shape[2] != 3:\n",
    "            raise ValueError(f\"Invalid or empty image dimensions: {img_array.shape}\")\n",
    "\n",
    "        img_resized = np.array(Image.fromarray(img_array).resize(size))  # Resize\n",
    "        img_normalized = img_resized / 255.0  # Normalize pixel values to [0, 1]\n",
    "        return img_normalized\n",
    "    except Exception as e:\n",
    "        print(f\"Error preprocessing image: {e}\")\n",
    "        return create_placeholder_image(size)\n",
    "\n",
    "# Preprocess the dataset\n",
    "def preprocess_img(data):\n",
    "    # Define placeholder image\n",
    "    placeholder_image = create_placeholder_image()\n",
    "\n",
    "    # Iterate over rows to preprocess images\n",
    "    breakfast_images = []\n",
    "    lunch_images = []\n",
    "\n",
    "    for index, row in data.iterrows():\n",
    "        # Handle missing breakfast images\n",
    "        if pd.isnull(row['Image Before Breakfast']) or row['Image Before Breakfast'] == '[]':  # Check for empty list or NaN\n",
    "            breakfast_images.append(placeholder_image)\n",
    "        else:\n",
    "            try:\n",
    "                img_data = eval(row['Image Before Breakfast'])  # Convert string to list\n",
    "                breakfast_images.append(preprocess_image(img_data))\n",
    "            except Exception as e:\n",
    "                print(f\"Error at index {index}, breakfast: {e}\")\n",
    "                breakfast_images.append(placeholder_image)\n",
    "\n",
    "        # Handle missing lunch images\n",
    "        if pd.isnull(row['Image Before Lunch']) or row['Image Before Lunch'] == '[]':  # Check for empty list or NaN\n",
    "            lunch_images.append(placeholder_image)\n",
    "        else:\n",
    "            try:\n",
    "                img_data = eval(row['Image Before Lunch'])  # Convert string to list\n",
    "                lunch_images.append(preprocess_image(img_data))\n",
    "            except Exception as e:\n",
    "                print(f\"Error at index {index}, lunch: {e}\")\n",
    "                lunch_images.append(placeholder_image)\n",
    "\n",
    "    # Add preprocessed images back to the dataset\n",
    "    data['Image Before Breakfast'] = breakfast_images\n",
    "    data['Image Before Lunch'] = lunch_images\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject ID</th>\n",
       "      <th>Day</th>\n",
       "      <th>Image Before Breakfast</th>\n",
       "      <th>Image Before Lunch</th>\n",
       "      <th>Breakfast Time</th>\n",
       "      <th>Lunch Time</th>\n",
       "      <th>CGM Data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[[[0.5490196078431373, 0.47843137254901963, 0....</td>\n",
       "      <td>[[[0.1607843137254902, 0.596078431372549, 0.78...</td>\n",
       "      <td>2021-09-19 08:41:00</td>\n",
       "      <td>2021-09-19 12:24:00</td>\n",
       "      <td>[('2021-09-19 08:20:00', 98.26666666666667), (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>[[[0.2627450980392157, 0.22745098039215686, 0....</td>\n",
       "      <td>[[[0.1568627450980392, 0.23137254901960785, 0....</td>\n",
       "      <td>2021-09-20 09:50:00</td>\n",
       "      <td>2021-09-20 15:20:00</td>\n",
       "      <td>[('2021-09-20 09:10:00', 97.18333333333334), (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>[[[0.7803921568627451, 0.7647058823529411, 0.7...</td>\n",
       "      <td>[[[0.20784313725490197, 0.17254901960784313, 0...</td>\n",
       "      <td>2021-09-21 09:34:00</td>\n",
       "      <td>2021-09-21 13:09:00</td>\n",
       "      <td>[('2021-09-21 09:20:00', 107.36666666666666), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>[[[0.5843137254901961, 0.4745098039215686, 0.3...</td>\n",
       "      <td>[[[0.11764705882352941, 0.10980392156862745, 0...</td>\n",
       "      <td>2021-09-22 09:46:00</td>\n",
       "      <td>2021-09-22 13:50:00</td>\n",
       "      <td>[('2021-09-22 09:25:00', 107.28333333333333), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>[[[0.6862745098039216, 0.7215686274509804, 0.7...</td>\n",
       "      <td>[[[0.2901960784313726, 0.3333333333333333, 0.3...</td>\n",
       "      <td>2021-09-23 09:07:00</td>\n",
       "      <td>2021-09-23 13:17:00</td>\n",
       "      <td>[('2021-09-23 08:55:00', 103.0), ('2021-09-23 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>[[[0.26666666666666666, 0.13333333333333333, 0...</td>\n",
       "      <td>[[[0.35294117647058826, 0.30196078431372547, 0...</td>\n",
       "      <td>2021-12-18 08:52:00</td>\n",
       "      <td>2021-12-18 12:28:00</td>\n",
       "      <td>[('2021-12-18 08:50:00', 101.36), ('2021-12-18...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>[[[0.10196078431372549, 0.10196078431372549, 0...</td>\n",
       "      <td>[[[0.06666666666666667, 0.03529411764705882, 0...</td>\n",
       "      <td>2021-12-19 08:43:00</td>\n",
       "      <td>2021-12-19 13:13:00</td>\n",
       "      <td>[('2021-12-19 08:40:00', 100.68), ('2021-12-19...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>[[[0.16862745098039217, 0.1450980392156863, 0....</td>\n",
       "      <td>[[[0.47843137254901963, 0.4235294117647059, 0....</td>\n",
       "      <td>2021-12-20 09:06:00</td>\n",
       "      <td>2021-12-20 12:46:00</td>\n",
       "      <td>[('2021-12-20 09:00:00', 104.04), ('2021-12-20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>[[[0.1607843137254902, 0.14901960784313725, 0....</td>\n",
       "      <td>[[[0.23137254901960785, 0.1803921568627451, 0....</td>\n",
       "      <td>2021-12-21 08:34:00</td>\n",
       "      <td>2021-12-21 12:38:00</td>\n",
       "      <td>[('2021-12-21 08:25:00', 96.4), ('2021-12-21 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>[[[0.45098039215686275, 0.35294117647058826, 0...</td>\n",
       "      <td>[[[0.25882352941176473, 0.20784313725490197, 0...</td>\n",
       "      <td>2021-12-22 08:44:00</td>\n",
       "      <td>2021-12-22 12:34:00</td>\n",
       "      <td>[('2021-12-22 08:35:00', 96.68), ('2021-12-22 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>324 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Subject ID  Day                             Image Before Breakfast  \\\n",
       "0             1    2  [[[0.5490196078431373, 0.47843137254901963, 0....   \n",
       "1             1    3  [[[0.2627450980392157, 0.22745098039215686, 0....   \n",
       "2             1    4  [[[0.7803921568627451, 0.7647058823529411, 0.7...   \n",
       "3             1    5  [[[0.5843137254901961, 0.4745098039215686, 0.3...   \n",
       "4             1    6  [[[0.6862745098039216, 0.7215686274509804, 0.7...   \n",
       "..          ...  ...                                                ...   \n",
       "319           7    6  [[[0.26666666666666666, 0.13333333333333333, 0...   \n",
       "320           7    7  [[[0.10196078431372549, 0.10196078431372549, 0...   \n",
       "321           7    8  [[[0.16862745098039217, 0.1450980392156863, 0....   \n",
       "322           7    9  [[[0.1607843137254902, 0.14901960784313725, 0....   \n",
       "323           7   10  [[[0.45098039215686275, 0.35294117647058826, 0...   \n",
       "\n",
       "                                    Image Before Lunch       Breakfast Time  \\\n",
       "0    [[[0.1607843137254902, 0.596078431372549, 0.78...  2021-09-19 08:41:00   \n",
       "1    [[[0.1568627450980392, 0.23137254901960785, 0....  2021-09-20 09:50:00   \n",
       "2    [[[0.20784313725490197, 0.17254901960784313, 0...  2021-09-21 09:34:00   \n",
       "3    [[[0.11764705882352941, 0.10980392156862745, 0...  2021-09-22 09:46:00   \n",
       "4    [[[0.2901960784313726, 0.3333333333333333, 0.3...  2021-09-23 09:07:00   \n",
       "..                                                 ...                  ...   \n",
       "319  [[[0.35294117647058826, 0.30196078431372547, 0...  2021-12-18 08:52:00   \n",
       "320  [[[0.06666666666666667, 0.03529411764705882, 0...  2021-12-19 08:43:00   \n",
       "321  [[[0.47843137254901963, 0.4235294117647059, 0....  2021-12-20 09:06:00   \n",
       "322  [[[0.23137254901960785, 0.1803921568627451, 0....  2021-12-21 08:34:00   \n",
       "323  [[[0.25882352941176473, 0.20784313725490197, 0...  2021-12-22 08:44:00   \n",
       "\n",
       "              Lunch Time                                           CGM Data  \n",
       "0    2021-09-19 12:24:00  [('2021-09-19 08:20:00', 98.26666666666667), (...  \n",
       "1    2021-09-20 15:20:00  [('2021-09-20 09:10:00', 97.18333333333334), (...  \n",
       "2    2021-09-21 13:09:00  [('2021-09-21 09:20:00', 107.36666666666666), ...  \n",
       "3    2021-09-22 13:50:00  [('2021-09-22 09:25:00', 107.28333333333333), ...  \n",
       "4    2021-09-23 13:17:00  [('2021-09-23 08:55:00', 103.0), ('2021-09-23 ...  \n",
       "..                   ...                                                ...  \n",
       "319  2021-12-18 12:28:00  [('2021-12-18 08:50:00', 101.36), ('2021-12-18...  \n",
       "320  2021-12-19 13:13:00  [('2021-12-19 08:40:00', 100.68), ('2021-12-19...  \n",
       "321  2021-12-20 12:46:00  [('2021-12-20 09:00:00', 104.04), ('2021-12-20...  \n",
       "322  2021-12-21 12:38:00  [('2021-12-21 08:25:00', 96.4), ('2021-12-21 0...  \n",
       "323  2021-12-22 12:34:00  [('2021-12-22 08:35:00', 96.68), ('2021-12-22 ...  \n",
       "\n",
       "[324 rows x 7 columns]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train = preprocess_img(data_train)\n",
    "\n",
    "data_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Process CGM Data (Time-Series Glucose Levels) - COMPLETE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace missing values of breakfast and lunch times with mean meal times of that subject.  \n",
    "Used measures of variability for time-series-data CGM Data.  \n",
    "Time between meals added as input feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updating missing values with mean\n",
    "\n",
    "def preprocess_cgm(data_train):\n",
    "\n",
    "    # Function to check if CGM Data is an empty array\n",
    "    def is_cgm_data_empty(row):\n",
    "        try:\n",
    "            cgm_list = ast.literal_eval(row['CGM Data'])\n",
    "            return len(cgm_list) == 0\n",
    "        except:\n",
    "            return True\n",
    "\n",
    "    # Function to filter out rows where CGM Data is empty\n",
    "    data_train = data_train[~data_train.apply(is_cgm_data_empty, axis=1)]\n",
    "\n",
    "    # Get the HH:MM:SS breakfast and lunch times and calculate the mean for each subject ID\n",
    "    data_train.loc[:, 'Breakfast Time'] = pd.to_datetime(data_train['Breakfast Time'], errors='coerce')\n",
    "    data_train.loc[:, 'Lunch Time'] = pd.to_datetime(data_train['Lunch Time'], errors='coerce')\n",
    "\n",
    "    def mean_time(times):\n",
    "        total_seconds = sum([t.hour * 3600 + t.minute * 60 + t.second for t in times if pd.notna(t)])\n",
    "        mean_seconds = total_seconds // len([t for t in times if pd.notna(t)])\n",
    "        return pd.to_datetime(mean_seconds, unit='s').time()\n",
    "\n",
    "    mean_times = data_train.groupby('Subject ID')[['Breakfast Time', 'Lunch Time']].apply(\n",
    "        lambda group: pd.Series({\n",
    "            'Breakfast Time': mean_time(group['Breakfast Time']),\n",
    "            'Lunch Time': mean_time(group['Lunch Time'])\n",
    "        })\n",
    "    )\n",
    "\n",
    "    mean_times = mean_times.reset_index()\n",
    "\n",
    "    # Find the reference date for any row within the same subject:\n",
    "    def get_reference_date(subject_id):\n",
    "        day_2_breakfast_index = data_train[(data_train['Subject ID'] == subject_id) & (data_train['Day'] == 2)]['Breakfast Time'].first_valid_index()\n",
    "        if day_2_breakfast_index is None or pd.isna(data_train.loc[day_2_breakfast_index, 'Breakfast Time']):\n",
    "            day_3_breakfast_index = data_train[(data_train['Subject ID'] == subject_id) & (data_train['Day'] == 4)]['Breakfast Time'].first_valid_index()\n",
    "            if day_3_breakfast_index is not None:\n",
    "                reference_date = data_train.loc[day_3_breakfast_index, 'Breakfast Time']\n",
    "                reference_day = 4\n",
    "            else:\n",
    "                reference_date = None\n",
    "                reference_day = None\n",
    "        else:\n",
    "            reference_date = data_train.loc[day_2_breakfast_index, 'Breakfast Time']\n",
    "            reference_day = 2\n",
    "        \n",
    "        return pd.Series([reference_date.date(), reference_day])\n",
    "\n",
    "    mean_times[['Reference Date', 'Reference Day']] = mean_times['Subject ID'].apply(get_reference_date)\n",
    "\n",
    "    # Update missing values\n",
    "    def update_missing_breakfast_time(row, mean_times):\n",
    "        subject_id = row['Subject ID']\n",
    "        day = row['Day']\n",
    "        \n",
    "        mean_breakfast_time = mean_times.loc[mean_times['Subject ID'] == subject_id, 'Breakfast Time'].iloc[0]\n",
    "        mean_reference_date = mean_times.loc[mean_times['Subject ID'] == subject_id, 'Reference Date'].iloc[0]\n",
    "        reference_day = mean_times.loc[mean_times['Subject ID'] == subject_id, 'Reference Day'].iloc[0]\n",
    "        current_date = mean_reference_date + pd.Timedelta(days=(day - reference_day))\n",
    "        updated_breakfast_time = pd.to_datetime(current_date.strftime('%Y-%m-%d') + ' ' + mean_breakfast_time.strftime('%H:%M:%S'))\n",
    "        row['Breakfast Time'] = updated_breakfast_time\n",
    "        return row\n",
    "\n",
    "    data_train = data_train.apply(\n",
    "        lambda row: update_missing_breakfast_time(row, mean_times) if pd.isna(row['Breakfast Time']) else row, axis=1\n",
    "    )\n",
    "\n",
    "    def update_missing_lunch_time(row, mean_times):\n",
    "        subject_id = row['Subject ID']\n",
    "        day = row['Day']\n",
    "        mean_lunch_time = mean_times.loc[mean_times['Subject ID'] == subject_id, 'Lunch Time'].iloc[0]\n",
    "        mean_reference_date = mean_times.loc[mean_times['Subject ID'] == subject_id, 'Reference Date'].iloc[0]\n",
    "        reference_day = mean_times.loc[mean_times['Subject ID'] == subject_id, 'Reference Day'].iloc[0]\n",
    "        current_date = mean_reference_date + pd.Timedelta(days=(day - reference_day))\n",
    "        updated_lunch_time = pd.to_datetime(current_date.strftime('%Y-%m-%d') + ' ' + mean_lunch_time.strftime('%H:%M:%S'))\n",
    "        row['Lunch Time'] = updated_lunch_time\n",
    "        return row\n",
    "\n",
    "    data_train = data_train.apply(\n",
    "        lambda row: update_missing_lunch_time(row, mean_times) if pd.isna(row['Lunch Time']) else row, axis=1\n",
    "    )\n",
    "\n",
    "    data_train['Time Between Meals'] = (data_train['Lunch Time'] - data_train['Breakfast Time']).dt.total_seconds()\n",
    "\n",
    "    return data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject ID</th>\n",
       "      <th>Day</th>\n",
       "      <th>Image Before Breakfast</th>\n",
       "      <th>Image Before Lunch</th>\n",
       "      <th>Breakfast Time</th>\n",
       "      <th>Lunch Time</th>\n",
       "      <th>CGM Data</th>\n",
       "      <th>Time Between Meals</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[[[0.5490196078431373, 0.47843137254901963, 0....</td>\n",
       "      <td>[[[0.1607843137254902, 0.596078431372549, 0.78...</td>\n",
       "      <td>2021-09-19 08:41:00</td>\n",
       "      <td>2021-09-19 12:24:00</td>\n",
       "      <td>[('2021-09-19 08:20:00', 98.26666666666667), (...</td>\n",
       "      <td>13380.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>[[[0.2627450980392157, 0.22745098039215686, 0....</td>\n",
       "      <td>[[[0.1568627450980392, 0.23137254901960785, 0....</td>\n",
       "      <td>2021-09-20 09:50:00</td>\n",
       "      <td>2021-09-20 15:20:00</td>\n",
       "      <td>[('2021-09-20 09:10:00', 97.18333333333334), (...</td>\n",
       "      <td>19800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>[[[0.7803921568627451, 0.7647058823529411, 0.7...</td>\n",
       "      <td>[[[0.20784313725490197, 0.17254901960784313, 0...</td>\n",
       "      <td>2021-09-21 09:34:00</td>\n",
       "      <td>2021-09-21 13:09:00</td>\n",
       "      <td>[('2021-09-21 09:20:00', 107.36666666666666), ...</td>\n",
       "      <td>12900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>[[[0.5843137254901961, 0.4745098039215686, 0.3...</td>\n",
       "      <td>[[[0.11764705882352941, 0.10980392156862745, 0...</td>\n",
       "      <td>2021-09-22 09:46:00</td>\n",
       "      <td>2021-09-22 13:50:00</td>\n",
       "      <td>[('2021-09-22 09:25:00', 107.28333333333333), ...</td>\n",
       "      <td>14640.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>[[[0.6862745098039216, 0.7215686274509804, 0.7...</td>\n",
       "      <td>[[[0.2901960784313726, 0.3333333333333333, 0.3...</td>\n",
       "      <td>2021-09-23 09:07:00</td>\n",
       "      <td>2021-09-23 13:17:00</td>\n",
       "      <td>[('2021-09-23 08:55:00', 103.0), ('2021-09-23 ...</td>\n",
       "      <td>15000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>[[[0.26666666666666666, 0.13333333333333333, 0...</td>\n",
       "      <td>[[[0.35294117647058826, 0.30196078431372547, 0...</td>\n",
       "      <td>2021-12-18 08:52:00</td>\n",
       "      <td>2021-12-18 12:28:00</td>\n",
       "      <td>[('2021-12-18 08:50:00', 101.36), ('2021-12-18...</td>\n",
       "      <td>12960.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>[[[0.10196078431372549, 0.10196078431372549, 0...</td>\n",
       "      <td>[[[0.06666666666666667, 0.03529411764705882, 0...</td>\n",
       "      <td>2021-12-19 08:43:00</td>\n",
       "      <td>2021-12-19 13:13:00</td>\n",
       "      <td>[('2021-12-19 08:40:00', 100.68), ('2021-12-19...</td>\n",
       "      <td>16200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>[[[0.16862745098039217, 0.1450980392156863, 0....</td>\n",
       "      <td>[[[0.47843137254901963, 0.4235294117647059, 0....</td>\n",
       "      <td>2021-12-20 09:06:00</td>\n",
       "      <td>2021-12-20 12:46:00</td>\n",
       "      <td>[('2021-12-20 09:00:00', 104.04), ('2021-12-20...</td>\n",
       "      <td>13200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>[[[0.1607843137254902, 0.14901960784313725, 0....</td>\n",
       "      <td>[[[0.23137254901960785, 0.1803921568627451, 0....</td>\n",
       "      <td>2021-12-21 08:34:00</td>\n",
       "      <td>2021-12-21 12:38:00</td>\n",
       "      <td>[('2021-12-21 08:25:00', 96.4), ('2021-12-21 0...</td>\n",
       "      <td>14640.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>[[[0.45098039215686275, 0.35294117647058826, 0...</td>\n",
       "      <td>[[[0.25882352941176473, 0.20784313725490197, 0...</td>\n",
       "      <td>2021-12-22 08:44:00</td>\n",
       "      <td>2021-12-22 12:34:00</td>\n",
       "      <td>[('2021-12-22 08:35:00', 96.68), ('2021-12-22 ...</td>\n",
       "      <td>13800.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>319 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Subject ID  Day                             Image Before Breakfast  \\\n",
       "0             1    2  [[[0.5490196078431373, 0.47843137254901963, 0....   \n",
       "1             1    3  [[[0.2627450980392157, 0.22745098039215686, 0....   \n",
       "2             1    4  [[[0.7803921568627451, 0.7647058823529411, 0.7...   \n",
       "3             1    5  [[[0.5843137254901961, 0.4745098039215686, 0.3...   \n",
       "4             1    6  [[[0.6862745098039216, 0.7215686274509804, 0.7...   \n",
       "..          ...  ...                                                ...   \n",
       "319           7    6  [[[0.26666666666666666, 0.13333333333333333, 0...   \n",
       "320           7    7  [[[0.10196078431372549, 0.10196078431372549, 0...   \n",
       "321           7    8  [[[0.16862745098039217, 0.1450980392156863, 0....   \n",
       "322           7    9  [[[0.1607843137254902, 0.14901960784313725, 0....   \n",
       "323           7   10  [[[0.45098039215686275, 0.35294117647058826, 0...   \n",
       "\n",
       "                                    Image Before Lunch      Breakfast Time  \\\n",
       "0    [[[0.1607843137254902, 0.596078431372549, 0.78... 2021-09-19 08:41:00   \n",
       "1    [[[0.1568627450980392, 0.23137254901960785, 0.... 2021-09-20 09:50:00   \n",
       "2    [[[0.20784313725490197, 0.17254901960784313, 0... 2021-09-21 09:34:00   \n",
       "3    [[[0.11764705882352941, 0.10980392156862745, 0... 2021-09-22 09:46:00   \n",
       "4    [[[0.2901960784313726, 0.3333333333333333, 0.3... 2021-09-23 09:07:00   \n",
       "..                                                 ...                 ...   \n",
       "319  [[[0.35294117647058826, 0.30196078431372547, 0... 2021-12-18 08:52:00   \n",
       "320  [[[0.06666666666666667, 0.03529411764705882, 0... 2021-12-19 08:43:00   \n",
       "321  [[[0.47843137254901963, 0.4235294117647059, 0.... 2021-12-20 09:06:00   \n",
       "322  [[[0.23137254901960785, 0.1803921568627451, 0.... 2021-12-21 08:34:00   \n",
       "323  [[[0.25882352941176473, 0.20784313725490197, 0... 2021-12-22 08:44:00   \n",
       "\n",
       "             Lunch Time                                           CGM Data  \\\n",
       "0   2021-09-19 12:24:00  [('2021-09-19 08:20:00', 98.26666666666667), (...   \n",
       "1   2021-09-20 15:20:00  [('2021-09-20 09:10:00', 97.18333333333334), (...   \n",
       "2   2021-09-21 13:09:00  [('2021-09-21 09:20:00', 107.36666666666666), ...   \n",
       "3   2021-09-22 13:50:00  [('2021-09-22 09:25:00', 107.28333333333333), ...   \n",
       "4   2021-09-23 13:17:00  [('2021-09-23 08:55:00', 103.0), ('2021-09-23 ...   \n",
       "..                  ...                                                ...   \n",
       "319 2021-12-18 12:28:00  [('2021-12-18 08:50:00', 101.36), ('2021-12-18...   \n",
       "320 2021-12-19 13:13:00  [('2021-12-19 08:40:00', 100.68), ('2021-12-19...   \n",
       "321 2021-12-20 12:46:00  [('2021-12-20 09:00:00', 104.04), ('2021-12-20...   \n",
       "322 2021-12-21 12:38:00  [('2021-12-21 08:25:00', 96.4), ('2021-12-21 0...   \n",
       "323 2021-12-22 12:34:00  [('2021-12-22 08:35:00', 96.68), ('2021-12-22 ...   \n",
       "\n",
       "     Time Between Meals  \n",
       "0               13380.0  \n",
       "1               19800.0  \n",
       "2               12900.0  \n",
       "3               14640.0  \n",
       "4               15000.0  \n",
       "..                  ...  \n",
       "319             12960.0  \n",
       "320             16200.0  \n",
       "321             13200.0  \n",
       "322             14640.0  \n",
       "323             13800.0  \n",
       "\n",
       "[319 rows x 8 columns]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train = preprocess_cgm(data_train)\n",
    "\n",
    "data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Function to check if CGM Data is an empty array\n",
    "# def is_cgm_data_empty(row):\n",
    "#     try:\n",
    "#         cgm_list = ast.literal_eval(row['CGM Data'])\n",
    "#         return len(cgm_list) == 0\n",
    "#     except:\n",
    "#         return True\n",
    "\n",
    "# # Function to filter out rows where CGM Data is empty\n",
    "# cgm_train = cgm_train[~cgm_train.apply(is_cgm_data_empty, axis=1)]\n",
    "\n",
    "# # Handle missing breakfast and lunch times\n",
    "# cgm_train['Breakfast Time'] = pd.to_datetime(cgm_train['Breakfast Time'], errors='coerce')\n",
    "# cgm_train['Lunch Time'] = pd.to_datetime(cgm_train['Lunch Time'], errors='coerce')\n",
    "\n",
    "# # Extract CGM data as list of tuples, convert to list of time series values\n",
    "# cgm_train['CGM Data'] = cgm_train['CGM Data'].apply(lambda x: eval(x) if isinstance(x, str) else [])\n",
    "\n",
    "# # Extract features from CGM data (flatten the time and glucose values)\n",
    "# def extract_cgm_features(cgm_data):\n",
    "#     times = [entry[0] for entry in cgm_data]\n",
    "#     glucose_levels = [entry[1] for entry in cgm_data]\n",
    "#     return times, glucose_levels\n",
    "\n",
    "# cgm_train['CGM Times'], cgm_train['CGM Levels'] = zip(*cgm_train['CGM Data'].apply(extract_cgm_features))\n",
    "\n",
    "# # Normalize glucose levels\n",
    "# scaler = StandardScaler()\n",
    "# cgm_train['CGM Levels'] = cgm_train['CGM Levels'].apply(lambda x: scaler.fit_transform(np.array(x).reshape(-1, 1)).flatten())\n",
    "\n",
    "# # We need to pad the sequences to a fixed length for GRU input\n",
    "# max_sequence_length = 300  # Define a maximum length for the sequences\n",
    "# cgm_train['Padded CGM Levels'] = pad_sequences(cgm_train['CGM Levels'], maxlen=max_sequence_length, padding='post', value=0, dtype='float32').tolist()\n",
    "\n",
    "# # Mask labels: We will use NaN or a predefined mask value for missing times -- 1\n",
    "# cgm_train['Breakfast Time Masked'] = cgm_train['Breakfast Time'].isna().astype(int)\n",
    "# cgm_train['Lunch Time Masked'] = cgm_train['Lunch Time'].isna().astype(int)\n",
    "\n",
    "# # Prepare the target variable: encode the time values for breakfast and lunch\n",
    "# def encode_times(time_column):\n",
    "#     return (time_column - pd.Timestamp('2021-09-18')) // pd.Timedelta('1s')\n",
    "\n",
    "# # Filter rows where both Breakfast and Lunch times are missing (i.e., both masks are 0)\n",
    "# filtered_cgm_train = cgm_train[(cgm_train['Breakfast Time Masked'] == 0) & (cgm_train['Lunch Time Masked'] == 0)].copy()\n",
    "\n",
    "# # Encode breakfast and lunch times only for rows where both are missing\n",
    "# filtered_cgm_train['Breakfast Time Encoded'] = encode_times(filtered_cgm_train['Breakfast Time'])\n",
    "# filtered_cgm_train['Lunch Time Encoded'] = encode_times(filtered_cgm_train['Lunch Time'])\n",
    "\n",
    "# time_scaler = MinMaxScaler()\n",
    "\n",
    "# # Reshape and scale both 'Breakfast Time Encoded' and 'Lunch Time Encoded'\n",
    "# filtered_cgm_train[['Breakfast Time Encoded', 'Lunch Time Encoded']] = time_scaler.fit_transform(\n",
    "#     filtered_cgm_train[['Breakfast Time Encoded', 'Lunch Time Encoded']]\n",
    "# )\n",
    "\n",
    "# X_train = np.array(filtered_cgm_train['Padded CGM Levels'].tolist())\n",
    "# y_train = filtered_cgm_train[['Breakfast Time Encoded', 'Lunch Time Encoded']].values\n",
    "\n",
    "# # Reshape X_train to (samples, time steps, features)\n",
    "# X_train_reshaped = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))  # (samples, time steps, features)\n",
    "\n",
    "# # Define the GRU model\n",
    "# def create_gru_model(input_shape):\n",
    "#     model = Sequential([\n",
    "#         Input(shape=input_shape),\n",
    "#         GRU(32, activation='relu'),\n",
    "#         Dense(2)  # Output two values: breakfast and lunch times\n",
    "#     ])\n",
    "#     model.compile(optimizer=Adam(learning_rate=0.001, clipvalue=1.0), loss='mse')\n",
    "#     return model\n",
    "\n",
    "# # Create and compile the model\n",
    "# model = create_gru_model((X_train_reshaped.shape[1], 1))\n",
    "\n",
    "# # Train the model\n",
    "# model.fit(X_train_reshaped, y_train, epochs=10, batch_size=32, validation_split=0.2, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def predict_meal_times(model, X):\n",
    "#     X = np.array(X.tolist()) if isinstance(X, pd.Series) else np.array(X)\n",
    "#     X_reshaped = X.reshape((X.shape[0], X.shape[1], 1))\n",
    "#     predictions = model.predict(X_reshaped)\n",
    "#     reference_date = pd.Timestamp('2021-09-18')\n",
    "\n",
    "#     # Decode predictions back to original scale using inverse transformation\n",
    "#     decoded_times = time_scaler.inverse_transform(predictions)\n",
    "\n",
    "#     # Add the decoded seconds back to the reference date\n",
    "#     decoded_breakfast_timestamps = reference_date + pd.to_timedelta(decoded_times[:, 0], unit='s')\n",
    "#     decoded_lunch_timestamps = reference_date + pd.to_timedelta(decoded_times[:, 1], unit='s')\n",
    "\n",
    "#     decoded_predictions = pd.DataFrame({\n",
    "#         'Predicted Breakfast Time': decoded_breakfast_timestamps,\n",
    "#         'Predicted Lunch Time': decoded_lunch_timestamps\n",
    "#     })\n",
    "\n",
    "#     return decoded_predictions\n",
    "\n",
    "# # Extract rows with missing breakfast or lunch times\n",
    "# missing_data = cgm_train[cgm_train['Breakfast Time'].isna() | cgm_train['Lunch Time'].isna()]\n",
    "\n",
    "# # Ensure that `Padded CGM Levels` is included in `missing_data`\n",
    "# predict_missing = missing_data['Padded CGM Levels']\n",
    "# missing_data_copy = missing_data.copy()\n",
    "\n",
    "# # Make predictions for missing breakfast and lunch times\n",
    "# predicted_times = predict_meal_times(model, predict_missing)\n",
    "\n",
    "# # Reset indices for both DataFrames to align by row order\n",
    "# missing_data_copy = missing_data_copy.reset_index(drop=True)\n",
    "# predicted_times = predicted_times.reset_index(drop=True)\n",
    "\n",
    "# # Add the 'Predicted Breakfast Time' column\n",
    "# missing_data_copy['Predicted Breakfast Time'] = predicted_times['Predicted Breakfast Time']\n",
    "# missing_data_copy['Predicted Lunch Time'] = predicted_times['Predicted Lunch Time']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Process Viome Data (Demographic Data) - COMPLETE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Used measures of variability to represent Viome Data.  \n",
    "Encoded categorical value of race, gender and diabetes status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_viome(data):\n",
    "    # Split the `Viome` column into individual features\n",
    "    viome_split = data['Viome'].str.split(',', expand=True).astype(float)\n",
    "    viome_split.columns = [f\"Viome_{i}\" for i in range(viome_split.shape[1])]\n",
    "    data = pd.concat([data.drop(columns=['Viome']), viome_split], axis=1)\n",
    "\n",
    "    # Impute missing values for numeric columns\n",
    "    numeric_cols = data.select_dtypes(include=[np.number]).columns.drop('Subject ID')\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    data[numeric_cols] = imputer.fit_transform(data[numeric_cols])\n",
    "\n",
    "    # Normalize numeric data\n",
    "    scaler = MinMaxScaler()\n",
    "    data[numeric_cols] = scaler.fit_transform(data[numeric_cols])\n",
    "\n",
    "    # Encode categorical columns\n",
    "    categorical_cols = ['Gender', 'Race', 'Diabetes Status']\n",
    "    encoder = OneHotEncoder(sparse_output=False, drop='first')  # Use sparse_output instead of sparse\n",
    "    encoded_cats = pd.DataFrame(\n",
    "        encoder.fit_transform(data[categorical_cols]),\n",
    "        columns=encoder.get_feature_names_out(categorical_cols)\n",
    "    )\n",
    "\n",
    "    # Drop original categorical columns and merge encoded ones\n",
    "    data = pd.concat([data.drop(columns=categorical_cols), encoded_cats], axis=1)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject ID</th>\n",
       "      <th>Day</th>\n",
       "      <th>Image Before Breakfast</th>\n",
       "      <th>Image Before Lunch</th>\n",
       "      <th>Breakfast Time</th>\n",
       "      <th>Lunch Time</th>\n",
       "      <th>CGM Data</th>\n",
       "      <th>Time Between Meals</th>\n",
       "      <th>Age</th>\n",
       "      <th>Weight</th>\n",
       "      <th>...</th>\n",
       "      <th>Viome_22</th>\n",
       "      <th>Viome_23</th>\n",
       "      <th>Viome_24</th>\n",
       "      <th>Viome_25</th>\n",
       "      <th>Viome_26</th>\n",
       "      <th>Gender_1.0</th>\n",
       "      <th>Race_Hispanic/Latino</th>\n",
       "      <th>Race_White</th>\n",
       "      <th>Diabetes Status_0.5</th>\n",
       "      <th>Diabetes Status_1.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[[[0.5490196078431373, 0.47843137254901963, 0....</td>\n",
       "      <td>[[[0.1607843137254902, 0.596078431372549, 0.78...</td>\n",
       "      <td>2021-09-19 08:41:00</td>\n",
       "      <td>2021-09-19 12:24:00</td>\n",
       "      <td>[('2021-09-19 08:20:00', 98.26666666666667), (...</td>\n",
       "      <td>13380.0</td>\n",
       "      <td>0.106383</td>\n",
       "      <td>0.101311</td>\n",
       "      <td>...</td>\n",
       "      <td>0.443409</td>\n",
       "      <td>0.295137</td>\n",
       "      <td>0.529551</td>\n",
       "      <td>0.412826</td>\n",
       "      <td>0.467538</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>[[[0.2627450980392157, 0.22745098039215686, 0....</td>\n",
       "      <td>[[[0.1568627450980392, 0.23137254901960785, 0....</td>\n",
       "      <td>2021-09-20 09:50:00</td>\n",
       "      <td>2021-09-20 15:20:00</td>\n",
       "      <td>[('2021-09-20 09:10:00', 97.18333333333334), (...</td>\n",
       "      <td>19800.0</td>\n",
       "      <td>0.106383</td>\n",
       "      <td>0.101311</td>\n",
       "      <td>...</td>\n",
       "      <td>0.443409</td>\n",
       "      <td>0.295137</td>\n",
       "      <td>0.529551</td>\n",
       "      <td>0.412826</td>\n",
       "      <td>0.467538</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>[[[0.7803921568627451, 0.7647058823529411, 0.7...</td>\n",
       "      <td>[[[0.20784313725490197, 0.17254901960784313, 0...</td>\n",
       "      <td>2021-09-21 09:34:00</td>\n",
       "      <td>2021-09-21 13:09:00</td>\n",
       "      <td>[('2021-09-21 09:20:00', 107.36666666666666), ...</td>\n",
       "      <td>12900.0</td>\n",
       "      <td>0.106383</td>\n",
       "      <td>0.101311</td>\n",
       "      <td>...</td>\n",
       "      <td>0.443409</td>\n",
       "      <td>0.295137</td>\n",
       "      <td>0.529551</td>\n",
       "      <td>0.412826</td>\n",
       "      <td>0.467538</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>[[[0.5843137254901961, 0.4745098039215686, 0.3...</td>\n",
       "      <td>[[[0.11764705882352941, 0.10980392156862745, 0...</td>\n",
       "      <td>2021-09-22 09:46:00</td>\n",
       "      <td>2021-09-22 13:50:00</td>\n",
       "      <td>[('2021-09-22 09:25:00', 107.28333333333333), ...</td>\n",
       "      <td>14640.0</td>\n",
       "      <td>0.106383</td>\n",
       "      <td>0.101311</td>\n",
       "      <td>...</td>\n",
       "      <td>0.443409</td>\n",
       "      <td>0.295137</td>\n",
       "      <td>0.529551</td>\n",
       "      <td>0.412826</td>\n",
       "      <td>0.467538</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>[[[0.6862745098039216, 0.7215686274509804, 0.7...</td>\n",
       "      <td>[[[0.2901960784313726, 0.3333333333333333, 0.3...</td>\n",
       "      <td>2021-09-23 09:07:00</td>\n",
       "      <td>2021-09-23 13:17:00</td>\n",
       "      <td>[('2021-09-23 08:55:00', 103.0), ('2021-09-23 ...</td>\n",
       "      <td>15000.0</td>\n",
       "      <td>0.106383</td>\n",
       "      <td>0.101311</td>\n",
       "      <td>...</td>\n",
       "      <td>0.443409</td>\n",
       "      <td>0.295137</td>\n",
       "      <td>0.529551</td>\n",
       "      <td>0.412826</td>\n",
       "      <td>0.467538</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>[[[0.26666666666666666, 0.13333333333333333, 0...</td>\n",
       "      <td>[[[0.35294117647058826, 0.30196078431372547, 0...</td>\n",
       "      <td>2021-12-18 08:52:00</td>\n",
       "      <td>2021-12-18 12:28:00</td>\n",
       "      <td>[('2021-12-18 08:50:00', 101.36), ('2021-12-18...</td>\n",
       "      <td>12960.0</td>\n",
       "      <td>0.936170</td>\n",
       "      <td>0.493445</td>\n",
       "      <td>...</td>\n",
       "      <td>0.486812</td>\n",
       "      <td>0.424777</td>\n",
       "      <td>0.664898</td>\n",
       "      <td>0.412061</td>\n",
       "      <td>0.423699</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>[[[0.10196078431372549, 0.10196078431372549, 0...</td>\n",
       "      <td>[[[0.06666666666666667, 0.03529411764705882, 0...</td>\n",
       "      <td>2021-12-19 08:43:00</td>\n",
       "      <td>2021-12-19 13:13:00</td>\n",
       "      <td>[('2021-12-19 08:40:00', 100.68), ('2021-12-19...</td>\n",
       "      <td>16200.0</td>\n",
       "      <td>0.936170</td>\n",
       "      <td>0.493445</td>\n",
       "      <td>...</td>\n",
       "      <td>0.486812</td>\n",
       "      <td>0.424777</td>\n",
       "      <td>0.664898</td>\n",
       "      <td>0.412061</td>\n",
       "      <td>0.423699</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>[[[0.16862745098039217, 0.1450980392156863, 0....</td>\n",
       "      <td>[[[0.47843137254901963, 0.4235294117647059, 0....</td>\n",
       "      <td>2021-12-20 09:06:00</td>\n",
       "      <td>2021-12-20 12:46:00</td>\n",
       "      <td>[('2021-12-20 09:00:00', 104.04), ('2021-12-20...</td>\n",
       "      <td>13200.0</td>\n",
       "      <td>0.936170</td>\n",
       "      <td>0.493445</td>\n",
       "      <td>...</td>\n",
       "      <td>0.486812</td>\n",
       "      <td>0.424777</td>\n",
       "      <td>0.664898</td>\n",
       "      <td>0.412061</td>\n",
       "      <td>0.423699</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>[[[0.1607843137254902, 0.14901960784313725, 0....</td>\n",
       "      <td>[[[0.23137254901960785, 0.1803921568627451, 0....</td>\n",
       "      <td>2021-12-21 08:34:00</td>\n",
       "      <td>2021-12-21 12:38:00</td>\n",
       "      <td>[('2021-12-21 08:25:00', 96.4), ('2021-12-21 0...</td>\n",
       "      <td>14640.0</td>\n",
       "      <td>0.936170</td>\n",
       "      <td>0.493445</td>\n",
       "      <td>...</td>\n",
       "      <td>0.486812</td>\n",
       "      <td>0.424777</td>\n",
       "      <td>0.664898</td>\n",
       "      <td>0.412061</td>\n",
       "      <td>0.423699</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>[[[0.45098039215686275, 0.35294117647058826, 0...</td>\n",
       "      <td>[[[0.25882352941176473, 0.20784313725490197, 0...</td>\n",
       "      <td>2021-12-22 08:44:00</td>\n",
       "      <td>2021-12-22 12:34:00</td>\n",
       "      <td>[('2021-12-22 08:35:00', 96.68), ('2021-12-22 ...</td>\n",
       "      <td>13800.0</td>\n",
       "      <td>0.936170</td>\n",
       "      <td>0.493445</td>\n",
       "      <td>...</td>\n",
       "      <td>0.486812</td>\n",
       "      <td>0.424777</td>\n",
       "      <td>0.664898</td>\n",
       "      <td>0.412061</td>\n",
       "      <td>0.423699</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>319 rows Ã— 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Subject ID  Day                             Image Before Breakfast  \\\n",
       "0             1    2  [[[0.5490196078431373, 0.47843137254901963, 0....   \n",
       "1             1    3  [[[0.2627450980392157, 0.22745098039215686, 0....   \n",
       "2             1    4  [[[0.7803921568627451, 0.7647058823529411, 0.7...   \n",
       "3             1    5  [[[0.5843137254901961, 0.4745098039215686, 0.3...   \n",
       "4             1    6  [[[0.6862745098039216, 0.7215686274509804, 0.7...   \n",
       "..          ...  ...                                                ...   \n",
       "314           7    6  [[[0.26666666666666666, 0.13333333333333333, 0...   \n",
       "315           7    7  [[[0.10196078431372549, 0.10196078431372549, 0...   \n",
       "316           7    8  [[[0.16862745098039217, 0.1450980392156863, 0....   \n",
       "317           7    9  [[[0.1607843137254902, 0.14901960784313725, 0....   \n",
       "318           7   10  [[[0.45098039215686275, 0.35294117647058826, 0...   \n",
       "\n",
       "                                    Image Before Lunch      Breakfast Time  \\\n",
       "0    [[[0.1607843137254902, 0.596078431372549, 0.78... 2021-09-19 08:41:00   \n",
       "1    [[[0.1568627450980392, 0.23137254901960785, 0.... 2021-09-20 09:50:00   \n",
       "2    [[[0.20784313725490197, 0.17254901960784313, 0... 2021-09-21 09:34:00   \n",
       "3    [[[0.11764705882352941, 0.10980392156862745, 0... 2021-09-22 09:46:00   \n",
       "4    [[[0.2901960784313726, 0.3333333333333333, 0.3... 2021-09-23 09:07:00   \n",
       "..                                                 ...                 ...   \n",
       "314  [[[0.35294117647058826, 0.30196078431372547, 0... 2021-12-18 08:52:00   \n",
       "315  [[[0.06666666666666667, 0.03529411764705882, 0... 2021-12-19 08:43:00   \n",
       "316  [[[0.47843137254901963, 0.4235294117647059, 0.... 2021-12-20 09:06:00   \n",
       "317  [[[0.23137254901960785, 0.1803921568627451, 0.... 2021-12-21 08:34:00   \n",
       "318  [[[0.25882352941176473, 0.20784313725490197, 0... 2021-12-22 08:44:00   \n",
       "\n",
       "             Lunch Time                                           CGM Data  \\\n",
       "0   2021-09-19 12:24:00  [('2021-09-19 08:20:00', 98.26666666666667), (...   \n",
       "1   2021-09-20 15:20:00  [('2021-09-20 09:10:00', 97.18333333333334), (...   \n",
       "2   2021-09-21 13:09:00  [('2021-09-21 09:20:00', 107.36666666666666), ...   \n",
       "3   2021-09-22 13:50:00  [('2021-09-22 09:25:00', 107.28333333333333), ...   \n",
       "4   2021-09-23 13:17:00  [('2021-09-23 08:55:00', 103.0), ('2021-09-23 ...   \n",
       "..                  ...                                                ...   \n",
       "314 2021-12-18 12:28:00  [('2021-12-18 08:50:00', 101.36), ('2021-12-18...   \n",
       "315 2021-12-19 13:13:00  [('2021-12-19 08:40:00', 100.68), ('2021-12-19...   \n",
       "316 2021-12-20 12:46:00  [('2021-12-20 09:00:00', 104.04), ('2021-12-20...   \n",
       "317 2021-12-21 12:38:00  [('2021-12-21 08:25:00', 96.4), ('2021-12-21 0...   \n",
       "318 2021-12-22 12:34:00  [('2021-12-22 08:35:00', 96.68), ('2021-12-22 ...   \n",
       "\n",
       "     Time Between Meals       Age    Weight  ...  Viome_22  Viome_23  \\\n",
       "0               13380.0  0.106383  0.101311  ...  0.443409  0.295137   \n",
       "1               19800.0  0.106383  0.101311  ...  0.443409  0.295137   \n",
       "2               12900.0  0.106383  0.101311  ...  0.443409  0.295137   \n",
       "3               14640.0  0.106383  0.101311  ...  0.443409  0.295137   \n",
       "4               15000.0  0.106383  0.101311  ...  0.443409  0.295137   \n",
       "..                  ...       ...       ...  ...       ...       ...   \n",
       "314             12960.0  0.936170  0.493445  ...  0.486812  0.424777   \n",
       "315             16200.0  0.936170  0.493445  ...  0.486812  0.424777   \n",
       "316             13200.0  0.936170  0.493445  ...  0.486812  0.424777   \n",
       "317             14640.0  0.936170  0.493445  ...  0.486812  0.424777   \n",
       "318             13800.0  0.936170  0.493445  ...  0.486812  0.424777   \n",
       "\n",
       "     Viome_24  Viome_25  Viome_26  Gender_1.0  Race_Hispanic/Latino  \\\n",
       "0    0.529551  0.412826  0.467538         0.0                   1.0   \n",
       "1    0.529551  0.412826  0.467538         0.0                   1.0   \n",
       "2    0.529551  0.412826  0.467538         0.0                   1.0   \n",
       "3    0.529551  0.412826  0.467538         0.0                   1.0   \n",
       "4    0.529551  0.412826  0.467538         0.0                   1.0   \n",
       "..        ...       ...       ...         ...                   ...   \n",
       "314  0.664898  0.412061  0.423699         1.0                   1.0   \n",
       "315  0.664898  0.412061  0.423699         1.0                   1.0   \n",
       "316  0.664898  0.412061  0.423699         1.0                   1.0   \n",
       "317  0.664898  0.412061  0.423699         1.0                   1.0   \n",
       "318  0.664898  0.412061  0.423699         1.0                   1.0   \n",
       "\n",
       "     Race_White  Diabetes Status_0.5  Diabetes Status_1.0  \n",
       "0           0.0                  0.0                  0.0  \n",
       "1           0.0                  0.0                  0.0  \n",
       "2           0.0                  0.0                  0.0  \n",
       "3           0.0                  0.0                  0.0  \n",
       "4           0.0                  0.0                  0.0  \n",
       "..          ...                  ...                  ...  \n",
       "314         0.0                  1.0                  0.0  \n",
       "315         0.0                  1.0                  0.0  \n",
       "316         0.0                  1.0                  0.0  \n",
       "317         0.0                  1.0                  0.0  \n",
       "318         0.0                  1.0                  0.0  \n",
       "\n",
       "[319 rows x 55 columns]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo_viome_train = preprocess_viome(demo_viome_train)\n",
    "final_data = pd.merge(data_train, demo_viome_train, on=['Subject ID'])\n",
    "\n",
    "final_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultimodalDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        \n",
    "        # Convert images to tensors and permute dimensions to [batch, channels, height, width]\n",
    "        self.breakfast_images = torch.tensor(\n",
    "            np.stack(data['Image Before Breakfast'].values), \n",
    "            dtype=torch.float32\n",
    "        ).permute(0, 3, 1, 2)  # Change from NHWC to NCHW format\n",
    "        \n",
    "        self.lunch_images = torch.tensor(\n",
    "            np.stack(data['Image Before Lunch'].values), \n",
    "            dtype=torch.float32\n",
    "        ).permute(0, 3, 1, 2)  # Change from NHWC to NCHW format\n",
    "        \n",
    "        # Process CGM data\n",
    "        def process_cgm(x):\n",
    "            try:\n",
    "                if isinstance(x, str):\n",
    "                    clean_str = x.replace('[', '').replace(']', '').replace('\\n', '').replace(' ', '')\n",
    "                    if clean_str:\n",
    "                        values = [float(i) for i in clean_str.split(',') if i]\n",
    "                        if len(values) > 288:\n",
    "                            return values[:288]\n",
    "                        elif len(values) < 288:\n",
    "                            return values + [0.0] * (288 - len(values))\n",
    "                        return values\n",
    "                return [0.0] * 288\n",
    "            except:\n",
    "                return [0.0] * 288\n",
    "        \n",
    "        processed_cgm = []\n",
    "        for x in data['CGM Data'].values:\n",
    "            cgm_values = process_cgm(x)\n",
    "            processed_cgm.append(cgm_values)\n",
    "            \n",
    "        self.cgm_data = torch.tensor(processed_cgm, dtype=torch.float32)\n",
    "        \n",
    "        # Extract viome and demographic features\n",
    "        viome_cols = [col for col in data.columns if 'Viome_' in col]\n",
    "        demo_cols = ['Age', 'Weight', 'Height', 'A1C', 'Baseline Fasting Glucose', \n",
    "                     'Insulin', 'Triglycerides', 'Cholesterol', 'HDL', 'Non-HDL', \n",
    "                     'LDL', 'VLDL', 'CHO/HDL Ratio', 'HOMA-IR', 'BMI']\n",
    "        \n",
    "        demo_viome_features = data[viome_cols + demo_cols].values\n",
    "        self.demo_viome = torch.tensor(demo_viome_features, dtype=torch.float32)\n",
    "        \n",
    "        # Extract labels\n",
    "        self.labels = torch.tensor(data['Lunch Calories'].values, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'breakfast_img': self.breakfast_images[idx],\n",
    "            'lunch_img': self.lunch_images[idx],\n",
    "            'cgm': self.cgm_data[idx],\n",
    "            'demo_viome': self.demo_viome[idx],\n",
    "            'label': self.labels[idx]\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multimodal Model Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultimodalNet(nn.Module):\n",
    "    def __init__(self, cgm_dim, demo_viome_dim):\n",
    "        super(MultimodalNet, self).__init__()\n",
    "        \n",
    "        # Image encoders (modified for correct dimensions)\n",
    "        self.image_encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),  # Input: [B, 3, 64, 64]\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),                             # Output: [B, 32, 32, 32]\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1), \n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),                             # Output: [B, 64, 16, 16]\n",
    "            nn.Flatten(),                                # Output: [B, 64 * 16 * 16]\n",
    "            nn.Linear(64 * 16 * 16, 256),               # Output: [B, 256]\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        # CGM encoder\n",
    "        self.cgm_encoder = nn.Sequential(\n",
    "            nn.Linear(288, 128),  # Assuming CGM length is 288\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Demo-Viome encoder\n",
    "        self.demo_viome_encoder = nn.Sequential(\n",
    "            nn.Linear(demo_viome_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # Joint embedding\n",
    "        self.fusion = nn.Sequential(\n",
    "            nn.Linear(256 * 2 + 64 + 32, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, breakfast_img, lunch_img, cgm, demo_viome):\n",
    "        # Ensure correct dimensions for images\n",
    "        if breakfast_img.dim() == 3:\n",
    "            breakfast_img = breakfast_img.unsqueeze(0)\n",
    "        if lunch_img.dim() == 3:\n",
    "            lunch_img = lunch_img.unsqueeze(0)\n",
    "            \n",
    "        # Encode images\n",
    "        breakfast_features = self.image_encoder(breakfast_img)\n",
    "        lunch_features = self.image_encoder(lunch_img)\n",
    "        \n",
    "        # Encode CGM\n",
    "        cgm_features = self.cgm_encoder(cgm)\n",
    "        \n",
    "        # Encode demo-viome\n",
    "        demo_viome_features = self.demo_viome_encoder(demo_viome)\n",
    "        \n",
    "        # Concatenate all features\n",
    "        combined = torch.cat([\n",
    "            breakfast_features, \n",
    "            lunch_features, \n",
    "            cgm_features, \n",
    "            demo_viome_features\n",
    "        ], dim=1)\n",
    "        \n",
    "        # Final prediction\n",
    "        output = self.fusion(combined)\n",
    "        return output.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RMSRELoss(nn.Module):\n",
    "    def __init__(self, eps=1e-6):\n",
    "        super(RMSRELoss, self).__init__()\n",
    "        self.eps = eps\n",
    "        \n",
    "    def forward(self, pred, target):\n",
    "        relative_error = (pred - target) / (target + self.eps)\n",
    "        rmsre = torch.sqrt(torch.mean(relative_error ** 2))\n",
    "        return rmsre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Sample CGM data before processing:\", final_data['CGM Data'].iloc[0])\n",
    "print(\"Shape of breakfast images:\", final_data['Image Before Breakfast'].iloc[0].shape)\n",
    "print(\"Number of Viome columns:\", len([col for col in final_data.columns if 'Viome_' in col]))\n",
    "dataset = MultimodalDataset(final_data)\n",
    "train_loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Initialize model\n",
    "cgm_dim = dataset.cgm_data.shape[1]  # Should be 288\n",
    "demo_viome_dim = dataset.demo_viome.shape[1] \n",
    "\n",
    "model = MultimodalNet(\n",
    "    cgm_dim=dataset.cgm_data.shape[1],\n",
    "    demo_viome_dim=dataset.demo_viome.shape[1]\n",
    ")\n",
    "\n",
    "# Initialize optimizer and loss function\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = RMSRELoss()\n",
    "\n",
    "# Training loop\n",
    "def train_epoch(model, loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for batch in loader:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        pred = model(\n",
    "            batch['breakfast_img'],\n",
    "            batch['lunch_img'],\n",
    "            batch['cgm'],\n",
    "            batch['demo_viome']\n",
    "        )\n",
    "        \n",
    "        loss = criterion(pred, batch['label'])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    loss = train_epoch(model, train_loader, optimizer, criterion)\n",
    "    print(f'Epoch {epoch+1}, Loss: {loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholder for missing images\n",
    "def create_placeholder_image(size=(64, 64, 3)):\n",
    "    return np.zeros(size, dtype=np.float32)\n",
    "\n",
    "# Function to preprocess image data\n",
    "def preprocess_image(img_data, size=(64, 64)):\n",
    "    try:\n",
    "        img_array = np.array(img_data, dtype=np.uint8)\n",
    "        if img_array.size == 0 or img_array.ndim != 3 or img_array.shape[2] != 3:\n",
    "            raise ValueError(f\"Invalid or empty image dimensions: {img_array.shape}\")\n",
    "        img_resized = np.array(Image.fromarray(img_array).resize(size))\n",
    "        img_normalized = img_resized / 255.0\n",
    "        return img_normalized\n",
    "    except Exception as e:\n",
    "        print(f\"Error preprocessing image: {e}\")\n",
    "        return create_placeholder_image(size)\n",
    "\n",
    "# Preprocess dataset (test data version without labels)\n",
    "def preprocess_test_dataset(data):\n",
    "    placeholder_image = create_placeholder_image()\n",
    "    breakfast_images = []\n",
    "    lunch_images = []\n",
    "\n",
    "    for index, row in data.iterrows():\n",
    "        # Process breakfast images\n",
    "        if pd.isnull(row['Image Before Breakfast']) or row['Image Before Breakfast'] == '[]':\n",
    "            breakfast_images.append(placeholder_image)\n",
    "        else:\n",
    "            try:\n",
    "                img_data = eval(row['Image Before Breakfast'])\n",
    "                breakfast_images.append(preprocess_image(img_data))\n",
    "            except Exception as e:\n",
    "                print(f\"Error at index {index}, breakfast: {e}\")\n",
    "                breakfast_images.append(placeholder_image)\n",
    "\n",
    "        # Process lunch images\n",
    "        if pd.isnull(row['Image Before Lunch']) or row['Image Before Lunch'] == '[]':\n",
    "            lunch_images.append(placeholder_image)\n",
    "        else:\n",
    "            try:\n",
    "                img_data = eval(row['Image Before Lunch'])\n",
    "                lunch_images.append(preprocess_image(img_data))\n",
    "            except Exception as e:\n",
    "                print(f\"Error at index {index}, lunch: {e}\")\n",
    "                lunch_images.append(placeholder_image)\n",
    "\n",
    "    data['Image Before Breakfast'] = breakfast_images\n",
    "    data['Image Before Lunch'] = lunch_images\n",
    "\n",
    "    return data\n",
    "\n",
    "# Test data preprocessing\n",
    "test_cgm_data = pd.read_csv('/Users/sudheerb/Documents/Academics /1st Semester/ML/Project/fa-24-tamu-csce-633-600-machine-learning/cgm_test.csv')\n",
    "test_img_data = pd.read_csv('/Users/sudheerb/Documents/Academics /1st Semester/ML/Project/fa-24-tamu-csce-633-600-machine-learning/img_test.csv')\n",
    "test_demo_viome_data = pd.read_csv('/Users/sudheerb/Documents/Academics /1st Semester/ML/Project/fa-24-tamu-csce-633-600-machine-learning/demo_viome_test.csv', delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3276825711.py, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[177], line 5\u001b[1;36m\u001b[0m\n\u001b[1;33m    file_path =\u001b[0m\n\u001b[1;37m                ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "temp_test_data = pd.merge(test_img_data, test_cgm_data, on=['Subject ID', 'Day'])\n",
    "print(temp_test_data['Image Before Breakfast'][0])\n",
    "processed_test_data = preprocess_test_dataset(temp_test_data)\n",
    "# Preprocess demo_viome data for test set\n",
    "file_path = \"\"\n",
    "if len(test_demo_viome_data.columns) == 1:\n",
    "    # If all data is in a single column, try splitting with a comma\n",
    "    test_demo_viome_data = pd.read_csv(file_path, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Columns in dataset after re-parsing:\", test_demo_viome_data.columns)\n",
    "viome_split = test_demo_viome_data['Viome'].str.split(',', expand=True).astype(float)\n",
    "viome_split.columns = [f\"Viome_{i}\" for i in range(viome_split.shape[1])]\n",
    "test_demo_viome_data = pd.concat([test_demo_viome_data.drop(columns=['Viome']), viome_split], axis=1)\n",
    "\n",
    "numeric_cols = test_demo_viome_data.select_dtypes(include=[np.number]).columns.drop('Subject ID')\n",
    "test_demo_viome_data[numeric_cols] = test_demo_viome_data[numeric_cols].fillna(test_demo_viome_data[numeric_cols].mean())\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "test_demo_viome_data[numeric_cols] = scaler.fit_transform(test_demo_viome_data[numeric_cols])\n",
    "\n",
    "categorical_cols = ['Gender', 'Race', 'Diabetes Status']\n",
    "encoder = OneHotEncoder(sparse_output=False, drop='first')\n",
    "encoded_cats = pd.DataFrame(\n",
    "    encoder.fit_transform(test_demo_viome_data[categorical_cols]),\n",
    "    columns=encoder.get_feature_names_out(categorical_cols)\n",
    ")\n",
    "test_demo_viome_data = pd.concat([test_demo_viome_data.drop(columns=categorical_cols), encoded_cats], axis=1)\n",
    "\n",
    "final_test_data = pd.merge(processed_test_data, test_demo_viome_data, on=['Subject ID'])\n",
    "\n",
    "# Test Dataset Class\n",
    "class MultimodalTestDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        # print(data['Image Before Breakfast'].head())\n",
    "        self.breakfast_images = torch.tensor(\n",
    "            np.stack(data['Image Before Breakfast'].values), dtype=torch.float32\n",
    "        ).permute(0, 3, 1, 2)\n",
    "        self.lunch_images = torch.tensor(\n",
    "            np.stack(data['Image Before Lunch'].values), dtype=torch.float32\n",
    "        ).permute(0, 3, 1, 2)\n",
    "        viome_cols = [col for col in data.columns if 'Viome_' in col]\n",
    "        demo_cols = ['Age', 'Weight', 'Height', 'A1C', 'Baseline Fasting Glucose', \n",
    "                     'Insulin', 'Triglycerides', 'Cholesterol', 'HDL', 'Non-HDL', \n",
    "                     'LDL', 'VLDL', 'CHO/HDL Ratio', 'HOMA-IR', 'BMI']\n",
    "        demo_viome_features = data[viome_cols + demo_cols].values\n",
    "        self.demo_viome = torch.tensor(demo_viome_features, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'breakfast_img': self.breakfast_images[idx],\n",
    "            'lunch_img': self.lunch_images[idx],\n",
    "            'demo_viome': self.demo_viome[idx]\n",
    "        }\n",
    "\n",
    "# Example usage for test data\n",
    "test_dataset = MultimodalTestDataset(final_test_data)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=4, shuffle=False)\n",
    "\n",
    "# Iterating through the test DataLoader\n",
    "for batch in test_dataloader:\n",
    "    print(batch['breakfast_img'].shape)\n",
    "    print(batch['lunch_img'].shape)\n",
    "    print(batch['demo_viome'].shape)\n",
    "    break  # Just show one batch for brevity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "\n",
    "# Placeholder for missing images\n",
    "def create_placeholder_image(size=(64, 64, 3)):\n",
    "    return np.zeros(size, dtype=np.float32)\n",
    "\n",
    "# Function to preprocess image data\n",
    "def preprocess_image(img_data, size=(64, 64)):\n",
    "    try:\n",
    "        img_array = np.array(img_data, dtype=np.uint8)\n",
    "        if img_array.size == 0 or img_array.ndim != 3 or img_array.shape[2] != 3:\n",
    "            raise ValueError(f\"Invalid or empty image dimensions: {img_array.shape}\")\n",
    "        img_resized = np.array(Image.fromarray(img_array).resize(size))\n",
    "        img_normalized = img_resized / 255.0\n",
    "        return img_normalized\n",
    "    except Exception as e:\n",
    "        print(f\"Error preprocessing image: {e}\")\n",
    "        return create_placeholder_image(size)\n",
    "\n",
    "# Preprocess dataset (test data version without labels)\n",
    "def preprocess_test_dataset(data):\n",
    "    placeholder_image = create_placeholder_image()\n",
    "    breakfast_images = []\n",
    "    lunch_images = []\n",
    "\n",
    "    for index, row in data.iterrows():\n",
    "        # Process breakfast images\n",
    "        if pd.isnull(row['Image Before Breakfast']) or row['Image Before Breakfast'] == '[]':\n",
    "            breakfast_images.append(placeholder_image)\n",
    "        else:\n",
    "            try:\n",
    "                img_data = eval(row['Image Before Breakfast'])\n",
    "                breakfast_images.append(preprocess_image(img_data))\n",
    "            except Exception as e:\n",
    "                print(f\"Error at index {index}, breakfast: {e}\")\n",
    "                breakfast_images.append(placeholder_image)\n",
    "\n",
    "        # Process lunch images\n",
    "        if pd.isnull(row['Image Before Lunch']) or row['Image Before Lunch'] == '[]':\n",
    "            lunch_images.append(placeholder_image)\n",
    "        else:\n",
    "            try:\n",
    "                img_data = eval(row['Image Before Lunch'])\n",
    "                lunch_images.append(preprocess_image(img_data))\n",
    "            except Exception as e:\n",
    "                print(f\"Error at index {index}, lunch: {e}\")\n",
    "                lunch_images.append(placeholder_image)\n",
    "\n",
    "    data['Image Before Breakfast'] = breakfast_images\n",
    "    data['Image Before Lunch'] = lunch_images\n",
    "\n",
    "    return data\n",
    "\n",
    "# Test data preprocessing\n",
    "test_cgm_data = pd.read_csv('/Users/sudheerb/Documents/Academics /1st Semester/ML/Project/fa-24-tamu-csce-633-600-machine-learning/cgm_test.csv')\n",
    "test_img_data = pd.read_csv('/Users/sudheerb/Documents/Academics /1st Semester/ML/Project/fa-24-tamu-csce-633-600-machine-learning/img_test.csv')\n",
    "test_demo_viome_data = pd.read_csv('/Users/sudheerb/Documents/Academics /1st Semester/ML/Project/fa-24-tamu-csce-633-600-machine-learning/demo_viome_test.csv', delimiter='\\t')\n",
    "temp_test_data = pd.merge(test_img_data, test_cgm_data, on=['Subject ID', 'Day'])\n",
    "\n",
    "# Preprocess image data\n",
    "processed_test_data = preprocess_test_dataset(temp_test_data)\n",
    "\n",
    "# Preprocess demo_viome data for test set\n",
    "if len(test_demo_viome_data.columns) == 1:\n",
    "    # If all data is in a single column, try splitting with a comma\n",
    "    test_demo_viome_data = pd.read_csv('/Users/sudheerb/Documents/Academics /1st Semester/ML/Project/fa-24-tamu-csce-633-600-machine-learning/demo_viome_test.csv', delimiter=',')\n",
    "\n",
    "viome_split = test_demo_viome_data['Viome'].str.split(',', expand=True).astype(float)\n",
    "viome_split.columns = [f\"Viome_{i}\" for i in range(viome_split.shape[1])]\n",
    "test_demo_viome_data = pd.concat([test_demo_viome_data.drop(columns=['Viome']), viome_split], axis=1)\n",
    "\n",
    "# Fill missing numeric columns with mean\n",
    "numeric_cols = test_demo_viome_data.select_dtypes(include=[np.number]).columns.drop('Subject ID')\n",
    "test_demo_viome_data[numeric_cols] = test_demo_viome_data[numeric_cols].fillna(test_demo_viome_data[numeric_cols].mean())\n",
    "\n",
    "# Scale numeric features\n",
    "scaler = MinMaxScaler()\n",
    "test_demo_viome_data[numeric_cols] = scaler.fit_transform(test_demo_viome_data[numeric_cols])\n",
    "\n",
    "# Encode categorical features\n",
    "categorical_cols = ['Gender', 'Race', 'Diabetes Status']\n",
    "encoder = OneHotEncoder(sparse_output=False, drop='first')\n",
    "encoded_cats = pd.DataFrame(\n",
    "    encoder.fit_transform(test_demo_viome_data[categorical_cols]),\n",
    "    columns=encoder.get_feature_names_out(categorical_cols)\n",
    ")\n",
    "\n",
    "test_demo_viome_data = pd.concat([test_demo_viome_data.drop(columns=categorical_cols), encoded_cats], axis=1)\n",
    "\n",
    "# Merge preprocessed data\n",
    "final_test_data = pd.merge(processed_test_data, test_demo_viome_data, on=['Subject ID'])\n",
    "\n",
    "# Test Dataset Class\n",
    "class MultimodalTestDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.breakfast_images = torch.tensor(\n",
    "            np.stack(data['Image Before Breakfast'].values), dtype=torch.float32\n",
    "        ).permute(0, 3, 1, 2)\n",
    "        self.lunch_images = torch.tensor(\n",
    "            np.stack(data['Image Before Lunch'].values), dtype=torch.float32\n",
    "        ).permute(0, 3, 1, 2)\n",
    "        viome_cols = [col for col in data.columns if 'Viome_' in col]\n",
    "        demo_cols = ['Age', 'Weight', 'Height', 'A1C', 'Baseline Fasting Glucose', \n",
    "                     'Insulin', 'Triglycerides', 'Cholesterol', 'HDL', 'Non-HDL', \n",
    "                     'LDL', 'VLDL', 'CHO/HDL Ratio', 'HOMA-IR', 'BMI']\n",
    "        demo_viome_features = data[viome_cols + demo_cols].values\n",
    "        self.demo_viome = torch.tensor(demo_viome_features, dtype=torch.float32)\n",
    "        def process_cgm(x):\n",
    "            try:\n",
    "                if isinstance(x, str):\n",
    "                    clean_str = x.replace('[', '').replace(']', '').replace('\\n', '').replace(' ', '')\n",
    "                    if clean_str:\n",
    "                        values = [float(i) for i in clean_str.split(',') if i]\n",
    "                        if len(values) > 288:\n",
    "                            return values[:288]\n",
    "                        elif len(values) < 288:\n",
    "                            return values + [0.0] * (288 - len(values))\n",
    "                        return values\n",
    "                return [0.0] * 288\n",
    "            except:\n",
    "                return [0.0] * 288\n",
    "        \n",
    "        processed_cgm = []\n",
    "        for x in data['CGM Data'].values:\n",
    "            cgm_values = process_cgm(x)\n",
    "            processed_cgm.append(cgm_values)\n",
    "            \n",
    "        self.cgm_data = torch.tensor(processed_cgm, dtype=torch.float32)\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'breakfast_img': self.breakfast_images[idx],\n",
    "            'lunch_img': self.lunch_images[idx],\n",
    "            'cgm': self.cgm_data[idx],\n",
    "            'demo_viome': self.demo_viome[idx]\n",
    "        }\n",
    "\n",
    "# Example usage for test data\n",
    "test_dataset = MultimodalTestDataset(final_test_data)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=4, shuffle=False)\n",
    "\n",
    "# Iterating through the test DataLoader\n",
    "for batch in test_dataloader:\n",
    "    print(batch['breakfast_img'].shape)\n",
    "    print(batch['lunch_img'].shape)\n",
    "    print(batch['demo_viome'].shape)\n",
    "    print\n",
    "    break  # Just show one batch for brevity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, data_loader, criterion):\n",
    "    \"\"\"\n",
    "    Evaluates the model on a given dataset.\n",
    "    \n",
    "    Args:\n",
    "        model (nn.Module): The trained multimodal model.\n",
    "        data_loader (DataLoader): DataLoader containing the test/validation dataset.\n",
    "        criterion (nn.Module): Loss function used for evaluation.\n",
    "        \n",
    "    Returns:\n",
    "        float: The average loss over the dataset.\n",
    "        list: Predicted values for the dataset.\n",
    "        list: Ground truth values for the dataset.\n",
    "    \"\"\"\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    total_loss = 0\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient computation for evaluation\n",
    "        for batch in data_loader:\n",
    "            # Extract input features and labels from the batch\n",
    "            breakfast_img = batch['breakfast_img']\n",
    "            lunch_img = batch['lunch_img']\n",
    "            cgm = batch['cgm']\n",
    "            demo_viome = batch['demo_viome']\n",
    "            \n",
    "            # Forward pass through the model\n",
    "            outputs = model(breakfast_img, lunch_img, cgm, demo_viome)\n",
    "            print(outputs)\n",
    "            # Compute the loss\n",
    "            # loss = criterion(outputs, labels)\n",
    "            # total_loss += loss.item()\n",
    "            if outputs.dim() == 0:  # Scalar tensor\n",
    "                predictions.append(outputs.item())  # Convert scalar to Python float and append\n",
    "            elif outputs.dim() == 1:  # 1D tensor\n",
    "                predictions.extend(outputs.cpu().numpy().tolist()) \n",
    "            # Store predictions and true labels for later analysis\n",
    "            # predictions.extend(outputs.cpu().numpy())\n",
    "            # true_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    # Calculate the average loss\n",
    "    # average_loss = total_loss / len(data_loader)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Evaluate the model on a validation/test dataset\n",
    "# test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)  # Use your test dataset here\n",
    "\n",
    "# Evaluate the model\n",
    "test_predictions = evaluate_model(model, test_dataloader, criterion)\n",
    "\n",
    "# # Print results\n",
    "# print(f\"Test Loss: {test_loss:.4f}\")\n",
    "\n",
    "# # Optionally, analyze predictions and ground truth\n",
    "# for i, (pred, true) in enumerate(zip(test_predictions[:5], test_labels[:5])):\n",
    "#     print(f\"Sample {i + 1}: Predicted: {pred:.2f}, True: {true:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'row_id': range(len(test_predictions)),\n",
    "    'label': test_predictions\n",
    "})\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "output_file = \"test_predictions.csv\"\n",
    "df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Predictions saved to {output_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
