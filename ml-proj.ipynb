{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.impute import SimpleImputer\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn as nn\n",
    "import keras.backend as K\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import GRU, Dense, Input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Merge Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Datasets\n",
    "\n",
    "# Training datasets\n",
    "cgm_train = pd.read_csv('cgm_train.csv')\n",
    "image_train = pd.read_csv('img_train.csv')\n",
    "demo_viome_train = pd.read_csv('demo_viome_train.csv')\n",
    "label_train = pd.read_csv('label_train.csv')\n",
    "\n",
    "# Test datasets\n",
    "cgm_test = pd.read_csv('cgm_test.csv')\n",
    "image_test = pd.read_csv('img_test.csv')\n",
    "demo_viome_test = pd.read_csv('demo_viome_test.csv')\n",
    "label_test = pd.read_csv('label_test_breakfast_only.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge CGM and Image datasets\n",
    "temp_data = pd.merge(image_train, cgm_train, on=['Subject ID', 'Day'])\n",
    "output_labels = label_train[[\"Subject ID\", \"Day\", \"Lunch Calories\"]]\n",
    "data_train = pd.merge(temp_data, output_labels, on=['Subject ID','Day'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject ID</th>\n",
       "      <th>Day</th>\n",
       "      <th>Image Before Breakfast</th>\n",
       "      <th>Image Before Lunch</th>\n",
       "      <th>Breakfast Time</th>\n",
       "      <th>Lunch Time</th>\n",
       "      <th>CGM Data</th>\n",
       "      <th>Lunch Calories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[[[140, 122, 108], [135, 118, 104], [118, 104,...</td>\n",
       "      <td>[[[41, 152, 201], [77, 164, 205], [88, 157, 13...</td>\n",
       "      <td>2021-09-19 08:41:00</td>\n",
       "      <td>2021-09-19 12:24:00</td>\n",
       "      <td>[('2021-09-19 08:20:00', 98.26666666666667), (...</td>\n",
       "      <td>830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>[[[67, 58, 47], [59, 52, 41], [51, 45, 35], [4...</td>\n",
       "      <td>[[[40, 59, 77], [35, 56, 72], [20, 36, 47], [9...</td>\n",
       "      <td>2021-09-20 09:50:00</td>\n",
       "      <td>2021-09-20 15:20:00</td>\n",
       "      <td>[('2021-09-20 09:10:00', 97.18333333333334), (...</td>\n",
       "      <td>435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>[[[199, 195, 193], [198, 193, 192], [196, 192,...</td>\n",
       "      <td>[[[53, 44, 38], [51, 43, 36], [54, 47, 39], [4...</td>\n",
       "      <td>2021-09-21 09:34:00</td>\n",
       "      <td>2021-09-21 13:09:00</td>\n",
       "      <td>[('2021-09-21 09:20:00', 107.36666666666666), ...</td>\n",
       "      <td>555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>[[[149, 121, 80], [157, 128, 86], [159, 130, 8...</td>\n",
       "      <td>[[[30, 28, 28], [20, 18, 17], [31, 27, 23], [2...</td>\n",
       "      <td>2021-09-22 09:46:00</td>\n",
       "      <td>2021-09-22 13:50:00</td>\n",
       "      <td>[('2021-09-22 09:25:00', 107.28333333333333), ...</td>\n",
       "      <td>355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>[[[175, 184, 198], [192, 206, 219], [160, 165,...</td>\n",
       "      <td>[[[74, 85, 100], [59, 69, 81], [73, 84, 96], [...</td>\n",
       "      <td>2021-09-23 09:07:00</td>\n",
       "      <td>2021-09-23 13:17:00</td>\n",
       "      <td>[('2021-09-23 08:55:00', 103.0), ('2021-09-23 ...</td>\n",
       "      <td>1180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>[[[68, 34, 35], [82, 60, 51], [63, 55, 38], [3...</td>\n",
       "      <td>[[[90, 77, 75], [92, 78, 75], [94, 83, 81], [9...</td>\n",
       "      <td>2021-12-18 08:52:00</td>\n",
       "      <td>2021-12-18 12:28:00</td>\n",
       "      <td>[('2021-12-18 08:50:00', 101.36), ('2021-12-18...</td>\n",
       "      <td>1180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>[[[26, 26, 22], [17, 17, 13], [18, 19, 14], [9...</td>\n",
       "      <td>[[[17, 9, 8], [10, 7, 7], [3, 3, 4], [3, 3, 3]...</td>\n",
       "      <td>2021-12-19 08:43:00</td>\n",
       "      <td>2021-12-19 13:13:00</td>\n",
       "      <td>[('2021-12-19 08:40:00', 100.68), ('2021-12-19...</td>\n",
       "      <td>830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>[[[43, 37, 33], [42, 36, 31], [42, 37, 33], [4...</td>\n",
       "      <td>[[[122, 108, 107], [124, 110, 108], [124, 111,...</td>\n",
       "      <td>2021-12-20 09:06:00</td>\n",
       "      <td>2021-12-20 12:46:00</td>\n",
       "      <td>[('2021-12-20 09:00:00', 104.04), ('2021-12-20...</td>\n",
       "      <td>435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>[[[41, 38, 33], [41, 38, 33], [41, 38, 33], [4...</td>\n",
       "      <td>[[[59, 46, 32], [63, 51, 41], [57, 42, 28], [6...</td>\n",
       "      <td>2021-12-21 08:34:00</td>\n",
       "      <td>2021-12-21 12:38:00</td>\n",
       "      <td>[('2021-12-21 08:25:00', 96.4), ('2021-12-21 0...</td>\n",
       "      <td>555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>[[[115, 90, 85], [115, 90, 86], [111, 86, 82],...</td>\n",
       "      <td>[[[66, 53, 44], [77, 67, 62], [70, 57, 48], [6...</td>\n",
       "      <td>2021-12-22 08:44:00</td>\n",
       "      <td>2021-12-22 12:34:00</td>\n",
       "      <td>[('2021-12-22 08:35:00', 96.68), ('2021-12-22 ...</td>\n",
       "      <td>355</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>324 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Subject ID  Day                             Image Before Breakfast  \\\n",
       "0             1    2  [[[140, 122, 108], [135, 118, 104], [118, 104,...   \n",
       "1             1    3  [[[67, 58, 47], [59, 52, 41], [51, 45, 35], [4...   \n",
       "2             1    4  [[[199, 195, 193], [198, 193, 192], [196, 192,...   \n",
       "3             1    5  [[[149, 121, 80], [157, 128, 86], [159, 130, 8...   \n",
       "4             1    6  [[[175, 184, 198], [192, 206, 219], [160, 165,...   \n",
       "..          ...  ...                                                ...   \n",
       "319           7    6  [[[68, 34, 35], [82, 60, 51], [63, 55, 38], [3...   \n",
       "320           7    7  [[[26, 26, 22], [17, 17, 13], [18, 19, 14], [9...   \n",
       "321           7    8  [[[43, 37, 33], [42, 36, 31], [42, 37, 33], [4...   \n",
       "322           7    9  [[[41, 38, 33], [41, 38, 33], [41, 38, 33], [4...   \n",
       "323           7   10  [[[115, 90, 85], [115, 90, 86], [111, 86, 82],...   \n",
       "\n",
       "                                    Image Before Lunch       Breakfast Time  \\\n",
       "0    [[[41, 152, 201], [77, 164, 205], [88, 157, 13...  2021-09-19 08:41:00   \n",
       "1    [[[40, 59, 77], [35, 56, 72], [20, 36, 47], [9...  2021-09-20 09:50:00   \n",
       "2    [[[53, 44, 38], [51, 43, 36], [54, 47, 39], [4...  2021-09-21 09:34:00   \n",
       "3    [[[30, 28, 28], [20, 18, 17], [31, 27, 23], [2...  2021-09-22 09:46:00   \n",
       "4    [[[74, 85, 100], [59, 69, 81], [73, 84, 96], [...  2021-09-23 09:07:00   \n",
       "..                                                 ...                  ...   \n",
       "319  [[[90, 77, 75], [92, 78, 75], [94, 83, 81], [9...  2021-12-18 08:52:00   \n",
       "320  [[[17, 9, 8], [10, 7, 7], [3, 3, 4], [3, 3, 3]...  2021-12-19 08:43:00   \n",
       "321  [[[122, 108, 107], [124, 110, 108], [124, 111,...  2021-12-20 09:06:00   \n",
       "322  [[[59, 46, 32], [63, 51, 41], [57, 42, 28], [6...  2021-12-21 08:34:00   \n",
       "323  [[[66, 53, 44], [77, 67, 62], [70, 57, 48], [6...  2021-12-22 08:44:00   \n",
       "\n",
       "              Lunch Time                                           CGM Data  \\\n",
       "0    2021-09-19 12:24:00  [('2021-09-19 08:20:00', 98.26666666666667), (...   \n",
       "1    2021-09-20 15:20:00  [('2021-09-20 09:10:00', 97.18333333333334), (...   \n",
       "2    2021-09-21 13:09:00  [('2021-09-21 09:20:00', 107.36666666666666), ...   \n",
       "3    2021-09-22 13:50:00  [('2021-09-22 09:25:00', 107.28333333333333), ...   \n",
       "4    2021-09-23 13:17:00  [('2021-09-23 08:55:00', 103.0), ('2021-09-23 ...   \n",
       "..                   ...                                                ...   \n",
       "319  2021-12-18 12:28:00  [('2021-12-18 08:50:00', 101.36), ('2021-12-18...   \n",
       "320  2021-12-19 13:13:00  [('2021-12-19 08:40:00', 100.68), ('2021-12-19...   \n",
       "321  2021-12-20 12:46:00  [('2021-12-20 09:00:00', 104.04), ('2021-12-20...   \n",
       "322  2021-12-21 12:38:00  [('2021-12-21 08:25:00', 96.4), ('2021-12-21 0...   \n",
       "323  2021-12-22 12:34:00  [('2021-12-22 08:35:00', 96.68), ('2021-12-22 ...   \n",
       "\n",
       "     Lunch Calories  \n",
       "0               830  \n",
       "1               435  \n",
       "2               555  \n",
       "3               355  \n",
       "4              1180  \n",
       "..              ...  \n",
       "319            1180  \n",
       "320             830  \n",
       "321             435  \n",
       "322             555  \n",
       "323             355  \n",
       "\n",
       "[324 rows x 8 columns]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Process Food Pictures (Image Dataset) - COMPLETE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replaces missing images with blank image.  \n",
    "Resizes and normalizes image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholder for missing images (a blank black image)\n",
    "def create_placeholder_image(size=(64, 64, 3)):\n",
    "    return np.zeros(size, dtype=np.float32)  # Normalized [0, 1] range\n",
    "\n",
    "# Function to preprocess image data\n",
    "def handle_image(img_data, size=(64, 64)):\n",
    "    try:\n",
    "        img_array = np.array(img_data, dtype=np.uint8)  # Ensure valid data type\n",
    "\n",
    "        # Check for empty image\n",
    "        if img_array.size == 0 or img_array.ndim != 3 or img_array.shape[2] != 3:\n",
    "            raise ValueError(f\"Invalid or empty image dimensions: {img_array.shape}\")\n",
    "\n",
    "        img_resized = np.array(Image.fromarray(img_array).resize(size))  # Resize\n",
    "        img_normalized = img_resized / 255.0  # Normalize pixel values to [0, 1]\n",
    "        return img_normalized\n",
    "    except Exception as e:\n",
    "        print(f\"Error preprocessing image: {e}\")\n",
    "        return create_placeholder_image(size)\n",
    "\n",
    "# Preprocess the dataset\n",
    "def preprocess_img(data):\n",
    "    # Define placeholder image\n",
    "    placeholder_image = create_placeholder_image()\n",
    "\n",
    "    # Iterate over rows to preprocess images\n",
    "    breakfast_images = []\n",
    "    lunch_images = []\n",
    "\n",
    "    for index, row in data.iterrows():\n",
    "        # Handle missing breakfast images\n",
    "        if pd.isnull(row['Image Before Breakfast']) or row['Image Before Breakfast'] == '[]':  # Check for empty list or NaN\n",
    "            breakfast_images.append(placeholder_image)\n",
    "        else:\n",
    "            try:\n",
    "                img_data = eval(row['Image Before Breakfast'])  # Convert string to list\n",
    "                breakfast_images.append(handle_image(img_data))\n",
    "            except Exception as e:\n",
    "                print(f\"Error at index {index}, breakfast: {e}\")\n",
    "                breakfast_images.append(placeholder_image)\n",
    "\n",
    "        # Handle missing lunch images\n",
    "        if pd.isnull(row['Image Before Lunch']) or row['Image Before Lunch'] == '[]':  # Check for empty list or NaN\n",
    "            lunch_images.append(placeholder_image)\n",
    "        else:\n",
    "            try:\n",
    "                img_data = eval(row['Image Before Lunch'])  # Convert string to list\n",
    "                lunch_images.append(handle_image(img_data))\n",
    "            except Exception as e:\n",
    "                print(f\"Error at index {index}, lunch: {e}\")\n",
    "                lunch_images.append(placeholder_image)\n",
    "\n",
    "    # Add preprocessed images back to the dataset\n",
    "    data['Image Before Breakfast'] = breakfast_images\n",
    "    data['Image Before Lunch'] = lunch_images\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject ID</th>\n",
       "      <th>Day</th>\n",
       "      <th>Image Before Breakfast</th>\n",
       "      <th>Image Before Lunch</th>\n",
       "      <th>Breakfast Time</th>\n",
       "      <th>Lunch Time</th>\n",
       "      <th>CGM Data</th>\n",
       "      <th>Lunch Calories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[[[0.5490196078431373, 0.47843137254901963, 0....</td>\n",
       "      <td>[[[0.1607843137254902, 0.596078431372549, 0.78...</td>\n",
       "      <td>2021-09-19 08:41:00</td>\n",
       "      <td>2021-09-19 12:24:00</td>\n",
       "      <td>[('2021-09-19 08:20:00', 98.26666666666667), (...</td>\n",
       "      <td>830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>[[[0.2627450980392157, 0.22745098039215686, 0....</td>\n",
       "      <td>[[[0.1568627450980392, 0.23137254901960785, 0....</td>\n",
       "      <td>2021-09-20 09:50:00</td>\n",
       "      <td>2021-09-20 15:20:00</td>\n",
       "      <td>[('2021-09-20 09:10:00', 97.18333333333334), (...</td>\n",
       "      <td>435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>[[[0.7803921568627451, 0.7647058823529411, 0.7...</td>\n",
       "      <td>[[[0.20784313725490197, 0.17254901960784313, 0...</td>\n",
       "      <td>2021-09-21 09:34:00</td>\n",
       "      <td>2021-09-21 13:09:00</td>\n",
       "      <td>[('2021-09-21 09:20:00', 107.36666666666666), ...</td>\n",
       "      <td>555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>[[[0.5843137254901961, 0.4745098039215686, 0.3...</td>\n",
       "      <td>[[[0.11764705882352941, 0.10980392156862745, 0...</td>\n",
       "      <td>2021-09-22 09:46:00</td>\n",
       "      <td>2021-09-22 13:50:00</td>\n",
       "      <td>[('2021-09-22 09:25:00', 107.28333333333333), ...</td>\n",
       "      <td>355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>[[[0.6862745098039216, 0.7215686274509804, 0.7...</td>\n",
       "      <td>[[[0.2901960784313726, 0.3333333333333333, 0.3...</td>\n",
       "      <td>2021-09-23 09:07:00</td>\n",
       "      <td>2021-09-23 13:17:00</td>\n",
       "      <td>[('2021-09-23 08:55:00', 103.0), ('2021-09-23 ...</td>\n",
       "      <td>1180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>[[[0.26666666666666666, 0.13333333333333333, 0...</td>\n",
       "      <td>[[[0.35294117647058826, 0.30196078431372547, 0...</td>\n",
       "      <td>2021-12-18 08:52:00</td>\n",
       "      <td>2021-12-18 12:28:00</td>\n",
       "      <td>[('2021-12-18 08:50:00', 101.36), ('2021-12-18...</td>\n",
       "      <td>1180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>[[[0.10196078431372549, 0.10196078431372549, 0...</td>\n",
       "      <td>[[[0.06666666666666667, 0.03529411764705882, 0...</td>\n",
       "      <td>2021-12-19 08:43:00</td>\n",
       "      <td>2021-12-19 13:13:00</td>\n",
       "      <td>[('2021-12-19 08:40:00', 100.68), ('2021-12-19...</td>\n",
       "      <td>830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>[[[0.16862745098039217, 0.1450980392156863, 0....</td>\n",
       "      <td>[[[0.47843137254901963, 0.4235294117647059, 0....</td>\n",
       "      <td>2021-12-20 09:06:00</td>\n",
       "      <td>2021-12-20 12:46:00</td>\n",
       "      <td>[('2021-12-20 09:00:00', 104.04), ('2021-12-20...</td>\n",
       "      <td>435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>[[[0.1607843137254902, 0.14901960784313725, 0....</td>\n",
       "      <td>[[[0.23137254901960785, 0.1803921568627451, 0....</td>\n",
       "      <td>2021-12-21 08:34:00</td>\n",
       "      <td>2021-12-21 12:38:00</td>\n",
       "      <td>[('2021-12-21 08:25:00', 96.4), ('2021-12-21 0...</td>\n",
       "      <td>555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>[[[0.45098039215686275, 0.35294117647058826, 0...</td>\n",
       "      <td>[[[0.25882352941176473, 0.20784313725490197, 0...</td>\n",
       "      <td>2021-12-22 08:44:00</td>\n",
       "      <td>2021-12-22 12:34:00</td>\n",
       "      <td>[('2021-12-22 08:35:00', 96.68), ('2021-12-22 ...</td>\n",
       "      <td>355</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>324 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Subject ID  Day                             Image Before Breakfast  \\\n",
       "0             1    2  [[[0.5490196078431373, 0.47843137254901963, 0....   \n",
       "1             1    3  [[[0.2627450980392157, 0.22745098039215686, 0....   \n",
       "2             1    4  [[[0.7803921568627451, 0.7647058823529411, 0.7...   \n",
       "3             1    5  [[[0.5843137254901961, 0.4745098039215686, 0.3...   \n",
       "4             1    6  [[[0.6862745098039216, 0.7215686274509804, 0.7...   \n",
       "..          ...  ...                                                ...   \n",
       "319           7    6  [[[0.26666666666666666, 0.13333333333333333, 0...   \n",
       "320           7    7  [[[0.10196078431372549, 0.10196078431372549, 0...   \n",
       "321           7    8  [[[0.16862745098039217, 0.1450980392156863, 0....   \n",
       "322           7    9  [[[0.1607843137254902, 0.14901960784313725, 0....   \n",
       "323           7   10  [[[0.45098039215686275, 0.35294117647058826, 0...   \n",
       "\n",
       "                                    Image Before Lunch       Breakfast Time  \\\n",
       "0    [[[0.1607843137254902, 0.596078431372549, 0.78...  2021-09-19 08:41:00   \n",
       "1    [[[0.1568627450980392, 0.23137254901960785, 0....  2021-09-20 09:50:00   \n",
       "2    [[[0.20784313725490197, 0.17254901960784313, 0...  2021-09-21 09:34:00   \n",
       "3    [[[0.11764705882352941, 0.10980392156862745, 0...  2021-09-22 09:46:00   \n",
       "4    [[[0.2901960784313726, 0.3333333333333333, 0.3...  2021-09-23 09:07:00   \n",
       "..                                                 ...                  ...   \n",
       "319  [[[0.35294117647058826, 0.30196078431372547, 0...  2021-12-18 08:52:00   \n",
       "320  [[[0.06666666666666667, 0.03529411764705882, 0...  2021-12-19 08:43:00   \n",
       "321  [[[0.47843137254901963, 0.4235294117647059, 0....  2021-12-20 09:06:00   \n",
       "322  [[[0.23137254901960785, 0.1803921568627451, 0....  2021-12-21 08:34:00   \n",
       "323  [[[0.25882352941176473, 0.20784313725490197, 0...  2021-12-22 08:44:00   \n",
       "\n",
       "              Lunch Time                                           CGM Data  \\\n",
       "0    2021-09-19 12:24:00  [('2021-09-19 08:20:00', 98.26666666666667), (...   \n",
       "1    2021-09-20 15:20:00  [('2021-09-20 09:10:00', 97.18333333333334), (...   \n",
       "2    2021-09-21 13:09:00  [('2021-09-21 09:20:00', 107.36666666666666), ...   \n",
       "3    2021-09-22 13:50:00  [('2021-09-22 09:25:00', 107.28333333333333), ...   \n",
       "4    2021-09-23 13:17:00  [('2021-09-23 08:55:00', 103.0), ('2021-09-23 ...   \n",
       "..                   ...                                                ...   \n",
       "319  2021-12-18 12:28:00  [('2021-12-18 08:50:00', 101.36), ('2021-12-18...   \n",
       "320  2021-12-19 13:13:00  [('2021-12-19 08:40:00', 100.68), ('2021-12-19...   \n",
       "321  2021-12-20 12:46:00  [('2021-12-20 09:00:00', 104.04), ('2021-12-20...   \n",
       "322  2021-12-21 12:38:00  [('2021-12-21 08:25:00', 96.4), ('2021-12-21 0...   \n",
       "323  2021-12-22 12:34:00  [('2021-12-22 08:35:00', 96.68), ('2021-12-22 ...   \n",
       "\n",
       "     Lunch Calories  \n",
       "0               830  \n",
       "1               435  \n",
       "2               555  \n",
       "3               355  \n",
       "4              1180  \n",
       "..              ...  \n",
       "319            1180  \n",
       "320             830  \n",
       "321             435  \n",
       "322             555  \n",
       "323             355  \n",
       "\n",
       "[324 rows x 8 columns]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train = preprocess_img(data_train)\n",
    "\n",
    "data_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Process CGM Data (Time-Series Glucose Levels) - COMPLETE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace missing values of breakfast and lunch times with mean meal times of that subject.  \n",
    "Used measures of variability for time-series-data CGM Data.  \n",
    "Time between meals added as input feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updating missing values with mean\n",
    "def preprocess_cgm(data_train):\n",
    "\n",
    "    # Function to check if CGM Data is an empty array\n",
    "    def is_cgm_data_empty(row):\n",
    "        try:\n",
    "            cgm_list = ast.literal_eval(row['CGM Data'])\n",
    "            return len(cgm_list) == 0\n",
    "        except:\n",
    "            return True\n",
    "\n",
    "    # Function to filter out rows where CGM Data is empty\n",
    "    data_train = data_train[~data_train.apply(is_cgm_data_empty, axis=1)]\n",
    "\n",
    "    # Get the HH:MM:SS breakfast and lunch times and calculate the mean for each subject ID\n",
    "    data_train.loc[:, 'Breakfast Time'] = pd.to_datetime(data_train['Breakfast Time'], errors='coerce')\n",
    "    data_train.loc[:, 'Lunch Time'] = pd.to_datetime(data_train['Lunch Time'], errors='coerce')\n",
    "\n",
    "    def mean_time(times):\n",
    "        total_seconds = sum([t.hour * 3600 + t.minute * 60 + t.second for t in times if pd.notna(t)])\n",
    "        mean_seconds = total_seconds // len([t for t in times if pd.notna(t)])\n",
    "        return pd.to_datetime(mean_seconds, unit='s').time()\n",
    "\n",
    "    mean_times = data_train.groupby('Subject ID')[['Breakfast Time', 'Lunch Time']].apply(\n",
    "        lambda group: pd.Series({\n",
    "            'Breakfast Time': mean_time(group['Breakfast Time']),\n",
    "            'Lunch Time': mean_time(group['Lunch Time'])\n",
    "        })\n",
    "    )\n",
    "\n",
    "    mean_times = mean_times.reset_index()\n",
    "\n",
    "    # Find the reference date for any row within the same subject:\n",
    "    def get_reference_date(subject_id):\n",
    "        day_2_breakfast_index = data_train[(data_train['Subject ID'] == subject_id) & (data_train['Day'] == 2)]['Breakfast Time'].first_valid_index()\n",
    "        if day_2_breakfast_index is None or pd.isna(data_train.loc[day_2_breakfast_index, 'Breakfast Time']):\n",
    "            # If Breakfast Time is not available for Day 2, check Lunch Time\n",
    "            day_2_lunch_index = data_train[(data_train['Subject ID'] == subject_id) & (data_train['Day'] == 2)]['Lunch Time'].first_valid_index()\n",
    "            if day_2_lunch_index is not None:\n",
    "                reference_date = data_train.loc[day_2_lunch_index, 'Lunch Time']\n",
    "                reference_day = 2\n",
    "            else:\n",
    "                # If neither Breakfast nor Lunch time is available for Day 2, check Day 3\n",
    "                day_3_breakfast_index = data_train[(data_train['Subject ID'] == subject_id) & (data_train['Day'] == 3)]['Breakfast Time'].first_valid_index()\n",
    "                if day_3_breakfast_index is not None:\n",
    "                    reference_date = data_train.loc[day_3_breakfast_index, 'Breakfast Time']\n",
    "                    reference_day = 3\n",
    "                else:\n",
    "                    reference_date = None\n",
    "                    reference_day = None\n",
    "        else:\n",
    "            reference_date = data_train.loc[day_2_breakfast_index, 'Breakfast Time']\n",
    "            reference_day = 2\n",
    "        \n",
    "        return pd.Series([reference_date.date(), reference_day])\n",
    "\n",
    "    mean_times[['Reference Date', 'Reference Day']] = mean_times['Subject ID'].apply(get_reference_date)\n",
    "\n",
    "    # Update missing values\n",
    "    def update_missing_breakfast_time(row, mean_times):\n",
    "        subject_id = row['Subject ID']\n",
    "        day = row['Day']\n",
    "        \n",
    "        mean_breakfast_time = mean_times.loc[mean_times['Subject ID'] == subject_id, 'Breakfast Time'].iloc[0]\n",
    "        mean_reference_date = mean_times.loc[mean_times['Subject ID'] == subject_id, 'Reference Date'].iloc[0]\n",
    "        reference_day = mean_times.loc[mean_times['Subject ID'] == subject_id, 'Reference Day'].iloc[0]\n",
    "        current_date = mean_reference_date + pd.Timedelta(days=(day - reference_day))\n",
    "        updated_breakfast_time = pd.to_datetime(current_date.strftime('%Y-%m-%d') + ' ' + mean_breakfast_time.strftime('%H:%M:%S'))\n",
    "        row['Breakfast Time'] = updated_breakfast_time\n",
    "        return row\n",
    "\n",
    "    data_train = data_train.apply(\n",
    "        lambda row: update_missing_breakfast_time(row, mean_times) if pd.isna(row['Breakfast Time']) else row, axis=1\n",
    "    )\n",
    "\n",
    "    def update_missing_lunch_time(row, mean_times):\n",
    "        subject_id = row['Subject ID']\n",
    "        day = row['Day']\n",
    "        mean_lunch_time = mean_times.loc[mean_times['Subject ID'] == subject_id, 'Lunch Time'].iloc[0]\n",
    "        mean_reference_date = mean_times.loc[mean_times['Subject ID'] == subject_id, 'Reference Date'].iloc[0]\n",
    "        reference_day = mean_times.loc[mean_times['Subject ID'] == subject_id, 'Reference Day'].iloc[0]\n",
    "        current_date = mean_reference_date + pd.Timedelta(days=(day - reference_day))\n",
    "        updated_lunch_time = pd.to_datetime(current_date.strftime('%Y-%m-%d') + ' ' + mean_lunch_time.strftime('%H:%M:%S'))\n",
    "        row['Lunch Time'] = updated_lunch_time\n",
    "        return row\n",
    "\n",
    "    data_train = data_train.apply(\n",
    "        lambda row: update_missing_lunch_time(row, mean_times) if pd.isna(row['Lunch Time']) else row, axis=1\n",
    "    )\n",
    "\n",
    "    data_train['Time Between Meals'] = (data_train['Lunch Time'] - data_train['Breakfast Time']).dt.total_seconds()\n",
    "\n",
    "    return data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject ID</th>\n",
       "      <th>Day</th>\n",
       "      <th>Image Before Breakfast</th>\n",
       "      <th>Image Before Lunch</th>\n",
       "      <th>Breakfast Time</th>\n",
       "      <th>Lunch Time</th>\n",
       "      <th>CGM Data</th>\n",
       "      <th>Lunch Calories</th>\n",
       "      <th>Time Between Meals</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[[[0.5490196078431373, 0.47843137254901963, 0....</td>\n",
       "      <td>[[[0.1607843137254902, 0.596078431372549, 0.78...</td>\n",
       "      <td>2021-09-19 08:41:00</td>\n",
       "      <td>2021-09-19 12:24:00</td>\n",
       "      <td>[('2021-09-19 08:20:00', 98.26666666666667), (...</td>\n",
       "      <td>830</td>\n",
       "      <td>13380.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>[[[0.2627450980392157, 0.22745098039215686, 0....</td>\n",
       "      <td>[[[0.1568627450980392, 0.23137254901960785, 0....</td>\n",
       "      <td>2021-09-20 09:50:00</td>\n",
       "      <td>2021-09-20 15:20:00</td>\n",
       "      <td>[('2021-09-20 09:10:00', 97.18333333333334), (...</td>\n",
       "      <td>435</td>\n",
       "      <td>19800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>[[[0.7803921568627451, 0.7647058823529411, 0.7...</td>\n",
       "      <td>[[[0.20784313725490197, 0.17254901960784313, 0...</td>\n",
       "      <td>2021-09-21 09:34:00</td>\n",
       "      <td>2021-09-21 13:09:00</td>\n",
       "      <td>[('2021-09-21 09:20:00', 107.36666666666666), ...</td>\n",
       "      <td>555</td>\n",
       "      <td>12900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>[[[0.5843137254901961, 0.4745098039215686, 0.3...</td>\n",
       "      <td>[[[0.11764705882352941, 0.10980392156862745, 0...</td>\n",
       "      <td>2021-09-22 09:46:00</td>\n",
       "      <td>2021-09-22 13:50:00</td>\n",
       "      <td>[('2021-09-22 09:25:00', 107.28333333333333), ...</td>\n",
       "      <td>355</td>\n",
       "      <td>14640.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>[[[0.6862745098039216, 0.7215686274509804, 0.7...</td>\n",
       "      <td>[[[0.2901960784313726, 0.3333333333333333, 0.3...</td>\n",
       "      <td>2021-09-23 09:07:00</td>\n",
       "      <td>2021-09-23 13:17:00</td>\n",
       "      <td>[('2021-09-23 08:55:00', 103.0), ('2021-09-23 ...</td>\n",
       "      <td>1180</td>\n",
       "      <td>15000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>[[[0.26666666666666666, 0.13333333333333333, 0...</td>\n",
       "      <td>[[[0.35294117647058826, 0.30196078431372547, 0...</td>\n",
       "      <td>2021-12-18 08:52:00</td>\n",
       "      <td>2021-12-18 12:28:00</td>\n",
       "      <td>[('2021-12-18 08:50:00', 101.36), ('2021-12-18...</td>\n",
       "      <td>1180</td>\n",
       "      <td>12960.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>[[[0.10196078431372549, 0.10196078431372549, 0...</td>\n",
       "      <td>[[[0.06666666666666667, 0.03529411764705882, 0...</td>\n",
       "      <td>2021-12-19 08:43:00</td>\n",
       "      <td>2021-12-19 13:13:00</td>\n",
       "      <td>[('2021-12-19 08:40:00', 100.68), ('2021-12-19...</td>\n",
       "      <td>830</td>\n",
       "      <td>16200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>[[[0.16862745098039217, 0.1450980392156863, 0....</td>\n",
       "      <td>[[[0.47843137254901963, 0.4235294117647059, 0....</td>\n",
       "      <td>2021-12-20 09:06:00</td>\n",
       "      <td>2021-12-20 12:46:00</td>\n",
       "      <td>[('2021-12-20 09:00:00', 104.04), ('2021-12-20...</td>\n",
       "      <td>435</td>\n",
       "      <td>13200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>[[[0.1607843137254902, 0.14901960784313725, 0....</td>\n",
       "      <td>[[[0.23137254901960785, 0.1803921568627451, 0....</td>\n",
       "      <td>2021-12-21 08:34:00</td>\n",
       "      <td>2021-12-21 12:38:00</td>\n",
       "      <td>[('2021-12-21 08:25:00', 96.4), ('2021-12-21 0...</td>\n",
       "      <td>555</td>\n",
       "      <td>14640.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>[[[0.45098039215686275, 0.35294117647058826, 0...</td>\n",
       "      <td>[[[0.25882352941176473, 0.20784313725490197, 0...</td>\n",
       "      <td>2021-12-22 08:44:00</td>\n",
       "      <td>2021-12-22 12:34:00</td>\n",
       "      <td>[('2021-12-22 08:35:00', 96.68), ('2021-12-22 ...</td>\n",
       "      <td>355</td>\n",
       "      <td>13800.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>319 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Subject ID  Day                             Image Before Breakfast  \\\n",
       "0             1    2  [[[0.5490196078431373, 0.47843137254901963, 0....   \n",
       "1             1    3  [[[0.2627450980392157, 0.22745098039215686, 0....   \n",
       "2             1    4  [[[0.7803921568627451, 0.7647058823529411, 0.7...   \n",
       "3             1    5  [[[0.5843137254901961, 0.4745098039215686, 0.3...   \n",
       "4             1    6  [[[0.6862745098039216, 0.7215686274509804, 0.7...   \n",
       "..          ...  ...                                                ...   \n",
       "319           7    6  [[[0.26666666666666666, 0.13333333333333333, 0...   \n",
       "320           7    7  [[[0.10196078431372549, 0.10196078431372549, 0...   \n",
       "321           7    8  [[[0.16862745098039217, 0.1450980392156863, 0....   \n",
       "322           7    9  [[[0.1607843137254902, 0.14901960784313725, 0....   \n",
       "323           7   10  [[[0.45098039215686275, 0.35294117647058826, 0...   \n",
       "\n",
       "                                    Image Before Lunch      Breakfast Time  \\\n",
       "0    [[[0.1607843137254902, 0.596078431372549, 0.78... 2021-09-19 08:41:00   \n",
       "1    [[[0.1568627450980392, 0.23137254901960785, 0.... 2021-09-20 09:50:00   \n",
       "2    [[[0.20784313725490197, 0.17254901960784313, 0... 2021-09-21 09:34:00   \n",
       "3    [[[0.11764705882352941, 0.10980392156862745, 0... 2021-09-22 09:46:00   \n",
       "4    [[[0.2901960784313726, 0.3333333333333333, 0.3... 2021-09-23 09:07:00   \n",
       "..                                                 ...                 ...   \n",
       "319  [[[0.35294117647058826, 0.30196078431372547, 0... 2021-12-18 08:52:00   \n",
       "320  [[[0.06666666666666667, 0.03529411764705882, 0... 2021-12-19 08:43:00   \n",
       "321  [[[0.47843137254901963, 0.4235294117647059, 0.... 2021-12-20 09:06:00   \n",
       "322  [[[0.23137254901960785, 0.1803921568627451, 0.... 2021-12-21 08:34:00   \n",
       "323  [[[0.25882352941176473, 0.20784313725490197, 0... 2021-12-22 08:44:00   \n",
       "\n",
       "             Lunch Time                                           CGM Data  \\\n",
       "0   2021-09-19 12:24:00  [('2021-09-19 08:20:00', 98.26666666666667), (...   \n",
       "1   2021-09-20 15:20:00  [('2021-09-20 09:10:00', 97.18333333333334), (...   \n",
       "2   2021-09-21 13:09:00  [('2021-09-21 09:20:00', 107.36666666666666), ...   \n",
       "3   2021-09-22 13:50:00  [('2021-09-22 09:25:00', 107.28333333333333), ...   \n",
       "4   2021-09-23 13:17:00  [('2021-09-23 08:55:00', 103.0), ('2021-09-23 ...   \n",
       "..                  ...                                                ...   \n",
       "319 2021-12-18 12:28:00  [('2021-12-18 08:50:00', 101.36), ('2021-12-18...   \n",
       "320 2021-12-19 13:13:00  [('2021-12-19 08:40:00', 100.68), ('2021-12-19...   \n",
       "321 2021-12-20 12:46:00  [('2021-12-20 09:00:00', 104.04), ('2021-12-20...   \n",
       "322 2021-12-21 12:38:00  [('2021-12-21 08:25:00', 96.4), ('2021-12-21 0...   \n",
       "323 2021-12-22 12:34:00  [('2021-12-22 08:35:00', 96.68), ('2021-12-22 ...   \n",
       "\n",
       "     Lunch Calories  Time Between Meals  \n",
       "0               830             13380.0  \n",
       "1               435             19800.0  \n",
       "2               555             12900.0  \n",
       "3               355             14640.0  \n",
       "4              1180             15000.0  \n",
       "..              ...                 ...  \n",
       "319            1180             12960.0  \n",
       "320             830             16200.0  \n",
       "321             435             13200.0  \n",
       "322             555             14640.0  \n",
       "323             355             13800.0  \n",
       "\n",
       "[319 rows x 9 columns]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data_train = preprocess_cgm(data_train)\n",
    "\n",
    "data_train = data_train.drop(columns=['Breakfast Time', 'Lunch Time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Function to check if CGM Data is an empty array\n",
    "# def is_cgm_data_empty(row):\n",
    "#     try:\n",
    "#         cgm_list = ast.literal_eval(row['CGM Data'])\n",
    "#         return len(cgm_list) == 0\n",
    "#     except:\n",
    "#         return True\n",
    "\n",
    "# # Function to filter out rows where CGM Data is empty\n",
    "# cgm_train = cgm_train[~cgm_train.apply(is_cgm_data_empty, axis=1)]\n",
    "\n",
    "# # Handle missing breakfast and lunch times\n",
    "# cgm_train['Breakfast Time'] = pd.to_datetime(cgm_train['Breakfast Time'], errors='coerce')\n",
    "# cgm_train['Lunch Time'] = pd.to_datetime(cgm_train['Lunch Time'], errors='coerce')\n",
    "\n",
    "# # Extract CGM data as list of tuples, convert to list of time series values\n",
    "# cgm_train['CGM Data'] = cgm_train['CGM Data'].apply(lambda x: eval(x) if isinstance(x, str) else [])\n",
    "\n",
    "# # Extract features from CGM data (flatten the time and glucose values)\n",
    "# def extract_cgm_features(cgm_data):\n",
    "#     times = [entry[0] for entry in cgm_data]\n",
    "#     glucose_levels = [entry[1] for entry in cgm_data]\n",
    "#     return times, glucose_levels\n",
    "\n",
    "# cgm_train['CGM Times'], cgm_train['CGM Levels'] = zip(*cgm_train['CGM Data'].apply(extract_cgm_features))\n",
    "\n",
    "# # Normalize glucose levels\n",
    "# scaler = StandardScaler()\n",
    "# cgm_train['CGM Levels'] = cgm_train['CGM Levels'].apply(lambda x: scaler.fit_transform(np.array(x).reshape(-1, 1)).flatten())\n",
    "\n",
    "# # We need to pad the sequences to a fixed length for GRU input\n",
    "# max_sequence_length = 300  # Define a maximum length for the sequences\n",
    "# cgm_train['Padded CGM Levels'] = pad_sequences(cgm_train['CGM Levels'], maxlen=max_sequence_length, padding='post', value=0, dtype='float32').tolist()\n",
    "\n",
    "# # Mask labels: We will use NaN or a predefined mask value for missing times -- 1\n",
    "# cgm_train['Breakfast Time Masked'] = cgm_train['Breakfast Time'].isna().astype(int)\n",
    "# cgm_train['Lunch Time Masked'] = cgm_train['Lunch Time'].isna().astype(int)\n",
    "\n",
    "# # Prepare the target variable: encode the time values for breakfast and lunch\n",
    "# def encode_times(time_column):\n",
    "#     return (time_column - pd.Timestamp('2021-09-18')) // pd.Timedelta('1s')\n",
    "\n",
    "# # Filter rows where both Breakfast and Lunch times are missing (i.e., both masks are 0)\n",
    "# filtered_cgm_train = cgm_train[(cgm_train['Breakfast Time Masked'] == 0) & (cgm_train['Lunch Time Masked'] == 0)].copy()\n",
    "\n",
    "# # Encode breakfast and lunch times only for rows where both are missing\n",
    "# filtered_cgm_train['Breakfast Time Encoded'] = encode_times(filtered_cgm_train['Breakfast Time'])\n",
    "# filtered_cgm_train['Lunch Time Encoded'] = encode_times(filtered_cgm_train['Lunch Time'])\n",
    "\n",
    "# time_scaler = MinMaxScaler()\n",
    "\n",
    "# # Reshape and scale both 'Breakfast Time Encoded' and 'Lunch Time Encoded'\n",
    "# filtered_cgm_train[['Breakfast Time Encoded', 'Lunch Time Encoded']] = time_scaler.fit_transform(\n",
    "#     filtered_cgm_train[['Breakfast Time Encoded', 'Lunch Time Encoded']]\n",
    "# )\n",
    "\n",
    "# X_train = np.array(filtered_cgm_train['Padded CGM Levels'].tolist())\n",
    "# y_train = filtered_cgm_train[['Breakfast Time Encoded', 'Lunch Time Encoded']].values\n",
    "\n",
    "# # Reshape X_train to (samples, time steps, features)\n",
    "# X_train_reshaped = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))  # (samples, time steps, features)\n",
    "\n",
    "# # Define the GRU model\n",
    "# def create_gru_model(input_shape):\n",
    "#     model = Sequential([\n",
    "#         Input(shape=input_shape),\n",
    "#         GRU(32, activation='relu'),\n",
    "#         Dense(2)  # Output two values: breakfast and lunch times\n",
    "#     ])\n",
    "#     model.compile(optimizer=Adam(learning_rate=0.001, clipvalue=1.0), loss='mse')\n",
    "#     return model\n",
    "\n",
    "# # Create and compile the model\n",
    "# model = create_gru_model((X_train_reshaped.shape[1], 1))\n",
    "\n",
    "# # Train the model\n",
    "# model.fit(X_train_reshaped, y_train, epochs=10, batch_size=32, validation_split=0.2, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def predict_meal_times(model, X):\n",
    "#     X = np.array(X.tolist()) if isinstance(X, pd.Series) else np.array(X)\n",
    "#     X_reshaped = X.reshape((X.shape[0], X.shape[1], 1))\n",
    "#     predictions = model.predict(X_reshaped)\n",
    "#     reference_date = pd.Timestamp('2021-09-18')\n",
    "\n",
    "#     # Decode predictions back to original scale using inverse transformation\n",
    "#     decoded_times = time_scaler.inverse_transform(predictions)\n",
    "\n",
    "#     # Add the decoded seconds back to the reference date\n",
    "#     decoded_breakfast_timestamps = reference_date + pd.to_timedelta(decoded_times[:, 0], unit='s')\n",
    "#     decoded_lunch_timestamps = reference_date + pd.to_timedelta(decoded_times[:, 1], unit='s')\n",
    "\n",
    "#     decoded_predictions = pd.DataFrame({\n",
    "#         'Predicted Breakfast Time': decoded_breakfast_timestamps,\n",
    "#         'Predicted Lunch Time': decoded_lunch_timestamps\n",
    "#     })\n",
    "\n",
    "#     return decoded_predictions\n",
    "\n",
    "# # Extract rows with missing breakfast or lunch times\n",
    "# missing_data = cgm_train[cgm_train['Breakfast Time'].isna() | cgm_train['Lunch Time'].isna()]\n",
    "\n",
    "# # Ensure that `Padded CGM Levels` is included in `missing_data`\n",
    "# predict_missing = missing_data['Padded CGM Levels']\n",
    "# missing_data_copy = missing_data.copy()\n",
    "\n",
    "# # Make predictions for missing breakfast and lunch times\n",
    "# predicted_times = predict_meal_times(model, predict_missing)\n",
    "\n",
    "# # Reset indices for both DataFrames to align by row order\n",
    "# missing_data_copy = missing_data_copy.reset_index(drop=True)\n",
    "# predicted_times = predicted_times.reset_index(drop=True)\n",
    "\n",
    "# # Add the 'Predicted Breakfast Time' column\n",
    "# missing_data_copy['Predicted Breakfast Time'] = predicted_times['Predicted Breakfast Time']\n",
    "# missing_data_copy['Predicted Lunch Time'] = predicted_times['Predicted Lunch Time']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Process Viome Data (Demographic Data) - COMPLETE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split Viome data into individual features.  \n",
    "Encoded categorical value of race, gender and diabetes status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_viome(data):\n",
    "    # Split the `Viome` column into individual features\n",
    "    viome_split = data['Viome'].str.split(',', expand=True).astype(float)\n",
    "    viome_split.columns = [f\"Viome_{i}\" for i in range(viome_split.shape[1])]\n",
    "    data = pd.concat([data.drop(columns=['Viome']), viome_split], axis=1)\n",
    "\n",
    "    # Impute missing values for numeric columns\n",
    "    numeric_cols = data.select_dtypes(include=[np.number]).columns.drop('Subject ID')\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    data[numeric_cols] = imputer.fit_transform(data[numeric_cols])\n",
    "\n",
    "    # Encode categorical columns\n",
    "    categorical_cols = ['Race', 'Diabetes Status']\n",
    "    encoder = OneHotEncoder(sparse_output=False, drop='first') \n",
    "    encoded_cats = pd.DataFrame(\n",
    "        encoder.fit_transform(data[categorical_cols]),\n",
    "        columns=encoder.get_feature_names_out(categorical_cols)\n",
    "    )\n",
    "\n",
    "    # Drop original categorical columns and merge encoded ones\n",
    "    data = pd.concat([data.drop(columns=categorical_cols), encoded_cats], axis=1)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject ID</th>\n",
       "      <th>Day</th>\n",
       "      <th>Image Before Breakfast</th>\n",
       "      <th>Image Before Lunch</th>\n",
       "      <th>Breakfast Time</th>\n",
       "      <th>Lunch Time</th>\n",
       "      <th>CGM Data</th>\n",
       "      <th>Lunch Calories</th>\n",
       "      <th>Time Between Meals</th>\n",
       "      <th>Age</th>\n",
       "      <th>...</th>\n",
       "      <th>Viome_21</th>\n",
       "      <th>Viome_22</th>\n",
       "      <th>Viome_23</th>\n",
       "      <th>Viome_24</th>\n",
       "      <th>Viome_25</th>\n",
       "      <th>Viome_26</th>\n",
       "      <th>Race_Hispanic/Latino</th>\n",
       "      <th>Race_White</th>\n",
       "      <th>Diabetes Status_2.0</th>\n",
       "      <th>Diabetes Status_3.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[[[0.5490196078431373, 0.47843137254901963, 0....</td>\n",
       "      <td>[[[0.1607843137254902, 0.596078431372549, 0.78...</td>\n",
       "      <td>2021-09-19 08:41:00</td>\n",
       "      <td>2021-09-19 12:24:00</td>\n",
       "      <td>[('2021-09-19 08:20:00', 98.26666666666667), (...</td>\n",
       "      <td>830</td>\n",
       "      <td>13380.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.773843</td>\n",
       "      <td>-0.125457</td>\n",
       "      <td>-0.352396</td>\n",
       "      <td>-0.241578</td>\n",
       "      <td>-0.135894</td>\n",
       "      <td>-0.164389</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>[[[0.2627450980392157, 0.22745098039215686, 0....</td>\n",
       "      <td>[[[0.1568627450980392, 0.23137254901960785, 0....</td>\n",
       "      <td>2021-09-20 09:50:00</td>\n",
       "      <td>2021-09-20 15:20:00</td>\n",
       "      <td>[('2021-09-20 09:10:00', 97.18333333333334), (...</td>\n",
       "      <td>435</td>\n",
       "      <td>19800.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.773843</td>\n",
       "      <td>-0.125457</td>\n",
       "      <td>-0.352396</td>\n",
       "      <td>-0.241578</td>\n",
       "      <td>-0.135894</td>\n",
       "      <td>-0.164389</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>[[[0.7803921568627451, 0.7647058823529411, 0.7...</td>\n",
       "      <td>[[[0.20784313725490197, 0.17254901960784313, 0...</td>\n",
       "      <td>2021-09-21 09:34:00</td>\n",
       "      <td>2021-09-21 13:09:00</td>\n",
       "      <td>[('2021-09-21 09:20:00', 107.36666666666666), ...</td>\n",
       "      <td>555</td>\n",
       "      <td>12900.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.773843</td>\n",
       "      <td>-0.125457</td>\n",
       "      <td>-0.352396</td>\n",
       "      <td>-0.241578</td>\n",
       "      <td>-0.135894</td>\n",
       "      <td>-0.164389</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>[[[0.5843137254901961, 0.4745098039215686, 0.3...</td>\n",
       "      <td>[[[0.11764705882352941, 0.10980392156862745, 0...</td>\n",
       "      <td>2021-09-22 09:46:00</td>\n",
       "      <td>2021-09-22 13:50:00</td>\n",
       "      <td>[('2021-09-22 09:25:00', 107.28333333333333), ...</td>\n",
       "      <td>355</td>\n",
       "      <td>14640.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.773843</td>\n",
       "      <td>-0.125457</td>\n",
       "      <td>-0.352396</td>\n",
       "      <td>-0.241578</td>\n",
       "      <td>-0.135894</td>\n",
       "      <td>-0.164389</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>[[[0.6862745098039216, 0.7215686274509804, 0.7...</td>\n",
       "      <td>[[[0.2901960784313726, 0.3333333333333333, 0.3...</td>\n",
       "      <td>2021-09-23 09:07:00</td>\n",
       "      <td>2021-09-23 13:17:00</td>\n",
       "      <td>[('2021-09-23 08:55:00', 103.0), ('2021-09-23 ...</td>\n",
       "      <td>1180</td>\n",
       "      <td>15000.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.773843</td>\n",
       "      <td>-0.125457</td>\n",
       "      <td>-0.352396</td>\n",
       "      <td>-0.241578</td>\n",
       "      <td>-0.135894</td>\n",
       "      <td>-0.164389</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>[[[0.26666666666666666, 0.13333333333333333, 0...</td>\n",
       "      <td>[[[0.35294117647058826, 0.30196078431372547, 0...</td>\n",
       "      <td>2021-12-18 08:52:00</td>\n",
       "      <td>2021-12-18 12:28:00</td>\n",
       "      <td>[('2021-12-18 08:50:00', 101.36), ('2021-12-18...</td>\n",
       "      <td>1180</td>\n",
       "      <td>12960.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.179446</td>\n",
       "      <td>0.263283</td>\n",
       "      <td>0.491576</td>\n",
       "      <td>0.502913</td>\n",
       "      <td>-0.141314</td>\n",
       "      <td>-0.414110</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>[[[0.10196078431372549, 0.10196078431372549, 0...</td>\n",
       "      <td>[[[0.06666666666666667, 0.03529411764705882, 0...</td>\n",
       "      <td>2021-12-19 08:43:00</td>\n",
       "      <td>2021-12-19 13:13:00</td>\n",
       "      <td>[('2021-12-19 08:40:00', 100.68), ('2021-12-19...</td>\n",
       "      <td>830</td>\n",
       "      <td>16200.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.179446</td>\n",
       "      <td>0.263283</td>\n",
       "      <td>0.491576</td>\n",
       "      <td>0.502913</td>\n",
       "      <td>-0.141314</td>\n",
       "      <td>-0.414110</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>[[[0.16862745098039217, 0.1450980392156863, 0....</td>\n",
       "      <td>[[[0.47843137254901963, 0.4235294117647059, 0....</td>\n",
       "      <td>2021-12-20 09:06:00</td>\n",
       "      <td>2021-12-20 12:46:00</td>\n",
       "      <td>[('2021-12-20 09:00:00', 104.04), ('2021-12-20...</td>\n",
       "      <td>435</td>\n",
       "      <td>13200.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.179446</td>\n",
       "      <td>0.263283</td>\n",
       "      <td>0.491576</td>\n",
       "      <td>0.502913</td>\n",
       "      <td>-0.141314</td>\n",
       "      <td>-0.414110</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>[[[0.1607843137254902, 0.14901960784313725, 0....</td>\n",
       "      <td>[[[0.23137254901960785, 0.1803921568627451, 0....</td>\n",
       "      <td>2021-12-21 08:34:00</td>\n",
       "      <td>2021-12-21 12:38:00</td>\n",
       "      <td>[('2021-12-21 08:25:00', 96.4), ('2021-12-21 0...</td>\n",
       "      <td>555</td>\n",
       "      <td>14640.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.179446</td>\n",
       "      <td>0.263283</td>\n",
       "      <td>0.491576</td>\n",
       "      <td>0.502913</td>\n",
       "      <td>-0.141314</td>\n",
       "      <td>-0.414110</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>[[[0.45098039215686275, 0.35294117647058826, 0...</td>\n",
       "      <td>[[[0.25882352941176473, 0.20784313725490197, 0...</td>\n",
       "      <td>2021-12-22 08:44:00</td>\n",
       "      <td>2021-12-22 12:34:00</td>\n",
       "      <td>[('2021-12-22 08:35:00', 96.68), ('2021-12-22 ...</td>\n",
       "      <td>355</td>\n",
       "      <td>13800.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.179446</td>\n",
       "      <td>0.263283</td>\n",
       "      <td>0.491576</td>\n",
       "      <td>0.502913</td>\n",
       "      <td>-0.141314</td>\n",
       "      <td>-0.414110</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>319 rows Ã— 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Subject ID  Day                             Image Before Breakfast  \\\n",
       "0             1    2  [[[0.5490196078431373, 0.47843137254901963, 0....   \n",
       "1             1    3  [[[0.2627450980392157, 0.22745098039215686, 0....   \n",
       "2             1    4  [[[0.7803921568627451, 0.7647058823529411, 0.7...   \n",
       "3             1    5  [[[0.5843137254901961, 0.4745098039215686, 0.3...   \n",
       "4             1    6  [[[0.6862745098039216, 0.7215686274509804, 0.7...   \n",
       "..          ...  ...                                                ...   \n",
       "314           7    6  [[[0.26666666666666666, 0.13333333333333333, 0...   \n",
       "315           7    7  [[[0.10196078431372549, 0.10196078431372549, 0...   \n",
       "316           7    8  [[[0.16862745098039217, 0.1450980392156863, 0....   \n",
       "317           7    9  [[[0.1607843137254902, 0.14901960784313725, 0....   \n",
       "318           7   10  [[[0.45098039215686275, 0.35294117647058826, 0...   \n",
       "\n",
       "                                    Image Before Lunch      Breakfast Time  \\\n",
       "0    [[[0.1607843137254902, 0.596078431372549, 0.78... 2021-09-19 08:41:00   \n",
       "1    [[[0.1568627450980392, 0.23137254901960785, 0.... 2021-09-20 09:50:00   \n",
       "2    [[[0.20784313725490197, 0.17254901960784313, 0... 2021-09-21 09:34:00   \n",
       "3    [[[0.11764705882352941, 0.10980392156862745, 0... 2021-09-22 09:46:00   \n",
       "4    [[[0.2901960784313726, 0.3333333333333333, 0.3... 2021-09-23 09:07:00   \n",
       "..                                                 ...                 ...   \n",
       "314  [[[0.35294117647058826, 0.30196078431372547, 0... 2021-12-18 08:52:00   \n",
       "315  [[[0.06666666666666667, 0.03529411764705882, 0... 2021-12-19 08:43:00   \n",
       "316  [[[0.47843137254901963, 0.4235294117647059, 0.... 2021-12-20 09:06:00   \n",
       "317  [[[0.23137254901960785, 0.1803921568627451, 0.... 2021-12-21 08:34:00   \n",
       "318  [[[0.25882352941176473, 0.20784313725490197, 0... 2021-12-22 08:44:00   \n",
       "\n",
       "             Lunch Time                                           CGM Data  \\\n",
       "0   2021-09-19 12:24:00  [('2021-09-19 08:20:00', 98.26666666666667), (...   \n",
       "1   2021-09-20 15:20:00  [('2021-09-20 09:10:00', 97.18333333333334), (...   \n",
       "2   2021-09-21 13:09:00  [('2021-09-21 09:20:00', 107.36666666666666), ...   \n",
       "3   2021-09-22 13:50:00  [('2021-09-22 09:25:00', 107.28333333333333), ...   \n",
       "4   2021-09-23 13:17:00  [('2021-09-23 08:55:00', 103.0), ('2021-09-23 ...   \n",
       "..                  ...                                                ...   \n",
       "314 2021-12-18 12:28:00  [('2021-12-18 08:50:00', 101.36), ('2021-12-18...   \n",
       "315 2021-12-19 13:13:00  [('2021-12-19 08:40:00', 100.68), ('2021-12-19...   \n",
       "316 2021-12-20 12:46:00  [('2021-12-20 09:00:00', 104.04), ('2021-12-20...   \n",
       "317 2021-12-21 12:38:00  [('2021-12-21 08:25:00', 96.4), ('2021-12-21 0...   \n",
       "318 2021-12-22 12:34:00  [('2021-12-22 08:35:00', 96.68), ('2021-12-22 ...   \n",
       "\n",
       "     Lunch Calories  Time Between Meals   Age  ...  Viome_21  Viome_22  \\\n",
       "0               830             13380.0  27.0  ...  0.773843 -0.125457   \n",
       "1               435             19800.0  27.0  ...  0.773843 -0.125457   \n",
       "2               555             12900.0  27.0  ...  0.773843 -0.125457   \n",
       "3               355             14640.0  27.0  ...  0.773843 -0.125457   \n",
       "4              1180             15000.0  27.0  ...  0.773843 -0.125457   \n",
       "..              ...                 ...   ...  ...       ...       ...   \n",
       "314            1180             12960.0  66.0  ... -0.179446  0.263283   \n",
       "315             830             16200.0  66.0  ... -0.179446  0.263283   \n",
       "316             435             13200.0  66.0  ... -0.179446  0.263283   \n",
       "317             555             14640.0  66.0  ... -0.179446  0.263283   \n",
       "318             355             13800.0  66.0  ... -0.179446  0.263283   \n",
       "\n",
       "     Viome_23  Viome_24  Viome_25  Viome_26  Race_Hispanic/Latino  Race_White  \\\n",
       "0   -0.352396 -0.241578 -0.135894 -0.164389                   1.0         0.0   \n",
       "1   -0.352396 -0.241578 -0.135894 -0.164389                   1.0         0.0   \n",
       "2   -0.352396 -0.241578 -0.135894 -0.164389                   1.0         0.0   \n",
       "3   -0.352396 -0.241578 -0.135894 -0.164389                   1.0         0.0   \n",
       "4   -0.352396 -0.241578 -0.135894 -0.164389                   1.0         0.0   \n",
       "..        ...       ...       ...       ...                   ...         ...   \n",
       "314  0.491576  0.502913 -0.141314 -0.414110                   1.0         0.0   \n",
       "315  0.491576  0.502913 -0.141314 -0.414110                   1.0         0.0   \n",
       "316  0.491576  0.502913 -0.141314 -0.414110                   1.0         0.0   \n",
       "317  0.491576  0.502913 -0.141314 -0.414110                   1.0         0.0   \n",
       "318  0.491576  0.502913 -0.141314 -0.414110                   1.0         0.0   \n",
       "\n",
       "     Diabetes Status_2.0  Diabetes Status_3.0  \n",
       "0                    0.0                  0.0  \n",
       "1                    0.0                  0.0  \n",
       "2                    0.0                  0.0  \n",
       "3                    0.0                  0.0  \n",
       "4                    0.0                  0.0  \n",
       "..                   ...                  ...  \n",
       "314                  1.0                  0.0  \n",
       "315                  1.0                  0.0  \n",
       "316                  1.0                  0.0  \n",
       "317                  1.0                  0.0  \n",
       "318                  1.0                  0.0  \n",
       "\n",
       "[319 rows x 56 columns]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo_viome_train = preprocess_viome(demo_viome_train)\n",
    "final_data = pd.merge(data_train, demo_viome_train, on=['Subject ID'])\n",
    "\n",
    "final_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensionality Reduction - PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of components to explain 90% variance: 22\n"
     ]
    }
   ],
   "source": [
    "# Normalize all numerical data\n",
    "numeric_cols = final_data.select_dtypes(include=[np.number]).columns.difference(['Subject ID', 'Day', 'Lunch Calories'])\n",
    "scaler = StandardScaler()\n",
    "final_data[numeric_cols] = scaler.fit_transform(final_data[numeric_cols])\n",
    "\n",
    "# Perform PCA\n",
    "pca = PCA()\n",
    "X_pca = pca.fit_transform(final_data[numeric_cols])\n",
    "\n",
    "# Select the number of components that explain at least 90% of the variance\n",
    "n_components = sum(pca.explained_variance_ratio_.cumsum() <= 0.90)\n",
    "print(f\"Number of components to explain 90% variance: {n_components}\")\n",
    "\n",
    "# Apply PCA with the selected number of components\n",
    "pca = PCA(n_components=n_components)\n",
    "X_reduced = pca.fit_transform(final_data[numeric_cols])\n",
    "\n",
    "# Create a DataFrame with reduced features, preserving the component names\n",
    "columns = [f\"PC{i+1}\" for i in range(n_components)]\n",
    "reduced_df = pd.DataFrame(X_reduced, columns=columns, index=final_data.index)\n",
    "\n",
    "# Select non-numerical and excluded columns from the original data\n",
    "excluded_cols = final_data.drop(columns=numeric_cols)\n",
    "\n",
    "# Combine reduced features with the excluded columns, keeping column names intact\n",
    "final_data = pd.concat([excluded_cols, reduced_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Subject ID', 'Day', 'Image Before Breakfast', 'Image Before Lunch',\n",
       "       'Breakfast Time', 'Lunch Time', 'CGM Data', 'Lunch Calories', 'PC1',\n",
       "       'PC2', 'PC3', 'PC4', 'PC5', 'PC6', 'PC7', 'PC8', 'PC9', 'PC10', 'PC11',\n",
       "       'PC12', 'PC13', 'PC14', 'PC15', 'PC16', 'PC17', 'PC18', 'PC19', 'PC20',\n",
       "       'PC21', 'PC22'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multimodal dataset created for training combining breakfast and lunch images, cgm data and demographic data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultimodalDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        \n",
    "        # Convert images to tensors and permute dimensions to [batch, channels, height, width]\n",
    "        self.breakfast_images = torch.tensor(\n",
    "            np.stack(data['Image Before Breakfast'].values), \n",
    "            dtype=torch.float32\n",
    "        ).permute(0, 3, 1, 2)  # Change from NHWC to NCHW format\n",
    "        \n",
    "        self.lunch_images = torch.tensor(\n",
    "            np.stack(data['Image Before Lunch'].values), \n",
    "            dtype=torch.float32\n",
    "        ).permute(0, 3, 1, 2)  # Change from NHWC to NCHW format\n",
    "        \n",
    "        # Process CGM data\n",
    "        def process_cgm(x):\n",
    "            try:\n",
    "                if isinstance(x, str):\n",
    "                    clean_str = x.replace('[', '').replace(']', '').replace('\\n', '').replace(' ', '')\n",
    "                    if clean_str:\n",
    "                        values = [float(i) for i in clean_str.split(',') if i]\n",
    "                        if len(values) > 288:\n",
    "                            return values[:288]\n",
    "                        elif len(values) < 288:\n",
    "                            return values + [0.0] * (288 - len(values))\n",
    "                        return values\n",
    "                return [0.0] * 288\n",
    "            except:\n",
    "                return [0.0] * 288\n",
    "        \n",
    "        processed_cgm = []\n",
    "        for x in data['CGM Data'].values:\n",
    "            cgm_values = process_cgm(x)\n",
    "            processed_cgm.append(cgm_values)\n",
    "            \n",
    "        self.cgm_data = torch.tensor(processed_cgm, dtype=torch.float32)\n",
    "        \n",
    "        # Extract viome and demographic features\n",
    "        viome_cols = [col for col in data.columns if 'PC' in col]\n",
    "        demo_viome_features = data[viome_cols].values\n",
    "\n",
    "        # demo_cols = ['Age', 'Weight', 'Height', 'A1C', 'Baseline Fasting Glucose', \n",
    "        #              'Insulin', 'Triglycerides', 'Cholesterol', 'HDL', 'Non-HDL', \n",
    "        #              'LDL', 'VLDL', 'CHO/HDL Ratio', 'HOMA-IR', 'BMI']\n",
    "        \n",
    "        # demo_viome_features = data[viome_cols + demo_cols].values\n",
    "        self.demo_viome = torch.tensor(demo_viome_features, dtype=torch.float32)\n",
    "        \n",
    "        # Extract labels\n",
    "        self.labels = torch.tensor(data['Lunch Calories'].values, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'breakfast_img': self.breakfast_images[idx],\n",
    "            'lunch_img': self.lunch_images[idx],\n",
    "            'cgm': self.cgm_data[idx],\n",
    "            'demo_viome': self.demo_viome[idx],\n",
    "            'label': self.labels[idx]\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multimodal Model Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 layer CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultimodalNet(nn.Module):\n",
    "    def __init__(self, cgm_dim, demo_viome_dim):\n",
    "        super(MultimodalNet, self).__init__()\n",
    "        \n",
    "        # Image encoders (modified for correct dimensions)\n",
    "        self.image_encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),  # Input: [B, 3, 64, 64]\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),                             # Output: [B, 32, 32, 32]\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1), \n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),                             # Output: [B, 64, 16, 16]\n",
    "            nn.Flatten(),                                # Output: [B, 64 * 16 * 16]\n",
    "            nn.Linear(64 * 16 * 16, 256),               # Output: [B, 256]\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        # CGM encoder\n",
    "        self.cgm_encoder = nn.Sequential(\n",
    "            nn.Linear(288, 128),  # Assuming CGM length is 288\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Demo-Viome encoder\n",
    "        self.demo_viome_encoder = nn.Sequential(\n",
    "            nn.Linear(demo_viome_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # Joint embedding\n",
    "        self.fusion = nn.Sequential(\n",
    "            nn.Linear(256 * 2 + 64 + 32, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, breakfast_img, lunch_img, cgm, demo_viome):\n",
    "        # Ensure correct dimensions for images\n",
    "        if breakfast_img.dim() == 3:\n",
    "            breakfast_img = breakfast_img.unsqueeze(0)\n",
    "        if lunch_img.dim() == 3:\n",
    "            lunch_img = lunch_img.unsqueeze(0)\n",
    "            \n",
    "        # Encode images\n",
    "        breakfast_features = self.image_encoder(breakfast_img)\n",
    "        lunch_features = self.image_encoder(lunch_img)\n",
    "        \n",
    "        # Encode CGM\n",
    "        cgm_features = self.cgm_encoder(cgm)\n",
    "        \n",
    "        # Encode demo-viome\n",
    "        demo_viome_features = self.demo_viome_encoder(demo_viome)\n",
    "        \n",
    "        # Concatenate all features\n",
    "        combined = torch.cat([\n",
    "            breakfast_features, \n",
    "            lunch_features, \n",
    "            cgm_features, \n",
    "            demo_viome_features\n",
    "        ], dim=1)\n",
    "        \n",
    "        # Final prediction\n",
    "        output = self.fusion(combined)\n",
    "        return output.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RMSRELoss(nn.Module):\n",
    "    def __init__(self, eps=1e-6):\n",
    "        super(RMSRELoss, self).__init__()\n",
    "        self.eps = eps\n",
    "        \n",
    "    def forward(self, pred, target):\n",
    "        relative_error = (pred - target) / (target + self.eps)\n",
    "        rmsre = torch.sqrt(torch.mean(relative_error ** 2))\n",
    "        return rmsre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of breakfast images: (64, 64, 3)\n",
      "Number of Viome columns: 22\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of breakfast images:\", final_data['Image Before Breakfast'].iloc[0].shape)\n",
    "print(\"Number of Viome columns:\", len([col for col in final_data.columns if 'PC' in col]))\n",
    "\n",
    "dataset = MultimodalDataset(final_data)\n",
    "train_loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Initialize model\n",
    "cgm_dim = dataset.cgm_data.shape[1]  # Should be 288\n",
    "demo_viome_dim = dataset.demo_viome.shape[1] \n",
    "\n",
    "model = MultimodalNet(\n",
    "    cgm_dim=dataset.cgm_data.shape[1],\n",
    "    demo_viome_dim=dataset.demo_viome.shape[1]\n",
    ")\n",
    "\n",
    "# Initialize optimizer and loss function\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.002)\n",
    "criterion = RMSRELoss()\n",
    "\n",
    "# Training loop\n",
    "def train_epoch(model, loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for batch in loader:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        pred = model(\n",
    "            batch['breakfast_img'],\n",
    "            batch['lunch_img'],\n",
    "            batch['cgm'],\n",
    "            batch['demo_viome']\n",
    "        )\n",
    "        \n",
    "        loss = criterion(pred, batch['label'])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.8230\n",
      "Epoch 2, Loss: 0.3878\n",
      "Epoch 3, Loss: 0.3721\n",
      "Epoch 4, Loss: 0.3522\n",
      "Epoch 5, Loss: 0.3448\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    loss = train_epoch(model, train_loader, optimizer, criterion)\n",
    "    print(f'Epoch {epoch+1}, Loss: {loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 48)\n",
      "(73, 54)\n",
      "(73, 29)\n"
     ]
    }
   ],
   "source": [
    "# Prepare test data\n",
    "temp_test_data = pd.merge(image_test, cgm_test, on=['Subject ID', 'Day'])\n",
    "processed_test_data = preprocess_img(temp_test_data).drop(columns=['Breakfast Time', 'Lunch Time'])\n",
    "# processed_test_data = preprocess_cgm(processed_test_data)\n",
    "demo_viome_test = preprocess_viome(demo_viome_test)\n",
    "print(demo_viome_test.shape)\n",
    "test_data = pd.merge(processed_test_data, demo_viome_test, on=['Subject ID'])\n",
    "print(test_data.shape)\n",
    "\n",
    "# Normalize all numerical data\n",
    "numeric_cols = test_data.select_dtypes(include=[np.number]).columns.difference(['Subject ID', 'Day', 'Lunch Calories'])\n",
    "test_data[numeric_cols] = scaler.fit_transform(test_data[numeric_cols])\n",
    "\n",
    "# Perform PCA\n",
    "X_test_pca = pca.fit_transform(test_data[numeric_cols])\n",
    "\n",
    "# Apply PCA with the selected number of components\n",
    "X_test_reduced = pca.fit_transform(test_data[numeric_cols])\n",
    "\n",
    "# Create a DataFrame with reduced features, preserving the component names\n",
    "columns = [f\"PC{i+1}\" for i in range(n_components)]\n",
    "reduced_df = pd.DataFrame(X_test_reduced, columns=columns, index=test_data.index)\n",
    "\n",
    "# Select non-numerical and excluded columns from the original data\n",
    "excluded_cols = test_data.drop(columns=numeric_cols)\n",
    "\n",
    "# Combine reduced features with the excluded columns, keeping column names intact\n",
    "final_test_data = pd.concat([excluded_cols, reduced_df], axis=1)\n",
    "\n",
    "print(final_test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 64, 64])\n",
      "torch.Size([4, 3, 64, 64])\n",
      "torch.Size([4, 22])\n"
     ]
    }
   ],
   "source": [
    "# Test Dataset Class\n",
    "class MultimodalTestDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.breakfast_images = torch.tensor(\n",
    "            np.stack(data['Image Before Breakfast'].values), dtype=torch.float32\n",
    "        ).permute(0, 3, 1, 2)\n",
    "        self.lunch_images = torch.tensor(\n",
    "            np.stack(data['Image Before Lunch'].values), dtype=torch.float32\n",
    "        ).permute(0, 3, 1, 2)\n",
    "\n",
    "        viome_cols = [col for col in data.columns if 'PC' in col]\n",
    "        demo_viome_features = data[viome_cols].values\n",
    "        self.demo_viome = torch.tensor(demo_viome_features, dtype=torch.float32)\n",
    "\n",
    "        # demo_cols = ['Age', 'Weight', 'Height', 'A1C', 'Baseline Fasting Glucose', \n",
    "        #              'Insulin', 'Triglycerides', 'Cholesterol', 'HDL', 'Non-HDL', \n",
    "        #              'LDL', 'VLDL', 'CHO/HDL Ratio', 'HOMA-IR', 'BMI']\n",
    "        # demo_viome_features = data[viome_cols + demo_cols].values\n",
    "        # self.demo_viome = torch.tensor(demo_viome_features, dtype=torch.float32)\n",
    "            \n",
    "        def process_cgm(x):\n",
    "            try:\n",
    "                if isinstance(x, str):\n",
    "                    clean_str = x.replace('[', '').replace(']', '').replace('\\n', '').replace(' ', '')\n",
    "                    if clean_str:\n",
    "                        values = [float(i) for i in clean_str.split(',') if i]\n",
    "                        if len(values) > 288:\n",
    "                            return values[:288]\n",
    "                        elif len(values) < 288:\n",
    "                            return values + [0.0] * (288 - len(values))\n",
    "                        return values\n",
    "                return [0.0] * 288\n",
    "            except:\n",
    "                return [0.0] * 288\n",
    "        \n",
    "        processed_cgm = []\n",
    "        for x in data['CGM Data'].values:\n",
    "            cgm_values = process_cgm(x)\n",
    "            processed_cgm.append(cgm_values)\n",
    "            \n",
    "        self.cgm_data = torch.tensor(processed_cgm, dtype=torch.float32)\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'breakfast_img': self.breakfast_images[idx],\n",
    "            'lunch_img': self.lunch_images[idx],\n",
    "            'cgm': self.cgm_data[idx],\n",
    "            'demo_viome': self.demo_viome[idx]\n",
    "        }\n",
    "\n",
    "# Example usage for test data\n",
    "test_dataset = MultimodalTestDataset(final_test_data)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=4, shuffle=False)\n",
    "\n",
    "# Iterating through the test DataLoader\n",
    "for batch in test_dataloader:\n",
    "    print(batch['breakfast_img'].shape)\n",
    "    print(batch['lunch_img'].shape)\n",
    "    print(batch['demo_viome'].shape)\n",
    "    print\n",
    "    break  # Just show one batch for brevity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, data_loader, criterion):\n",
    "    \"\"\"\n",
    "    Evaluates the model on a given dataset.\n",
    "    \n",
    "    Args:\n",
    "        model (nn.Module): The trained multimodal model.\n",
    "        data_loader (DataLoader): DataLoader containing the test/validation dataset.\n",
    "        criterion (nn.Module): Loss function used for evaluation.\n",
    "        \n",
    "    Returns:\n",
    "        float: The average loss over the dataset.\n",
    "        list: Predicted values for the dataset.\n",
    "        list: Ground truth values for the dataset.\n",
    "    \"\"\"\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    total_loss = 0\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient computation for evaluation\n",
    "        for batch in data_loader:\n",
    "            # Extract input features and labels from the batch\n",
    "            breakfast_img = batch['breakfast_img']\n",
    "            lunch_img = batch['lunch_img']\n",
    "            cgm = batch['cgm']\n",
    "            demo_viome = batch['demo_viome']\n",
    "            \n",
    "            # Forward pass through the model\n",
    "            outputs = model(breakfast_img, lunch_img, cgm, demo_viome)\n",
    "            print(outputs)\n",
    "            # Compute the loss\n",
    "            # loss = criterion(outputs, labels)\n",
    "            # total_loss += loss.item()\n",
    "            if outputs.dim() == 0:  # Scalar tensor\n",
    "                predictions.append(outputs.item())  # Convert scalar to Python float and append\n",
    "            elif outputs.dim() == 1:  # 1D tensor\n",
    "                predictions.extend(outputs.cpu().numpy().tolist()) \n",
    "            # Store predictions and true labels for later analysis\n",
    "            # predictions.extend(outputs.cpu().numpy())\n",
    "            # true_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    # Calculate the average loss\n",
    "    # average_loss = total_loss / len(data_loader)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x1fef5231fd0>"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([491.5707, 512.7244, 475.1385, 481.6491])\n",
      "tensor([511.4363, 463.5124, 506.5764, 503.0213])\n",
      "tensor([490.7001, 472.1819, 498.9342, 456.2516])\n",
      "tensor([482.2861, 511.5241, 498.3384, 504.6321])\n",
      "tensor([470.7960, 484.8428, 488.8864, 459.4357])\n",
      "tensor([528.4476, 528.6655, 522.1774, 508.0132])\n",
      "tensor([497.6235, 520.4547, 451.4596, 486.6229])\n",
      "tensor([504.6050, 495.8683, 480.0132, 446.4283])\n",
      "tensor([482.3800, 484.6467, 487.2083, 468.7929])\n",
      "tensor([504.7418, 447.9373, 478.9869, 499.1167])\n",
      "tensor([519.6929, 471.6568, 511.3696, 497.0445])\n",
      "tensor([470.6676, 441.7014, 462.1342, 483.9120])\n",
      "tensor([536.1730, 504.4230, 499.6394, 461.2311])\n",
      "tensor([462.5667, 515.9330, 480.7739, 507.3439])\n",
      "tensor([535.3418, 469.0012, 486.5817, 511.2068])\n",
      "tensor([493.5347, 474.7438, 478.7812, 489.0830])\n",
      "tensor([482.1906, 517.0590, 491.7988, 488.7464])\n",
      "tensor([547.8935, 502.8844, 483.9938, 474.8955])\n",
      "tensor(467.7475)\n"
     ]
    }
   ],
   "source": [
    "# Example: Evaluate the model on a validation/test dataset\n",
    "# test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)  # Use your test dataset here\n",
    "\n",
    "# Evaluate the model\n",
    "test_predictions = evaluate_model(model, test_dataloader, criterion)\n",
    "\n",
    "# # Print results\n",
    "# print(f\"Test Loss: {test_loss:.4f}\")\n",
    "\n",
    "# # Optionally, analyze predictions and ground truth\n",
    "# for i, (pred, true) in enumerate(zip(test_predictions[:5], test_labels[:5])):\n",
    "#     print(f\"Sample {i + 1}: Predicted: {pred:.2f}, True: {true:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to test_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    'row_id': range(len(test_predictions)),\n",
    "    'label': test_predictions\n",
    "})\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "output_file = \"test_predictions.csv\"\n",
    "df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Predictions saved to {output_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
