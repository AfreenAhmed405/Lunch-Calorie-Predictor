{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import ast\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import torch.nn as nn\n",
    "import keras.backend as K\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import GRU, Dense, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications import ResNet50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Merge Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Datasets\n",
    "\n",
    "# Training datasets\n",
    "cgm_train = pd.read_csv('cgm_train.csv')\n",
    "image_train = pd.read_csv('img_train.csv')\n",
    "demo_viome_train = pd.read_csv('demo_viome_train.csv')\n",
    "label_train = pd.read_csv('label_train.csv')\n",
    "\n",
    "# Test datasets\n",
    "cgm_test = pd.read_csv('cgm_test.csv')\n",
    "image_test = pd.read_csv('img_test.csv')\n",
    "demo_viome_test = pd.read_csv('demo_viome_test.csv')\n",
    "label_test = pd.read_csv('label_test_breakfast_only.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge CGM and Image datasets\n",
    "data_train = pd.merge(image_train, cgm_train, on=['Subject ID', 'Day'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject ID</th>\n",
       "      <th>Day</th>\n",
       "      <th>Image Before Breakfast</th>\n",
       "      <th>Image Before Lunch</th>\n",
       "      <th>Breakfast Time</th>\n",
       "      <th>Lunch Time</th>\n",
       "      <th>CGM Data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[[[140, 122, 108], [135, 118, 104], [118, 104,...</td>\n",
       "      <td>[[[41, 152, 201], [77, 164, 205], [88, 157, 13...</td>\n",
       "      <td>2021-09-19 08:41:00</td>\n",
       "      <td>2021-09-19 12:24:00</td>\n",
       "      <td>[('2021-09-19 08:20:00', 98.26666666666667), (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>[[[67, 58, 47], [59, 52, 41], [51, 45, 35], [4...</td>\n",
       "      <td>[[[40, 59, 77], [35, 56, 72], [20, 36, 47], [9...</td>\n",
       "      <td>2021-09-20 09:50:00</td>\n",
       "      <td>2021-09-20 15:20:00</td>\n",
       "      <td>[('2021-09-20 09:10:00', 97.18333333333334), (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>[[[199, 195, 193], [198, 193, 192], [196, 192,...</td>\n",
       "      <td>[[[53, 44, 38], [51, 43, 36], [54, 47, 39], [4...</td>\n",
       "      <td>2021-09-21 09:34:00</td>\n",
       "      <td>2021-09-21 13:09:00</td>\n",
       "      <td>[('2021-09-21 09:20:00', 107.36666666666666), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>[[[149, 121, 80], [157, 128, 86], [159, 130, 8...</td>\n",
       "      <td>[[[30, 28, 28], [20, 18, 17], [31, 27, 23], [2...</td>\n",
       "      <td>2021-09-22 09:46:00</td>\n",
       "      <td>2021-09-22 13:50:00</td>\n",
       "      <td>[('2021-09-22 09:25:00', 107.28333333333333), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>[[[175, 184, 198], [192, 206, 219], [160, 165,...</td>\n",
       "      <td>[[[74, 85, 100], [59, 69, 81], [73, 84, 96], [...</td>\n",
       "      <td>2021-09-23 09:07:00</td>\n",
       "      <td>2021-09-23 13:17:00</td>\n",
       "      <td>[('2021-09-23 08:55:00', 103.0), ('2021-09-23 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>[[[68, 34, 35], [82, 60, 51], [63, 55, 38], [3...</td>\n",
       "      <td>[[[90, 77, 75], [92, 78, 75], [94, 83, 81], [9...</td>\n",
       "      <td>2021-12-18 08:52:00</td>\n",
       "      <td>2021-12-18 12:28:00</td>\n",
       "      <td>[('2021-12-18 08:50:00', 101.36), ('2021-12-18...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>[[[26, 26, 22], [17, 17, 13], [18, 19, 14], [9...</td>\n",
       "      <td>[[[17, 9, 8], [10, 7, 7], [3, 3, 4], [3, 3, 3]...</td>\n",
       "      <td>2021-12-19 08:43:00</td>\n",
       "      <td>2021-12-19 13:13:00</td>\n",
       "      <td>[('2021-12-19 08:40:00', 100.68), ('2021-12-19...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>[[[43, 37, 33], [42, 36, 31], [42, 37, 33], [4...</td>\n",
       "      <td>[[[122, 108, 107], [124, 110, 108], [124, 111,...</td>\n",
       "      <td>2021-12-20 09:06:00</td>\n",
       "      <td>2021-12-20 12:46:00</td>\n",
       "      <td>[('2021-12-20 09:00:00', 104.04), ('2021-12-20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>[[[41, 38, 33], [41, 38, 33], [41, 38, 33], [4...</td>\n",
       "      <td>[[[59, 46, 32], [63, 51, 41], [57, 42, 28], [6...</td>\n",
       "      <td>2021-12-21 08:34:00</td>\n",
       "      <td>2021-12-21 12:38:00</td>\n",
       "      <td>[('2021-12-21 08:25:00', 96.4), ('2021-12-21 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>[[[115, 90, 85], [115, 90, 86], [111, 86, 82],...</td>\n",
       "      <td>[[[66, 53, 44], [77, 67, 62], [70, 57, 48], [6...</td>\n",
       "      <td>2021-12-22 08:44:00</td>\n",
       "      <td>2021-12-22 12:34:00</td>\n",
       "      <td>[('2021-12-22 08:35:00', 96.68), ('2021-12-22 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>324 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Subject ID  Day                             Image Before Breakfast  \\\n",
       "0             1    2  [[[140, 122, 108], [135, 118, 104], [118, 104,...   \n",
       "1             1    3  [[[67, 58, 47], [59, 52, 41], [51, 45, 35], [4...   \n",
       "2             1    4  [[[199, 195, 193], [198, 193, 192], [196, 192,...   \n",
       "3             1    5  [[[149, 121, 80], [157, 128, 86], [159, 130, 8...   \n",
       "4             1    6  [[[175, 184, 198], [192, 206, 219], [160, 165,...   \n",
       "..          ...  ...                                                ...   \n",
       "319           7    6  [[[68, 34, 35], [82, 60, 51], [63, 55, 38], [3...   \n",
       "320           7    7  [[[26, 26, 22], [17, 17, 13], [18, 19, 14], [9...   \n",
       "321           7    8  [[[43, 37, 33], [42, 36, 31], [42, 37, 33], [4...   \n",
       "322           7    9  [[[41, 38, 33], [41, 38, 33], [41, 38, 33], [4...   \n",
       "323           7   10  [[[115, 90, 85], [115, 90, 86], [111, 86, 82],...   \n",
       "\n",
       "                                    Image Before Lunch       Breakfast Time  \\\n",
       "0    [[[41, 152, 201], [77, 164, 205], [88, 157, 13...  2021-09-19 08:41:00   \n",
       "1    [[[40, 59, 77], [35, 56, 72], [20, 36, 47], [9...  2021-09-20 09:50:00   \n",
       "2    [[[53, 44, 38], [51, 43, 36], [54, 47, 39], [4...  2021-09-21 09:34:00   \n",
       "3    [[[30, 28, 28], [20, 18, 17], [31, 27, 23], [2...  2021-09-22 09:46:00   \n",
       "4    [[[74, 85, 100], [59, 69, 81], [73, 84, 96], [...  2021-09-23 09:07:00   \n",
       "..                                                 ...                  ...   \n",
       "319  [[[90, 77, 75], [92, 78, 75], [94, 83, 81], [9...  2021-12-18 08:52:00   \n",
       "320  [[[17, 9, 8], [10, 7, 7], [3, 3, 4], [3, 3, 3]...  2021-12-19 08:43:00   \n",
       "321  [[[122, 108, 107], [124, 110, 108], [124, 111,...  2021-12-20 09:06:00   \n",
       "322  [[[59, 46, 32], [63, 51, 41], [57, 42, 28], [6...  2021-12-21 08:34:00   \n",
       "323  [[[66, 53, 44], [77, 67, 62], [70, 57, 48], [6...  2021-12-22 08:44:00   \n",
       "\n",
       "              Lunch Time                                           CGM Data  \n",
       "0    2021-09-19 12:24:00  [('2021-09-19 08:20:00', 98.26666666666667), (...  \n",
       "1    2021-09-20 15:20:00  [('2021-09-20 09:10:00', 97.18333333333334), (...  \n",
       "2    2021-09-21 13:09:00  [('2021-09-21 09:20:00', 107.36666666666666), ...  \n",
       "3    2021-09-22 13:50:00  [('2021-09-22 09:25:00', 107.28333333333333), ...  \n",
       "4    2021-09-23 13:17:00  [('2021-09-23 08:55:00', 103.0), ('2021-09-23 ...  \n",
       "..                   ...                                                ...  \n",
       "319  2021-12-18 12:28:00  [('2021-12-18 08:50:00', 101.36), ('2021-12-18...  \n",
       "320  2021-12-19 13:13:00  [('2021-12-19 08:40:00', 100.68), ('2021-12-19...  \n",
       "321  2021-12-20 12:46:00  [('2021-12-20 09:00:00', 104.04), ('2021-12-20...  \n",
       "322  2021-12-21 12:38:00  [('2021-12-21 08:25:00', 96.4), ('2021-12-21 0...  \n",
       "323  2021-12-22 12:34:00  [('2021-12-22 08:35:00', 96.68), ('2021-12-22 ...  \n",
       "\n",
       "[324 rows x 7 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Process Food Pictures (Image Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_img(data_train):\n",
    "\n",
    "    # Load pretrained model\n",
    "    base_model = ResNet50(weights='imagenet', include_top=False, pooling='avg')\n",
    "    pca = PCA(n_components=10)\n",
    "    def extract_features(image):\n",
    "        image = np.expand_dims(image, axis=0)  # Add batch dimension\n",
    "        features = base_model.predict(image)\n",
    "        return features.flatten()  # Flatten the output\n",
    "        \n",
    "    # Preprocess for Breakfast image\n",
    "    image_before_breakfast_matrix = []\n",
    "    null_breakfast = []\n",
    "\n",
    "    for i in range(len(data_train)):\n",
    "        string_matrix = data_train['Image Before Breakfast'][i]\n",
    "        parsed_matrix = ast.literal_eval(string_matrix)\n",
    "        matrix_array = np.array(parsed_matrix)\n",
    "        print(f\"Matrix shape: {matrix_array.shape}, index: {i}\")\n",
    "        if matrix_array.shape == (0,):\n",
    "            null_breakfast.append(i)\n",
    "        image_before_breakfast_matrix.append(matrix_array)\n",
    "\n",
    "    data_train = data_train.drop(null_breakfast)\n",
    "    data_train = data_train.reset_index(drop=True)\n",
    "    a = [extract_features(image) for image in image_before_breakfast_matrix if image.size != 0]\n",
    "    reduced_features_a = pca.fit_transform(a)\n",
    "    data_train['Reduced_img_before_breakfast'] = [list(row) for row in reduced_features_a]\n",
    "\n",
    "    # Preprocess for Lunch image\n",
    "    image_before_lunch_matrix = []\n",
    "    null_lunch = []\n",
    "\n",
    "    for i in range(len(data_train)):\n",
    "        string_matrix = data_train['Image Before Lunch'][i]\n",
    "        parsed_matrix = ast.literal_eval(string_matrix)\n",
    "        matrix_array = np.array(parsed_matrix)\n",
    "        print(f\"Matrix shape: {matrix_array.shape}, index: {i}\")\n",
    "        if matrix_array.shape == (0,):\n",
    "            null_lunch.append(i)\n",
    "        image_before_lunch_matrix.append(matrix_array)\n",
    "\n",
    "    data_train = data_train.drop(null_lunch)\n",
    "    data_train = data_train.reset_index(drop=True)\n",
    "    b = [extract_features(image) for image in image_before_lunch_matrix if image.size != 0]\n",
    "    reduced_features_b = pca.fit_transform(b)\n",
    "    data_train['Reduced_img_before_lunch'] = [list(row) for row in reduced_features_b]\n",
    "    data_train.drop(columns=['Image Before Breakfast', 'Image Before Lunch'], axis=1, inplace=True)\n",
    "\n",
    "    return data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix shape: (64, 64, 3), index: 0\n",
      "Matrix shape: (64, 64, 3), index: 1\n",
      "Matrix shape: (64, 64, 3), index: 2\n",
      "Matrix shape: (64, 64, 3), index: 3\n",
      "Matrix shape: (64, 64, 3), index: 4\n",
      "Matrix shape: (64, 64, 3), index: 5\n",
      "Matrix shape: (64, 64, 3), index: 6\n",
      "Matrix shape: (64, 64, 3), index: 7\n",
      "Matrix shape: (64, 64, 3), index: 8\n",
      "Matrix shape: (64, 64, 3), index: 9\n",
      "Matrix shape: (64, 64, 3), index: 10\n",
      "Matrix shape: (64, 64, 3), index: 11\n",
      "Matrix shape: (64, 64, 3), index: 12\n",
      "Matrix shape: (64, 64, 3), index: 13\n",
      "Matrix shape: (64, 64, 3), index: 14\n",
      "Matrix shape: (64, 64, 3), index: 15\n",
      "Matrix shape: (64, 64, 3), index: 16\n",
      "Matrix shape: (64, 64, 3), index: 17\n",
      "Matrix shape: (64, 64, 3), index: 18\n",
      "Matrix shape: (64, 64, 3), index: 19\n",
      "Matrix shape: (64, 64, 3), index: 20\n",
      "Matrix shape: (64, 64, 3), index: 21\n",
      "Matrix shape: (64, 64, 3), index: 22\n",
      "Matrix shape: (64, 64, 3), index: 23\n",
      "Matrix shape: (64, 64, 3), index: 24\n",
      "Matrix shape: (64, 64, 3), index: 25\n",
      "Matrix shape: (64, 64, 3), index: 26\n",
      "Matrix shape: (64, 64, 3), index: 27\n",
      "Matrix shape: (64, 64, 3), index: 28\n",
      "Matrix shape: (64, 64, 3), index: 29\n",
      "Matrix shape: (64, 64, 3), index: 30\n",
      "Matrix shape: (64, 64, 3), index: 31\n",
      "Matrix shape: (64, 64, 3), index: 32\n",
      "Matrix shape: (64, 64, 3), index: 33\n",
      "Matrix shape: (64, 64, 3), index: 34\n",
      "Matrix shape: (64, 64, 3), index: 35\n",
      "Matrix shape: (64, 64, 3), index: 36\n",
      "Matrix shape: (64, 64, 3), index: 37\n",
      "Matrix shape: (64, 64, 3), index: 38\n",
      "Matrix shape: (64, 64, 3), index: 39\n",
      "Matrix shape: (64, 64, 3), index: 40\n",
      "Matrix shape: (64, 64, 3), index: 41\n",
      "Matrix shape: (64, 64, 3), index: 42\n",
      "Matrix shape: (0,), index: 43\n",
      "Matrix shape: (0,), index: 44\n",
      "Matrix shape: (64, 64, 3), index: 45\n",
      "Matrix shape: (64, 64, 3), index: 46\n",
      "Matrix shape: (64, 64, 3), index: 47\n",
      "Matrix shape: (64, 64, 3), index: 48\n",
      "Matrix shape: (64, 64, 3), index: 49\n",
      "Matrix shape: (64, 64, 3), index: 50\n"
     ]
    }
   ],
   "source": [
    "data_train = preprocess_img(data_train)\n",
    "\n",
    "data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Placeholder for missing images (a blank black image)\n",
    "# def create_placeholder_image(size=(64, 64, 3)):\n",
    "#     return np.zeros(size, dtype=np.float32)  # Normalized [0, 1] range\n",
    "\n",
    "# # Function to preprocess image data\n",
    "# def preprocess_image(img_data, size=(64, 64)):\n",
    "#     try:\n",
    "#         img_array = np.array(img_data, dtype=np.uint8)  # Ensure valid data type\n",
    "\n",
    "#         # Check for empty image\n",
    "#         if img_array.size == 0 or img_array.ndim != 3 or img_array.shape[2] != 3:\n",
    "#             raise ValueError(f\"Invalid or empty image dimensions: {img_array.shape}\")\n",
    "\n",
    "#         img_resized = np.array(Image.fromarray(img_array).resize(size))  # Resize\n",
    "#         img_normalized = img_resized / 255.0  # Normalize pixel values to [0, 1]\n",
    "#         return img_normalized\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error preprocessing image: {e}\")\n",
    "#         return create_placeholder_image(size)\n",
    "\n",
    "# # Preprocess the dataset\n",
    "# def preprocess_dataset(data):\n",
    "#     # Define placeholder image\n",
    "#     placeholder_image = create_placeholder_image()\n",
    "\n",
    "#     # Iterate over rows to preprocess images\n",
    "#     breakfast_images = []\n",
    "#     lunch_images = []\n",
    "\n",
    "#     for index, row in data.iterrows():\n",
    "#         # Handle missing breakfast images\n",
    "#         if pd.isnull(row['Image Before Breakfast']) or row['Image Before Breakfast'] == '[]':  # Check for empty list or NaN\n",
    "#             breakfast_images.append(placeholder_image)\n",
    "#         else:\n",
    "#             try:\n",
    "#                 img_data = eval(row['Image Before Breakfast'])  # Convert string to list\n",
    "#                 breakfast_images.append(preprocess_image(img_data))\n",
    "#             except Exception as e:\n",
    "#                 print(f\"Error at index {index}, breakfast: {e}\")\n",
    "#                 breakfast_images.append(placeholder_image)\n",
    "\n",
    "#         # Handle missing lunch images\n",
    "#         if pd.isnull(row['Image Before Lunch']) or row['Image Before Lunch'] == '[]':  # Check for empty list or NaN\n",
    "#             lunch_images.append(placeholder_image)\n",
    "#         else:\n",
    "#             try:\n",
    "#                 img_data = eval(row['Image Before Lunch'])  # Convert string to list\n",
    "#                 lunch_images.append(preprocess_image(img_data))\n",
    "#             except Exception as e:\n",
    "#                 print(f\"Error at index {index}, lunch: {e}\")\n",
    "#                 lunch_images.append(placeholder_image)\n",
    "\n",
    "#     # Add preprocessed images back to the dataset\n",
    "#     data['Image Before Breakfast'] = breakfast_images\n",
    "#     data['Image Before Lunch'] = lunch_images\n",
    "\n",
    "#     return data\n",
    "\n",
    "# # Apply preprocessing\n",
    "# cgm_image_data_processed = preprocess_dataset(temp_data_processed)\n",
    "\n",
    "# # Save the processed dataset if needed\n",
    "# # processed_data.to_pickle(\"processed_img_train.pkl\")  # Save in pickle format for further use\n",
    "# print(cgm_image_data_processed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Process CGM Data (Time-Series Glucose Levels) - COMPLETE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updating missing values with mean\n",
    "\n",
    "def preprocess_cgm(data_train):\n",
    "\n",
    "    # Function to check if CGM Data is an empty array\n",
    "    def is_cgm_data_empty(row):\n",
    "        try:\n",
    "            cgm_list = ast.literal_eval(row['CGM Data'])\n",
    "            return len(cgm_list) == 0\n",
    "        except:\n",
    "            return True\n",
    "\n",
    "    # Function to filter out rows where CGM Data is empty\n",
    "    data_train = data_train[~data_train.apply(is_cgm_data_empty, axis=1)]\n",
    "\n",
    "    # Get the HH:MM:SS breakfast and lunch times and calculate the mean for each subject ID\n",
    "    data_train.loc[:, 'Breakfast Time'] = pd.to_datetime(data_train['Breakfast Time'], errors='coerce')\n",
    "    data_train.loc[:, 'Lunch Time'] = pd.to_datetime(data_train['Lunch Time'], errors='coerce')\n",
    "\n",
    "    def mean_time(times):\n",
    "        total_seconds = sum([t.hour * 3600 + t.minute * 60 + t.second for t in times if pd.notna(t)])\n",
    "        mean_seconds = total_seconds // len([t for t in times if pd.notna(t)])\n",
    "        return pd.to_datetime(mean_seconds, unit='s').time()\n",
    "\n",
    "    mean_times = data_train.groupby('Subject ID')[['Breakfast Time', 'Lunch Time']].apply(\n",
    "        lambda group: pd.Series({\n",
    "            'Breakfast Time': mean_time(group['Breakfast Time']),\n",
    "            'Lunch Time': mean_time(group['Lunch Time'])\n",
    "        })\n",
    "    )\n",
    "\n",
    "    mean_times = mean_times.reset_index()\n",
    "\n",
    "    # Find the reference date for any row within the same subject:\n",
    "    def get_reference_date(subject_id):\n",
    "        day_2_breakfast_index = data_train[(data_train['Subject ID'] == subject_id) & (data_train['Day'] == 2)]['Breakfast Time'].first_valid_index()\n",
    "        if day_2_breakfast_index is None or pd.isna(data_train.loc[day_2_breakfast_index, 'Breakfast Time']):\n",
    "            day_3_breakfast_index = data_train[(data_train['Subject ID'] == subject_id) & (data_train['Day'] == 4)]['Breakfast Time'].first_valid_index()\n",
    "            if day_3_breakfast_index is not None:\n",
    "                reference_date = data_train.loc[day_3_breakfast_index, 'Breakfast Time']\n",
    "                reference_day = 4\n",
    "            else:\n",
    "                reference_date = None\n",
    "                reference_day = None\n",
    "        else:\n",
    "            reference_date = data_train.loc[day_2_breakfast_index, 'Breakfast Time']\n",
    "            reference_day = 2\n",
    "        \n",
    "        return pd.Series([reference_date.date(), reference_day])\n",
    "\n",
    "    mean_times[['Reference Date', 'Reference Day']] = mean_times['Subject ID'].apply(get_reference_date)\n",
    "\n",
    "    # Update missing values\n",
    "    def update_missing_breakfast_time(row, mean_times):\n",
    "        subject_id = row['Subject ID']\n",
    "        day = row['Day']\n",
    "        \n",
    "        mean_breakfast_time = mean_times.loc[mean_times['Subject ID'] == subject_id, 'Breakfast Time'].iloc[0]\n",
    "        mean_reference_date = mean_times.loc[mean_times['Subject ID'] == subject_id, 'Reference Date'].iloc[0]\n",
    "        reference_day = mean_times.loc[mean_times['Subject ID'] == subject_id, 'Reference Day'].iloc[0]\n",
    "        current_date = mean_reference_date + pd.Timedelta(days=(day - reference_day))\n",
    "        updated_breakfast_time = pd.to_datetime(current_date.strftime('%Y-%m-%d') + ' ' + mean_breakfast_time.strftime('%H:%M:%S'))\n",
    "        row['Breakfast Time'] = updated_breakfast_time\n",
    "        return row\n",
    "\n",
    "    data_train = data_train.apply(\n",
    "        lambda row: update_missing_breakfast_time(row, mean_times) if pd.isna(row['Breakfast Time']) else row, axis=1\n",
    "    )\n",
    "\n",
    "    def update_missing_lunch_time(row, mean_times):\n",
    "        subject_id = row['Subject ID']\n",
    "        day = row['Day']\n",
    "        mean_lunch_time = mean_times.loc[mean_times['Subject ID'] == subject_id, 'Lunch Time'].iloc[0]\n",
    "        mean_reference_date = mean_times.loc[mean_times['Subject ID'] == subject_id, 'Reference Date'].iloc[0]\n",
    "        reference_day = mean_times.loc[mean_times['Subject ID'] == subject_id, 'Reference Day'].iloc[0]\n",
    "        current_date = mean_reference_date + pd.Timedelta(days=(day - reference_day))\n",
    "        updated_lunch_time = pd.to_datetime(current_date.strftime('%Y-%m-%d') + ' ' + mean_lunch_time.strftime('%H:%M:%S'))\n",
    "        row['Lunch Time'] = updated_lunch_time\n",
    "        return row\n",
    "\n",
    "    data_train = data_train.apply(\n",
    "        lambda row: update_missing_lunch_time(row, mean_times) if pd.isna(row['Lunch Time']) else row, axis=1\n",
    "    )\n",
    "\n",
    "    data_train['Time Between Meals'] = (data_train['Lunch Time'] - data_train['Breakfast Time']).dt.total_seconds()\n",
    "\n",
    "    def safe_get_glucose_data(cgm_data):\n",
    "        try:\n",
    "            if cgm_data and isinstance(cgm_data, list) and all(isinstance(entry, tuple) and len(entry) >= 2 for entry in cgm_data):\n",
    "                return sum([entry[1] for entry in cgm_data]) / len(cgm_data)\n",
    "            else:\n",
    "                return None\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing data: {e}\")\n",
    "            return None\n",
    "\n",
    "    # Apply the function to the 'CGM Data' column\n",
    "    Mean_Glucose = data_train['CGM Data'].apply(safe_get_glucose_data)\n",
    "    Max_Glucose = data_train['CGM Data'].apply(\n",
    "        lambda x: max([entry[1] for entry in x]) if x and isinstance(x, list) and all(isinstance(entry, tuple) and len(entry) >= 2 for entry in x) else None\n",
    "    )\n",
    "    Min_Glucose = data_train['CGM Data'].apply(\n",
    "        lambda x: min([entry[1] for entry in x]) if x and isinstance(x, list) and all(isinstance(entry, tuple) and len(entry) >= 2 for entry in x) else None\n",
    "    )\n",
    "    Std_Glucose = data_train['CGM Data'].apply(\n",
    "        lambda x: pd.Series([entry[1] for entry in x]).std() if x and isinstance(x, list) and all(isinstance(entry, tuple) and len(entry) >= 2 for entry in x) else None\n",
    "    )\n",
    "    data_train['CGM Data'] = data_train['CGM Data'].apply(ast.literal_eval)\n",
    "\n",
    "    data_train['Mean_Glucose'] = data_train['CGM Data'].apply(\n",
    "        lambda x: sum([entry[1] for entry in x]) / len(x) if x else None\n",
    "    )\n",
    "    data_train['Max_Glucose'] = data_train['CGM Data'].apply(\n",
    "        lambda x: max([entry[1] for entry in x]) if x else None\n",
    "    )\n",
    "    data_train['Min_Glucose'] = data_train['CGM Data'].apply(\n",
    "        lambda x: min([entry[1] for entry in x]) if x else None\n",
    "    )\n",
    "    data_train['Std_Glucose'] = data_train['CGM Data'].apply(\n",
    "        lambda x: pd.Series([entry[1] for entry in x]).std() if x else None\n",
    "    )\n",
    "\n",
    "    return data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject ID</th>\n",
       "      <th>Day</th>\n",
       "      <th>Breakfast Time</th>\n",
       "      <th>Lunch Time</th>\n",
       "      <th>CGM Data</th>\n",
       "      <th>Reduced_img_before_breakfast</th>\n",
       "      <th>Reduced_img_before_lunch</th>\n",
       "      <th>Time Between Meals</th>\n",
       "      <th>Mean_Glucose</th>\n",
       "      <th>Max_Glucose</th>\n",
       "      <th>Min_Glucose</th>\n",
       "      <th>Std_Glucose</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2021-09-19 08:41:00</td>\n",
       "      <td>2021-09-19 12:24:00</td>\n",
       "      <td>[(2021-09-19 08:20:00, 98.26666666666667), (20...</td>\n",
       "      <td>[-32.91928047158247, 13.888790849359642, 0.305...</td>\n",
       "      <td>[23.074055405498918, 9.36279840473365, -29.019...</td>\n",
       "      <td>13380.0</td>\n",
       "      <td>90.989097</td>\n",
       "      <td>141.816667</td>\n",
       "      <td>40.733333</td>\n",
       "      <td>21.618896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2021-09-20 09:50:00</td>\n",
       "      <td>2021-09-20 15:20:00</td>\n",
       "      <td>[(2021-09-20 09:10:00, 97.18333333333334), (20...</td>\n",
       "      <td>[-26.219316263974584, 16.424703743708214, -0.4...</td>\n",
       "      <td>[-5.970847077816804, -17.233244496181673, -14....</td>\n",
       "      <td>19800.0</td>\n",
       "      <td>97.619082</td>\n",
       "      <td>118.083333</td>\n",
       "      <td>87.183333</td>\n",
       "      <td>6.088044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2021-09-21 09:34:00</td>\n",
       "      <td>2021-09-21 13:09:00</td>\n",
       "      <td>[(2021-09-21 09:20:00, 107.36666666666666), (2...</td>\n",
       "      <td>[-17.86024001380985, 10.620841236259638, -16.3...</td>\n",
       "      <td>[-30.777239192648928, 12.674365094458542, -17....</td>\n",
       "      <td>12900.0</td>\n",
       "      <td>110.482796</td>\n",
       "      <td>139.900000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>12.068927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2021-09-22 09:46:00</td>\n",
       "      <td>2021-09-22 13:50:00</td>\n",
       "      <td>[(2021-09-22 09:25:00, 107.28333333333333), (2...</td>\n",
       "      <td>[-22.16294018289692, -14.158064305457387, 0.06...</td>\n",
       "      <td>[0.9527481173828339, 9.93729447868345, -13.841...</td>\n",
       "      <td>14640.0</td>\n",
       "      <td>100.235590</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>84.366667</td>\n",
       "      <td>10.515336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2021-09-23 09:07:00</td>\n",
       "      <td>2021-09-23 13:17:00</td>\n",
       "      <td>[(2021-09-23 08:55:00, 103.0), (2021-09-23 09:...</td>\n",
       "      <td>[-34.523258800819974, -0.5308802734574567, 6.3...</td>\n",
       "      <td>[-13.064853292144731, 8.075026293004358, -38.5...</td>\n",
       "      <td>15000.0</td>\n",
       "      <td>105.868153</td>\n",
       "      <td>124.633333</td>\n",
       "      <td>92.316667</td>\n",
       "      <td>6.152499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>2021-12-18 08:52:00</td>\n",
       "      <td>2021-12-18 12:28:00</td>\n",
       "      <td>[(2021-12-18 08:50:00, 101.36), (2021-12-18 08...</td>\n",
       "      <td>[34.08229264951511, 81.75710130576871, 53.9032...</td>\n",
       "      <td>[52.317760336616395, 37.45572974952651, -37.56...</td>\n",
       "      <td>12960.0</td>\n",
       "      <td>111.874667</td>\n",
       "      <td>136.360000</td>\n",
       "      <td>86.320000</td>\n",
       "      <td>13.147774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>2021-12-19 08:43:00</td>\n",
       "      <td>2021-12-19 13:13:00</td>\n",
       "      <td>[(2021-12-19 08:40:00, 100.68), (2021-12-19 08...</td>\n",
       "      <td>[-4.772387612000207, 33.625020758590985, 6.841...</td>\n",
       "      <td>[-26.31511985939777, -1.6458231174627136, 6.21...</td>\n",
       "      <td>16200.0</td>\n",
       "      <td>118.940408</td>\n",
       "      <td>177.040000</td>\n",
       "      <td>81.680000</td>\n",
       "      <td>23.180273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>2021-12-20 09:06:00</td>\n",
       "      <td>2021-12-20 12:46:00</td>\n",
       "      <td>[(2021-12-20 09:00:00, 104.04), (2021-12-20 09...</td>\n",
       "      <td>[24.554002373388368, 56.19980844749697, 50.114...</td>\n",
       "      <td>[50.35121167943291, -25.185911034165546, -31.6...</td>\n",
       "      <td>13200.0</td>\n",
       "      <td>102.462222</td>\n",
       "      <td>126.360000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>13.187046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>2021-12-21 08:34:00</td>\n",
       "      <td>2021-12-21 12:38:00</td>\n",
       "      <td>[(2021-12-21 08:25:00, 96.4), (2021-12-21 08:3...</td>\n",
       "      <td>[2.5593543587830556, 34.02232430320033, 10.929...</td>\n",
       "      <td>[25.349492297530325, -26.763417976221163, -14....</td>\n",
       "      <td>14640.0</td>\n",
       "      <td>101.840000</td>\n",
       "      <td>159.360000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>24.678828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>2021-12-22 08:44:00</td>\n",
       "      <td>2021-12-22 12:34:00</td>\n",
       "      <td>[(2021-12-22 08:35:00, 96.68), (2021-12-22 08:...</td>\n",
       "      <td>[7.528774552845239, 53.01155936077776, 10.6809...</td>\n",
       "      <td>[18.627785162522564, 30.2389180369778, -24.347...</td>\n",
       "      <td>13800.0</td>\n",
       "      <td>107.682151</td>\n",
       "      <td>140.320000</td>\n",
       "      <td>88.320000</td>\n",
       "      <td>13.732379</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>290 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Subject ID  Day      Breakfast Time          Lunch Time  \\\n",
       "0             1    2 2021-09-19 08:41:00 2021-09-19 12:24:00   \n",
       "1             1    3 2021-09-20 09:50:00 2021-09-20 15:20:00   \n",
       "2             1    4 2021-09-21 09:34:00 2021-09-21 13:09:00   \n",
       "3             1    5 2021-09-22 09:46:00 2021-09-22 13:50:00   \n",
       "4             1    6 2021-09-23 09:07:00 2021-09-23 13:17:00   \n",
       "..          ...  ...                 ...                 ...   \n",
       "286           7    6 2021-12-18 08:52:00 2021-12-18 12:28:00   \n",
       "287           7    7 2021-12-19 08:43:00 2021-12-19 13:13:00   \n",
       "288           7    8 2021-12-20 09:06:00 2021-12-20 12:46:00   \n",
       "289           7    9 2021-12-21 08:34:00 2021-12-21 12:38:00   \n",
       "290           7   10 2021-12-22 08:44:00 2021-12-22 12:34:00   \n",
       "\n",
       "                                              CGM Data  \\\n",
       "0    [(2021-09-19 08:20:00, 98.26666666666667), (20...   \n",
       "1    [(2021-09-20 09:10:00, 97.18333333333334), (20...   \n",
       "2    [(2021-09-21 09:20:00, 107.36666666666666), (2...   \n",
       "3    [(2021-09-22 09:25:00, 107.28333333333333), (2...   \n",
       "4    [(2021-09-23 08:55:00, 103.0), (2021-09-23 09:...   \n",
       "..                                                 ...   \n",
       "286  [(2021-12-18 08:50:00, 101.36), (2021-12-18 08...   \n",
       "287  [(2021-12-19 08:40:00, 100.68), (2021-12-19 08...   \n",
       "288  [(2021-12-20 09:00:00, 104.04), (2021-12-20 09...   \n",
       "289  [(2021-12-21 08:25:00, 96.4), (2021-12-21 08:3...   \n",
       "290  [(2021-12-22 08:35:00, 96.68), (2021-12-22 08:...   \n",
       "\n",
       "                          Reduced_img_before_breakfast  \\\n",
       "0    [-32.91928047158247, 13.888790849359642, 0.305...   \n",
       "1    [-26.219316263974584, 16.424703743708214, -0.4...   \n",
       "2    [-17.86024001380985, 10.620841236259638, -16.3...   \n",
       "3    [-22.16294018289692, -14.158064305457387, 0.06...   \n",
       "4    [-34.523258800819974, -0.5308802734574567, 6.3...   \n",
       "..                                                 ...   \n",
       "286  [34.08229264951511, 81.75710130576871, 53.9032...   \n",
       "287  [-4.772387612000207, 33.625020758590985, 6.841...   \n",
       "288  [24.554002373388368, 56.19980844749697, 50.114...   \n",
       "289  [2.5593543587830556, 34.02232430320033, 10.929...   \n",
       "290  [7.528774552845239, 53.01155936077776, 10.6809...   \n",
       "\n",
       "                              Reduced_img_before_lunch  Time Between Meals  \\\n",
       "0    [23.074055405498918, 9.36279840473365, -29.019...             13380.0   \n",
       "1    [-5.970847077816804, -17.233244496181673, -14....             19800.0   \n",
       "2    [-30.777239192648928, 12.674365094458542, -17....             12900.0   \n",
       "3    [0.9527481173828339, 9.93729447868345, -13.841...             14640.0   \n",
       "4    [-13.064853292144731, 8.075026293004358, -38.5...             15000.0   \n",
       "..                                                 ...                 ...   \n",
       "286  [52.317760336616395, 37.45572974952651, -37.56...             12960.0   \n",
       "287  [-26.31511985939777, -1.6458231174627136, 6.21...             16200.0   \n",
       "288  [50.35121167943291, -25.185911034165546, -31.6...             13200.0   \n",
       "289  [25.349492297530325, -26.763417976221163, -14....             14640.0   \n",
       "290  [18.627785162522564, 30.2389180369778, -24.347...             13800.0   \n",
       "\n",
       "     Mean_Glucose  Max_Glucose  Min_Glucose  Std_Glucose  \n",
       "0       90.989097   141.816667    40.733333    21.618896  \n",
       "1       97.619082   118.083333    87.183333     6.088044  \n",
       "2      110.482796   139.900000    90.000000    12.068927  \n",
       "3      100.235590   126.000000    84.366667    10.515336  \n",
       "4      105.868153   124.633333    92.316667     6.152499  \n",
       "..            ...          ...          ...          ...  \n",
       "286    111.874667   136.360000    86.320000    13.147774  \n",
       "287    118.940408   177.040000    81.680000    23.180273  \n",
       "288    102.462222   126.360000    76.000000    13.187046  \n",
       "289    101.840000   159.360000    70.000000    24.678828  \n",
       "290    107.682151   140.320000    88.320000    13.732379  \n",
       "\n",
       "[290 rows x 12 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train = preprocess_cgm(data_train)\n",
    "\n",
    "data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Function to check if CGM Data is an empty array\n",
    "# def is_cgm_data_empty(row):\n",
    "#     try:\n",
    "#         cgm_list = ast.literal_eval(row['CGM Data'])\n",
    "#         return len(cgm_list) == 0\n",
    "#     except:\n",
    "#         return True\n",
    "\n",
    "# # Function to filter out rows where CGM Data is empty\n",
    "# cgm_train = cgm_train[~cgm_train.apply(is_cgm_data_empty, axis=1)]\n",
    "\n",
    "# # Handle missing breakfast and lunch times\n",
    "# cgm_train['Breakfast Time'] = pd.to_datetime(cgm_train['Breakfast Time'], errors='coerce')\n",
    "# cgm_train['Lunch Time'] = pd.to_datetime(cgm_train['Lunch Time'], errors='coerce')\n",
    "\n",
    "# # Extract CGM data as list of tuples, convert to list of time series values\n",
    "# cgm_train['CGM Data'] = cgm_train['CGM Data'].apply(lambda x: eval(x) if isinstance(x, str) else [])\n",
    "\n",
    "# # Extract features from CGM data (flatten the time and glucose values)\n",
    "# def extract_cgm_features(cgm_data):\n",
    "#     times = [entry[0] for entry in cgm_data]\n",
    "#     glucose_levels = [entry[1] for entry in cgm_data]\n",
    "#     return times, glucose_levels\n",
    "\n",
    "# cgm_train['CGM Times'], cgm_train['CGM Levels'] = zip(*cgm_train['CGM Data'].apply(extract_cgm_features))\n",
    "\n",
    "# # Normalize glucose levels\n",
    "# scaler = StandardScaler()\n",
    "# cgm_train['CGM Levels'] = cgm_train['CGM Levels'].apply(lambda x: scaler.fit_transform(np.array(x).reshape(-1, 1)).flatten())\n",
    "\n",
    "# # We need to pad the sequences to a fixed length for GRU input\n",
    "# max_sequence_length = 300  # Define a maximum length for the sequences\n",
    "# cgm_train['Padded CGM Levels'] = pad_sequences(cgm_train['CGM Levels'], maxlen=max_sequence_length, padding='post', value=0, dtype='float32').tolist()\n",
    "\n",
    "# # Mask labels: We will use NaN or a predefined mask value for missing times -- 1\n",
    "# cgm_train['Breakfast Time Masked'] = cgm_train['Breakfast Time'].isna().astype(int)\n",
    "# cgm_train['Lunch Time Masked'] = cgm_train['Lunch Time'].isna().astype(int)\n",
    "\n",
    "# # Prepare the target variable: encode the time values for breakfast and lunch\n",
    "# def encode_times(time_column):\n",
    "#     return (time_column - pd.Timestamp('2021-09-18')) // pd.Timedelta('1s')\n",
    "\n",
    "# # Filter rows where both Breakfast and Lunch times are missing (i.e., both masks are 0)\n",
    "# filtered_cgm_train = cgm_train[(cgm_train['Breakfast Time Masked'] == 0) & (cgm_train['Lunch Time Masked'] == 0)].copy()\n",
    "\n",
    "# # Encode breakfast and lunch times only for rows where both are missing\n",
    "# filtered_cgm_train['Breakfast Time Encoded'] = encode_times(filtered_cgm_train['Breakfast Time'])\n",
    "# filtered_cgm_train['Lunch Time Encoded'] = encode_times(filtered_cgm_train['Lunch Time'])\n",
    "\n",
    "# time_scaler = MinMaxScaler()\n",
    "\n",
    "# # Reshape and scale both 'Breakfast Time Encoded' and 'Lunch Time Encoded'\n",
    "# filtered_cgm_train[['Breakfast Time Encoded', 'Lunch Time Encoded']] = time_scaler.fit_transform(\n",
    "#     filtered_cgm_train[['Breakfast Time Encoded', 'Lunch Time Encoded']]\n",
    "# )\n",
    "\n",
    "# X_train = np.array(filtered_cgm_train['Padded CGM Levels'].tolist())\n",
    "# y_train = filtered_cgm_train[['Breakfast Time Encoded', 'Lunch Time Encoded']].values\n",
    "\n",
    "# # Reshape X_train to (samples, time steps, features)\n",
    "# X_train_reshaped = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))  # (samples, time steps, features)\n",
    "\n",
    "# # Define the GRU model\n",
    "# def create_gru_model(input_shape):\n",
    "#     model = Sequential([\n",
    "#         Input(shape=input_shape),\n",
    "#         GRU(32, activation='relu'),\n",
    "#         Dense(2)  # Output two values: breakfast and lunch times\n",
    "#     ])\n",
    "#     model.compile(optimizer=Adam(learning_rate=0.001, clipvalue=1.0), loss='mse')\n",
    "#     return model\n",
    "\n",
    "# # Create and compile the model\n",
    "# model = create_gru_model((X_train_reshaped.shape[1], 1))\n",
    "\n",
    "# # Train the model\n",
    "# model.fit(X_train_reshaped, y_train, epochs=10, batch_size=32, validation_split=0.2, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def predict_meal_times(model, X):\n",
    "#     X = np.array(X.tolist()) if isinstance(X, pd.Series) else np.array(X)\n",
    "#     X_reshaped = X.reshape((X.shape[0], X.shape[1], 1))\n",
    "#     predictions = model.predict(X_reshaped)\n",
    "#     reference_date = pd.Timestamp('2021-09-18')\n",
    "\n",
    "#     # Decode predictions back to original scale using inverse transformation\n",
    "#     decoded_times = time_scaler.inverse_transform(predictions)\n",
    "\n",
    "#     # Add the decoded seconds back to the reference date\n",
    "#     decoded_breakfast_timestamps = reference_date + pd.to_timedelta(decoded_times[:, 0], unit='s')\n",
    "#     decoded_lunch_timestamps = reference_date + pd.to_timedelta(decoded_times[:, 1], unit='s')\n",
    "\n",
    "#     decoded_predictions = pd.DataFrame({\n",
    "#         'Predicted Breakfast Time': decoded_breakfast_timestamps,\n",
    "#         'Predicted Lunch Time': decoded_lunch_timestamps\n",
    "#     })\n",
    "\n",
    "#     return decoded_predictions\n",
    "\n",
    "# # Extract rows with missing breakfast or lunch times\n",
    "# missing_data = cgm_train[cgm_train['Breakfast Time'].isna() | cgm_train['Lunch Time'].isna()]\n",
    "\n",
    "# # Ensure that `Padded CGM Levels` is included in `missing_data`\n",
    "# predict_missing = missing_data['Padded CGM Levels']\n",
    "# missing_data_copy = missing_data.copy()\n",
    "\n",
    "# # Make predictions for missing breakfast and lunch times\n",
    "# predicted_times = predict_meal_times(model, predict_missing)\n",
    "\n",
    "# # Reset indices for both DataFrames to align by row order\n",
    "# missing_data_copy = missing_data_copy.reset_index(drop=True)\n",
    "# predicted_times = predicted_times.reset_index(drop=True)\n",
    "\n",
    "# # Add the 'Predicted Breakfast Time' column\n",
    "# missing_data_copy['Predicted Breakfast Time'] = predicted_times['Predicted Breakfast Time']\n",
    "# missing_data_copy['Predicted Lunch Time'] = predicted_times['Predicted Lunch Time']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Process Viome Data (Demographic Data) - COMPLETE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_viome(demo_viome_train):\n",
    "    array_of_means = []\n",
    "    array_of_max = []\n",
    "    array_of_min = []\n",
    "    for i in range(36):\n",
    "        list1 = demo_viome_train['Viome'][i].split(',')\n",
    "        random_sum = 0\n",
    "        random_max = -1000\n",
    "        random_min = 1000\n",
    "        for j in list1:\n",
    "            temp_num = float(j)\n",
    "            random_sum += temp_num\n",
    "            if temp_num > random_max:\n",
    "                random_max = temp_num\n",
    "            if temp_num < random_min:\n",
    "                random_min = temp_num\n",
    "        array_of_means.append(random_sum/27)\n",
    "        array_of_max.append(random_max)\n",
    "        array_of_min.append(random_min)\n",
    "\n",
    "    np_array_of_means = np.array(array_of_means)\n",
    "    np_array_of_max = np.array(array_of_max)\n",
    "    np_array_of_min = np.array(array_of_min)\n",
    "\n",
    "    demo_viome_train['Viome_Mean'] = np_array_of_means\n",
    "    demo_viome_train['Viome_Max'] = np_array_of_max\n",
    "    demo_viome_train['Viome_Min'] = np_array_of_min\n",
    "    demo_viome_train.drop(columns=['Viome'], inplace=True)\n",
    "\n",
    "    demo_viome_train = pd.get_dummies(demo_viome_train, columns=['Race'], drop_first=False)\n",
    "\n",
    "    return demo_viome_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Viome'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\maila\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Viome'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[53], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m demo_viome_train \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocess_viome\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdemo_viome_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m data_train \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mmerge(data_train, demo_viome_train, on\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSubject ID\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      4\u001b[0m data_train\n",
      "Cell \u001b[1;32mIn[50], line 6\u001b[0m, in \u001b[0;36mpreprocess_viome\u001b[1;34m(demo_viome_train)\u001b[0m\n\u001b[0;32m      4\u001b[0m array_of_min \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m36\u001b[39m):\n\u001b[1;32m----> 6\u001b[0m     list1 \u001b[38;5;241m=\u001b[39m \u001b[43mdemo_viome_train\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mViome\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m[i]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      7\u001b[0m     random_sum \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m      8\u001b[0m     random_max \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1000\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\maila\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\maila\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Viome'"
     ]
    }
   ],
   "source": [
    "demo_viome_train = preprocess_viome(demo_viome_train)\n",
    "data_train = pd.merge(data_train, demo_viome_train, on=['Subject ID'])\n",
    "\n",
    "data_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multimodal Training"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
