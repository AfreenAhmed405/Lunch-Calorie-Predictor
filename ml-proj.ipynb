{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1582,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import ast\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import torch.nn as nn\n",
    "import keras.backend as K\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GRU, Dense, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1583,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Datasets\n",
    "\n",
    "# Training datasets\n",
    "cgm_train = pd.read_csv('cgm_train.csv')\n",
    "image_train = pd.read_csv('img_train.csv')\n",
    "demo_viome_train = pd.read_csv('demo_viome_train.csv')\n",
    "label_train = pd.read_csv('label_train.csv')\n",
    "\n",
    "# Test datasets\n",
    "cgm_test = pd.read_csv('cgm_test.csv')\n",
    "image_test = pd.read_csv('img_test.csv')\n",
    "demo_viome_test = pd.read_csv('demo_viome_test.csv')\n",
    "label_test = pd.read_csv('label_test_breakfast_only.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Process CGM Data (Time-Series Glucose Levels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject ID</th>\n",
       "      <th>Day</th>\n",
       "      <th>Breakfast Time</th>\n",
       "      <th>Lunch Time</th>\n",
       "      <th>CGM Data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>2021-12-21 09:00:00</td>\n",
       "      <td>2021-12-21 12:45:00</td>\n",
       "      <td>[('2021-12-21 08:10:00', 124.58), ('2021-12-21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>2022-03-02 09:53:22</td>\n",
       "      <td>2022-03-02 14:55:00</td>\n",
       "      <td>[('2022-03-02 11:00:00', 139.04), ('2022-03-02...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>2022-03-12 08:03:52</td>\n",
       "      <td>2022-03-12 12:39:00</td>\n",
       "      <td>[('2022-03-12 12:40:00', 103.0), ('2022-03-12 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>2022-04-08 08:30:00</td>\n",
       "      <td>2022-04-08 12:48:00</td>\n",
       "      <td>[('2022-04-08 08:15:00', 131.58), ('2022-04-08...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>2022-04-02 09:26:00</td>\n",
       "      <td>2022-04-02 13:46:07</td>\n",
       "      <td>[('2022-04-02 09:20:00', 105.0), ('2022-04-02 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>2022-04-07 07:53:00</td>\n",
       "      <td>2022-04-07 12:43:37</td>\n",
       "      <td>[('2022-04-07 07:45:00', 110.23666666666666), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>2022-04-21 09:46:07</td>\n",
       "      <td>2022-04-21 14:05:00</td>\n",
       "      <td>[('2022-04-21 13:30:00', 117.0), ('2022-04-21 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>2022-08-08 09:49:10</td>\n",
       "      <td>2022-08-08 12:58:00</td>\n",
       "      <td>[('2022-08-08 12:45:00', 116.0), ('2022-08-08 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>28</td>\n",
       "      <td>9</td>\n",
       "      <td>2022-08-24 09:10:10</td>\n",
       "      <td>2022-08-24 13:04:01</td>\n",
       "      <td>[('2022-08-24 09:00:00', 143.28), ('2022-08-24...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>2022-09-29 06:14:06</td>\n",
       "      <td>2022-09-29 11:56:25</td>\n",
       "      <td>[('2022-09-29 05:45:00', 131.68), ('2022-09-29...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>29</td>\n",
       "      <td>8</td>\n",
       "      <td>2022-10-05 06:21:46</td>\n",
       "      <td>2022-10-05 11:56:21</td>\n",
       "      <td>[('2022-10-05 06:20:00', 106.77333333333333), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>2022-12-01 08:15:30</td>\n",
       "      <td>2022-12-01 14:05:45</td>\n",
       "      <td>[('2022-12-01 11:50:00', 140.8), ('2022-12-01 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>30</td>\n",
       "      <td>5</td>\n",
       "      <td>2022-12-04 08:15:30</td>\n",
       "      <td>2022-12-04 12:33:50</td>\n",
       "      <td>[('2022-12-04 12:00:00', 219.25), ('2022-12-04...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>32</td>\n",
       "      <td>6</td>\n",
       "      <td>2023-07-10 06:47:43</td>\n",
       "      <td>2023-07-10 13:09:37</td>\n",
       "      <td>[('2023-07-10 04:25:00', 108.62666666666667), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>32</td>\n",
       "      <td>7</td>\n",
       "      <td>2023-07-11 07:14:43</td>\n",
       "      <td>2023-07-11 13:20:52</td>\n",
       "      <td>[('2023-07-11 07:05:00', 119.94666666666667), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>32</td>\n",
       "      <td>9</td>\n",
       "      <td>2023-07-13 05:57:06</td>\n",
       "      <td>2023-07-13 13:20:52</td>\n",
       "      <td>[('2023-07-13 05:35:00', 92.12), ('2023-07-13 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>32</td>\n",
       "      <td>10</td>\n",
       "      <td>2023-07-14 06:47:43</td>\n",
       "      <td>2023-07-14 14:12:48</td>\n",
       "      <td>[('2023-07-14 05:15:00', 94.0), ('2023-07-14 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>2023-08-25 07:44:13</td>\n",
       "      <td>2023-08-25 12:49:44</td>\n",
       "      <td>[('2023-08-25 12:15:00', 169.54333333333332), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>35</td>\n",
       "      <td>6</td>\n",
       "      <td>2023-08-29 06:44:49</td>\n",
       "      <td>2023-08-29 13:16:52</td>\n",
       "      <td>[('2023-08-29 06:30:00', 175.36333333333334), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>35</td>\n",
       "      <td>9</td>\n",
       "      <td>2023-09-01 07:37:01</td>\n",
       "      <td>2023-09-01 13:16:52</td>\n",
       "      <td>[('2023-09-01 06:40:00', 189.81666666666666), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>36</td>\n",
       "      <td>2</td>\n",
       "      <td>2023-08-31 07:56:52</td>\n",
       "      <td>2023-08-31 12:14:53</td>\n",
       "      <td>[('2023-08-31 08:10:00', 126.27333333333333), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>36</td>\n",
       "      <td>3</td>\n",
       "      <td>2023-09-01 07:56:52</td>\n",
       "      <td>2023-09-01 11:59:45</td>\n",
       "      <td>[('2023-09-01 08:00:00', 180.55333333333334), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "      <td>2023-12-10 06:52:33</td>\n",
       "      <td>2023-12-10 12:00:25</td>\n",
       "      <td>[('2023-12-10 11:50:00', 108.04666666666667), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>41</td>\n",
       "      <td>9</td>\n",
       "      <td>2023-12-05 08:10:52</td>\n",
       "      <td>2023-12-05 12:06:21</td>\n",
       "      <td>[('2023-12-05 08:00:00', 145.0), ('2023-12-05 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>42</td>\n",
       "      <td>4</td>\n",
       "      <td>2023-12-02 10:10:02</td>\n",
       "      <td>2023-12-02 12:20:55</td>\n",
       "      <td>[('2023-12-02 08:30:00', 131.15), ('2023-12-02...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>42</td>\n",
       "      <td>6</td>\n",
       "      <td>2023-12-04 08:39:38</td>\n",
       "      <td>2023-12-04 12:20:55</td>\n",
       "      <td>[('2023-12-04 08:40:00', 127.05), ('2023-12-04...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>42</td>\n",
       "      <td>7</td>\n",
       "      <td>2023-12-05 10:02:09</td>\n",
       "      <td>2023-12-05 12:20:55</td>\n",
       "      <td>[('2023-12-05 08:45:00', 155.2), ('2023-12-05 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>42</td>\n",
       "      <td>9</td>\n",
       "      <td>2023-12-07 09:21:37</td>\n",
       "      <td>2023-12-07 13:11:17</td>\n",
       "      <td>[('2023-12-07 12:55:00', 129.25), ('2023-12-07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>42</td>\n",
       "      <td>10</td>\n",
       "      <td>2023-12-08 09:21:37</td>\n",
       "      <td>2023-12-08 12:20:55</td>\n",
       "      <td>[('2023-12-08 10:30:00', 117.95), ('2023-12-08...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>44</td>\n",
       "      <td>3</td>\n",
       "      <td>2024-01-05 08:34:21</td>\n",
       "      <td>2024-01-05 13:00:04</td>\n",
       "      <td>[('2024-01-05 09:00:00', 113.87707641196013), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>44</td>\n",
       "      <td>7</td>\n",
       "      <td>2024-01-09 08:34:21</td>\n",
       "      <td>2024-01-09 12:37:20</td>\n",
       "      <td>[('2024-01-09 06:25:00', 112.64), ('2024-01-09...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>45</td>\n",
       "      <td>3</td>\n",
       "      <td>2024-01-26 09:21:03</td>\n",
       "      <td>2024-01-26 12:49:27</td>\n",
       "      <td>[('2024-01-26 09:00:00', 130.74), ('2024-01-26...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>45</td>\n",
       "      <td>8</td>\n",
       "      <td>2024-01-31 09:21:56</td>\n",
       "      <td>2024-01-31 12:49:27</td>\n",
       "      <td>[('2024-01-31 09:10:00', 150.98666666666668), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>45</td>\n",
       "      <td>9</td>\n",
       "      <td>2024-02-01 10:03:19</td>\n",
       "      <td>2024-02-01 12:49:27</td>\n",
       "      <td>[('2024-02-01 09:45:00', 152.0), ('2024-02-01 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>45</td>\n",
       "      <td>10</td>\n",
       "      <td>2024-02-02 09:07:46</td>\n",
       "      <td>2024-02-02 12:49:27</td>\n",
       "      <td>[('2024-02-02 08:50:00', 146.0), ('2024-02-02 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>48</td>\n",
       "      <td>3</td>\n",
       "      <td>2024-02-11 09:14:49</td>\n",
       "      <td>2024-02-11 13:08:14</td>\n",
       "      <td>[('2024-02-11 10:30:00', 82.88666666666667), (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>48</td>\n",
       "      <td>6</td>\n",
       "      <td>2024-02-14 07:35:41</td>\n",
       "      <td>2024-02-14 13:08:14</td>\n",
       "      <td>[('2024-02-14 07:25:00', 111.33), ('2024-02-14...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>49</td>\n",
       "      <td>7</td>\n",
       "      <td>2024-03-05 07:39:42</td>\n",
       "      <td>2024-03-05 12:16:15</td>\n",
       "      <td>[('2024-03-05 12:05:00', 85.0), ('2024-03-05 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>49</td>\n",
       "      <td>10</td>\n",
       "      <td>2024-03-08 07:39:42</td>\n",
       "      <td>2024-03-08 13:10:28</td>\n",
       "      <td>[('2024-03-08 07:10:00', 152.16), ('2024-03-08...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Subject ID  Day      Breakfast Time          Lunch Time  \\\n",
       "52            8    9 2021-12-21 09:00:00 2021-12-21 12:45:00   \n",
       "88           12    9 2022-03-02 09:53:22 2022-03-02 14:55:00   \n",
       "97           13    9 2022-03-12 08:03:52 2022-03-12 12:39:00   \n",
       "107          14   10 2022-04-08 08:30:00 2022-04-08 12:48:00   \n",
       "110          15    4 2022-04-02 09:26:00 2022-04-02 13:46:07   \n",
       "121          16    6 2022-04-07 07:53:00 2022-04-07 12:43:37   \n",
       "139          19    6 2022-04-21 09:46:07 2022-04-21 14:05:00   \n",
       "172          26    3 2022-08-08 09:49:10 2022-08-08 12:58:00   \n",
       "187          28    9 2022-08-24 09:10:10 2022-08-24 13:04:01   \n",
       "189          29    2 2022-09-29 06:14:06 2022-09-29 11:56:25   \n",
       "195          29    8 2022-10-05 06:21:46 2022-10-05 11:56:21   \n",
       "198          30    2 2022-12-01 08:15:30 2022-12-01 14:05:45   \n",
       "201          30    5 2022-12-04 08:15:30 2022-12-04 12:33:50   \n",
       "220          32    6 2023-07-10 06:47:43 2023-07-10 13:09:37   \n",
       "221          32    7 2023-07-11 07:14:43 2023-07-11 13:20:52   \n",
       "223          32    9 2023-07-13 05:57:06 2023-07-13 13:20:52   \n",
       "224          32   10 2023-07-14 06:47:43 2023-07-14 14:12:48   \n",
       "234          35    2 2023-08-25 07:44:13 2023-08-25 12:49:44   \n",
       "238          35    6 2023-08-29 06:44:49 2023-08-29 13:16:52   \n",
       "241          35    9 2023-09-01 07:37:01 2023-09-01 13:16:52   \n",
       "243          36    2 2023-08-31 07:56:52 2023-08-31 12:14:53   \n",
       "244          36    3 2023-09-01 07:56:52 2023-09-01 11:59:45   \n",
       "252          38    2 2023-12-10 06:52:33 2023-12-10 12:00:25   \n",
       "268          41    9 2023-12-05 08:10:52 2023-12-05 12:06:21   \n",
       "272          42    4 2023-12-02 10:10:02 2023-12-02 12:20:55   \n",
       "274          42    6 2023-12-04 08:39:38 2023-12-04 12:20:55   \n",
       "275          42    7 2023-12-05 10:02:09 2023-12-05 12:20:55   \n",
       "277          42    9 2023-12-07 09:21:37 2023-12-07 13:11:17   \n",
       "278          42   10 2023-12-08 09:21:37 2023-12-08 12:20:55   \n",
       "280          44    3 2024-01-05 08:34:21 2024-01-05 13:00:04   \n",
       "284          44    7 2024-01-09 08:34:21 2024-01-09 12:37:20   \n",
       "289          45    3 2024-01-26 09:21:03 2024-01-26 12:49:27   \n",
       "294          45    8 2024-01-31 09:21:56 2024-01-31 12:49:27   \n",
       "295          45    9 2024-02-01 10:03:19 2024-02-01 12:49:27   \n",
       "296          45   10 2024-02-02 09:07:46 2024-02-02 12:49:27   \n",
       "298          48    3 2024-02-11 09:14:49 2024-02-11 13:08:14   \n",
       "301          48    6 2024-02-14 07:35:41 2024-02-14 13:08:14   \n",
       "311          49    7 2024-03-05 07:39:42 2024-03-05 12:16:15   \n",
       "314          49   10 2024-03-08 07:39:42 2024-03-08 13:10:28   \n",
       "\n",
       "                                              CGM Data  \n",
       "52   [('2021-12-21 08:10:00', 124.58), ('2021-12-21...  \n",
       "88   [('2022-03-02 11:00:00', 139.04), ('2022-03-02...  \n",
       "97   [('2022-03-12 12:40:00', 103.0), ('2022-03-12 ...  \n",
       "107  [('2022-04-08 08:15:00', 131.58), ('2022-04-08...  \n",
       "110  [('2022-04-02 09:20:00', 105.0), ('2022-04-02 ...  \n",
       "121  [('2022-04-07 07:45:00', 110.23666666666666), ...  \n",
       "139  [('2022-04-21 13:30:00', 117.0), ('2022-04-21 ...  \n",
       "172  [('2022-08-08 12:45:00', 116.0), ('2022-08-08 ...  \n",
       "187  [('2022-08-24 09:00:00', 143.28), ('2022-08-24...  \n",
       "189  [('2022-09-29 05:45:00', 131.68), ('2022-09-29...  \n",
       "195  [('2022-10-05 06:20:00', 106.77333333333333), ...  \n",
       "198  [('2022-12-01 11:50:00', 140.8), ('2022-12-01 ...  \n",
       "201  [('2022-12-04 12:00:00', 219.25), ('2022-12-04...  \n",
       "220  [('2023-07-10 04:25:00', 108.62666666666667), ...  \n",
       "221  [('2023-07-11 07:05:00', 119.94666666666667), ...  \n",
       "223  [('2023-07-13 05:35:00', 92.12), ('2023-07-13 ...  \n",
       "224  [('2023-07-14 05:15:00', 94.0), ('2023-07-14 0...  \n",
       "234  [('2023-08-25 12:15:00', 169.54333333333332), ...  \n",
       "238  [('2023-08-29 06:30:00', 175.36333333333334), ...  \n",
       "241  [('2023-09-01 06:40:00', 189.81666666666666), ...  \n",
       "243  [('2023-08-31 08:10:00', 126.27333333333333), ...  \n",
       "244  [('2023-09-01 08:00:00', 180.55333333333334), ...  \n",
       "252  [('2023-12-10 11:50:00', 108.04666666666667), ...  \n",
       "268  [('2023-12-05 08:00:00', 145.0), ('2023-12-05 ...  \n",
       "272  [('2023-12-02 08:30:00', 131.15), ('2023-12-02...  \n",
       "274  [('2023-12-04 08:40:00', 127.05), ('2023-12-04...  \n",
       "275  [('2023-12-05 08:45:00', 155.2), ('2023-12-05 ...  \n",
       "277  [('2023-12-07 12:55:00', 129.25), ('2023-12-07...  \n",
       "278  [('2023-12-08 10:30:00', 117.95), ('2023-12-08...  \n",
       "280  [('2024-01-05 09:00:00', 113.87707641196013), ...  \n",
       "284  [('2024-01-09 06:25:00', 112.64), ('2024-01-09...  \n",
       "289  [('2024-01-26 09:00:00', 130.74), ('2024-01-26...  \n",
       "294  [('2024-01-31 09:10:00', 150.98666666666668), ...  \n",
       "295  [('2024-02-01 09:45:00', 152.0), ('2024-02-01 ...  \n",
       "296  [('2024-02-02 08:50:00', 146.0), ('2024-02-02 ...  \n",
       "298  [('2024-02-11 10:30:00', 82.88666666666667), (...  \n",
       "301  [('2024-02-14 07:25:00', 111.33), ('2024-02-14...  \n",
       "311  [('2024-03-05 12:05:00', 85.0), ('2024-03-05 1...  \n",
       "314  [('2024-03-08 07:10:00', 152.16), ('2024-03-08...  "
      ]
     },
     "execution_count": 1584,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Updating missing values with mean\n",
    "\n",
    "# Function to check if CGM Data is an empty array\n",
    "def is_cgm_data_empty(row):\n",
    "    try:\n",
    "        cgm_list = ast.literal_eval(row['CGM Data'])\n",
    "        return len(cgm_list) == 0\n",
    "    except:\n",
    "        return True\n",
    "\n",
    "# Function to filter out rows where CGM Data is empty\n",
    "cgm_train = cgm_train[~cgm_train.apply(is_cgm_data_empty, axis=1)]\n",
    "\n",
    "# 1. Get the HH:MM:SS breakfast and lunch times and calculate the mean for each subject ID\n",
    "cgm_train['Breakfast Time'] = pd.to_datetime(cgm_train['Breakfast Time'], errors='coerce')\n",
    "cgm_train['Lunch Time'] = pd.to_datetime(cgm_train['Lunch Time'], errors='coerce')\n",
    "\n",
    "def mean_time(times):\n",
    "    total_seconds = sum([t.hour * 3600 + t.minute * 60 + t.second for t in times if pd.notna(t)])\n",
    "    mean_seconds = total_seconds // len([t for t in times if pd.notna(t)])\n",
    "    return pd.to_datetime(mean_seconds, unit='s').time()\n",
    "\n",
    "mean_times = cgm_train.groupby('Subject ID')[['Breakfast Time', 'Lunch Time']].apply(\n",
    "    lambda group: pd.Series({\n",
    "        'Breakfast Time': mean_time(group['Breakfast Time']),\n",
    "        'Lunch Time': mean_time(group['Lunch Time'])\n",
    "    })\n",
    ")\n",
    "\n",
    "mean_times = mean_times.reset_index()\n",
    "\n",
    "# 2. Find the reference date for any row within the same subject:\n",
    "def get_reference_date(subject_id):\n",
    "    day_2_breakfast_index = cgm_train[(cgm_train['Subject ID'] == subject_id) & (cgm_train['Day'] == 2)]['Breakfast Time'].first_valid_index()\n",
    "    if day_2_breakfast_index is None or pd.isna(cgm_train.loc[day_2_breakfast_index, 'Breakfast Time']):\n",
    "        day_3_breakfast_index = cgm_train[(cgm_train['Subject ID'] == subject_id) & (cgm_train['Day'] == 4)]['Breakfast Time'].first_valid_index()\n",
    "        if day_3_breakfast_index is not None:\n",
    "            reference_date = cgm_train.loc[day_3_breakfast_index, 'Breakfast Time']\n",
    "            reference_day = 4\n",
    "        else:\n",
    "            reference_date = None\n",
    "            reference_day = None\n",
    "    else:\n",
    "        reference_date = cgm_train.loc[day_2_breakfast_index, 'Breakfast Time']\n",
    "        reference_day = 2\n",
    "    \n",
    "    return pd.Series([reference_date.date(), reference_day])\n",
    "\n",
    "\n",
    "mean_times[['Reference Date', 'Reference Day']] = mean_times['Subject ID'].apply(get_reference_date)\n",
    "\n",
    "# 3. Update missing_values_df\n",
    "def update_missing_breakfast_time(row, mean_times):\n",
    "    subject_id = row['Subject ID']\n",
    "    day = row['Day']\n",
    "    \n",
    "    mean_breakfast_time = mean_times.loc[mean_times['Subject ID'] == subject_id, 'Breakfast Time'].iloc[0]\n",
    "    mean_reference_date = mean_times.loc[mean_times['Subject ID'] == subject_id, 'Reference Date'].iloc[0]\n",
    "    reference_day = mean_times.loc[mean_times['Subject ID'] == subject_id, 'Reference Day'].iloc[0]\n",
    "    current_date = mean_reference_date + pd.Timedelta(days=(day - reference_day))\n",
    "    updated_breakfast_time = pd.to_datetime(current_date.strftime('%Y-%m-%d') + ' ' + mean_breakfast_time.strftime('%H:%M:%S'))\n",
    "    row['Breakfast Time'] = updated_breakfast_time\n",
    "    return row\n",
    "\n",
    "cgm_train = cgm_train.apply(\n",
    "    lambda row: update_missing_breakfast_time(row, mean_times) if pd.isna(row['Breakfast Time']) else row, axis=1\n",
    ")\n",
    "\n",
    "def update_missing_lunch_time(row, mean_times):\n",
    "    subject_id = row['Subject ID']\n",
    "    day = row['Day']\n",
    "    mean_lunch_time = mean_times.loc[mean_times['Subject ID'] == subject_id, 'Lunch Time'].iloc[0]\n",
    "    mean_reference_date = mean_times.loc[mean_times['Subject ID'] == subject_id, 'Reference Date'].iloc[0]\n",
    "    reference_day = mean_times.loc[mean_times['Subject ID'] == subject_id, 'Reference Day'].iloc[0]\n",
    "    current_date = mean_reference_date + pd.Timedelta(days=(day - reference_day))\n",
    "    updated_lunch_time = pd.to_datetime(current_date.strftime('%Y-%m-%d') + ' ' + mean_lunch_time.strftime('%H:%M:%S'))\n",
    "    row['Lunch Time'] = updated_lunch_time\n",
    "    return row\n",
    "\n",
    "cgm_train = cgm_train.apply(\n",
    "    lambda row: update_missing_lunch_time(row, mean_times) if pd.isna(row['Lunch Time']) else row, axis=1\n",
    ")\n",
    "\n",
    "cgm_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1585,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject ID</th>\n",
       "      <th>Day</th>\n",
       "      <th>Breakfast Time</th>\n",
       "      <th>Lunch Time</th>\n",
       "      <th>CGM Data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>2021-12-21 09:00:00</td>\n",
       "      <td>2021-12-21 12:45:00</td>\n",
       "      <td>[('2021-12-21 08:10:00', 124.58), ('2021-12-21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>2022-03-02 09:53:22</td>\n",
       "      <td>2022-03-02 14:55:00</td>\n",
       "      <td>[('2022-03-02 11:00:00', 139.04), ('2022-03-02...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>2022-03-12 08:03:52</td>\n",
       "      <td>2022-03-12 12:39:00</td>\n",
       "      <td>[('2022-03-12 12:40:00', 103.0), ('2022-03-12 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>2022-04-08 08:30:00</td>\n",
       "      <td>2022-04-08 12:48:00</td>\n",
       "      <td>[('2022-04-08 08:15:00', 131.58), ('2022-04-08...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>2022-04-02 09:26:00</td>\n",
       "      <td>2022-04-02 13:46:07</td>\n",
       "      <td>[('2022-04-02 09:20:00', 105.0), ('2022-04-02 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>2022-04-07 07:53:00</td>\n",
       "      <td>2022-04-07 12:43:37</td>\n",
       "      <td>[('2022-04-07 07:45:00', 110.23666666666666), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>2022-04-21 09:46:07</td>\n",
       "      <td>2022-04-21 14:05:00</td>\n",
       "      <td>[('2022-04-21 13:30:00', 117.0), ('2022-04-21 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>2022-08-08 09:49:10</td>\n",
       "      <td>2022-08-08 12:58:00</td>\n",
       "      <td>[('2022-08-08 12:45:00', 116.0), ('2022-08-08 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>28</td>\n",
       "      <td>9</td>\n",
       "      <td>2022-08-24 09:10:10</td>\n",
       "      <td>2022-08-24 13:04:01</td>\n",
       "      <td>[('2022-08-24 09:00:00', 143.28), ('2022-08-24...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>2022-09-29 06:14:06</td>\n",
       "      <td>2022-09-29 11:56:25</td>\n",
       "      <td>[('2022-09-29 05:45:00', 131.68), ('2022-09-29...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>29</td>\n",
       "      <td>8</td>\n",
       "      <td>2022-10-05 06:21:46</td>\n",
       "      <td>2022-10-05 11:56:21</td>\n",
       "      <td>[('2022-10-05 06:20:00', 106.77333333333333), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>2022-12-01 08:15:30</td>\n",
       "      <td>2022-12-01 14:05:45</td>\n",
       "      <td>[('2022-12-01 11:50:00', 140.8), ('2022-12-01 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>30</td>\n",
       "      <td>5</td>\n",
       "      <td>2022-12-04 08:15:30</td>\n",
       "      <td>2022-12-04 12:33:50</td>\n",
       "      <td>[('2022-12-04 12:00:00', 219.25), ('2022-12-04...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>32</td>\n",
       "      <td>6</td>\n",
       "      <td>2023-07-10 06:47:43</td>\n",
       "      <td>2023-07-10 13:09:37</td>\n",
       "      <td>[('2023-07-10 04:25:00', 108.62666666666667), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>32</td>\n",
       "      <td>7</td>\n",
       "      <td>2023-07-11 07:14:43</td>\n",
       "      <td>2023-07-11 13:20:52</td>\n",
       "      <td>[('2023-07-11 07:05:00', 119.94666666666667), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>32</td>\n",
       "      <td>9</td>\n",
       "      <td>2023-07-13 05:57:06</td>\n",
       "      <td>2023-07-13 13:20:52</td>\n",
       "      <td>[('2023-07-13 05:35:00', 92.12), ('2023-07-13 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>32</td>\n",
       "      <td>10</td>\n",
       "      <td>2023-07-14 06:47:43</td>\n",
       "      <td>2023-07-14 14:12:48</td>\n",
       "      <td>[('2023-07-14 05:15:00', 94.0), ('2023-07-14 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>2023-08-25 07:44:13</td>\n",
       "      <td>2023-08-25 12:49:44</td>\n",
       "      <td>[('2023-08-25 12:15:00', 169.54333333333332), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>35</td>\n",
       "      <td>6</td>\n",
       "      <td>2023-08-29 06:44:49</td>\n",
       "      <td>2023-08-29 13:16:52</td>\n",
       "      <td>[('2023-08-29 06:30:00', 175.36333333333334), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>35</td>\n",
       "      <td>9</td>\n",
       "      <td>2023-09-01 07:37:01</td>\n",
       "      <td>2023-09-01 13:16:52</td>\n",
       "      <td>[('2023-09-01 06:40:00', 189.81666666666666), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>36</td>\n",
       "      <td>2</td>\n",
       "      <td>2023-08-31 07:56:52</td>\n",
       "      <td>2023-08-31 12:14:53</td>\n",
       "      <td>[('2023-08-31 08:10:00', 126.27333333333333), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>36</td>\n",
       "      <td>3</td>\n",
       "      <td>2023-09-01 07:56:52</td>\n",
       "      <td>2023-09-01 11:59:45</td>\n",
       "      <td>[('2023-09-01 08:00:00', 180.55333333333334), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "      <td>2023-12-10 06:52:33</td>\n",
       "      <td>2023-12-10 12:00:25</td>\n",
       "      <td>[('2023-12-10 11:50:00', 108.04666666666667), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>41</td>\n",
       "      <td>9</td>\n",
       "      <td>2023-12-05 08:10:52</td>\n",
       "      <td>2023-12-05 12:06:21</td>\n",
       "      <td>[('2023-12-05 08:00:00', 145.0), ('2023-12-05 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>42</td>\n",
       "      <td>4</td>\n",
       "      <td>2023-12-02 10:10:02</td>\n",
       "      <td>2023-12-02 12:20:55</td>\n",
       "      <td>[('2023-12-02 08:30:00', 131.15), ('2023-12-02...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>42</td>\n",
       "      <td>6</td>\n",
       "      <td>2023-12-04 08:39:38</td>\n",
       "      <td>2023-12-04 12:20:55</td>\n",
       "      <td>[('2023-12-04 08:40:00', 127.05), ('2023-12-04...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>42</td>\n",
       "      <td>7</td>\n",
       "      <td>2023-12-05 10:02:09</td>\n",
       "      <td>2023-12-05 12:20:55</td>\n",
       "      <td>[('2023-12-05 08:45:00', 155.2), ('2023-12-05 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>42</td>\n",
       "      <td>9</td>\n",
       "      <td>2023-12-07 09:21:37</td>\n",
       "      <td>2023-12-07 13:11:17</td>\n",
       "      <td>[('2023-12-07 12:55:00', 129.25), ('2023-12-07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>42</td>\n",
       "      <td>10</td>\n",
       "      <td>2023-12-08 09:21:37</td>\n",
       "      <td>2023-12-08 12:20:55</td>\n",
       "      <td>[('2023-12-08 10:30:00', 117.95), ('2023-12-08...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>44</td>\n",
       "      <td>3</td>\n",
       "      <td>2024-01-05 08:34:21</td>\n",
       "      <td>2024-01-05 13:00:04</td>\n",
       "      <td>[('2024-01-05 09:00:00', 113.87707641196013), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>44</td>\n",
       "      <td>7</td>\n",
       "      <td>2024-01-09 08:34:21</td>\n",
       "      <td>2024-01-09 12:37:20</td>\n",
       "      <td>[('2024-01-09 06:25:00', 112.64), ('2024-01-09...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>45</td>\n",
       "      <td>3</td>\n",
       "      <td>2024-01-26 09:21:03</td>\n",
       "      <td>2024-01-26 12:49:27</td>\n",
       "      <td>[('2024-01-26 09:00:00', 130.74), ('2024-01-26...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>45</td>\n",
       "      <td>8</td>\n",
       "      <td>2024-01-31 09:21:56</td>\n",
       "      <td>2024-01-31 12:49:27</td>\n",
       "      <td>[('2024-01-31 09:10:00', 150.98666666666668), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>45</td>\n",
       "      <td>9</td>\n",
       "      <td>2024-02-01 10:03:19</td>\n",
       "      <td>2024-02-01 12:49:27</td>\n",
       "      <td>[('2024-02-01 09:45:00', 152.0), ('2024-02-01 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>45</td>\n",
       "      <td>10</td>\n",
       "      <td>2024-02-02 09:07:46</td>\n",
       "      <td>2024-02-02 12:49:27</td>\n",
       "      <td>[('2024-02-02 08:50:00', 146.0), ('2024-02-02 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>48</td>\n",
       "      <td>3</td>\n",
       "      <td>2024-02-11 09:14:49</td>\n",
       "      <td>2024-02-11 13:08:14</td>\n",
       "      <td>[('2024-02-11 10:30:00', 82.88666666666667), (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>48</td>\n",
       "      <td>6</td>\n",
       "      <td>2024-02-14 07:35:41</td>\n",
       "      <td>2024-02-14 13:08:14</td>\n",
       "      <td>[('2024-02-14 07:25:00', 111.33), ('2024-02-14...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>49</td>\n",
       "      <td>7</td>\n",
       "      <td>2024-03-05 07:39:42</td>\n",
       "      <td>2024-03-05 12:16:15</td>\n",
       "      <td>[('2024-03-05 12:05:00', 85.0), ('2024-03-05 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>49</td>\n",
       "      <td>10</td>\n",
       "      <td>2024-03-08 07:39:42</td>\n",
       "      <td>2024-03-08 13:10:28</td>\n",
       "      <td>[('2024-03-08 07:10:00', 152.16), ('2024-03-08...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Subject ID  Day      Breakfast Time          Lunch Time  \\\n",
       "52            8    9 2021-12-21 09:00:00 2021-12-21 12:45:00   \n",
       "88           12    9 2022-03-02 09:53:22 2022-03-02 14:55:00   \n",
       "97           13    9 2022-03-12 08:03:52 2022-03-12 12:39:00   \n",
       "107          14   10 2022-04-08 08:30:00 2022-04-08 12:48:00   \n",
       "110          15    4 2022-04-02 09:26:00 2022-04-02 13:46:07   \n",
       "121          16    6 2022-04-07 07:53:00 2022-04-07 12:43:37   \n",
       "139          19    6 2022-04-21 09:46:07 2022-04-21 14:05:00   \n",
       "172          26    3 2022-08-08 09:49:10 2022-08-08 12:58:00   \n",
       "187          28    9 2022-08-24 09:10:10 2022-08-24 13:04:01   \n",
       "189          29    2 2022-09-29 06:14:06 2022-09-29 11:56:25   \n",
       "195          29    8 2022-10-05 06:21:46 2022-10-05 11:56:21   \n",
       "198          30    2 2022-12-01 08:15:30 2022-12-01 14:05:45   \n",
       "201          30    5 2022-12-04 08:15:30 2022-12-04 12:33:50   \n",
       "220          32    6 2023-07-10 06:47:43 2023-07-10 13:09:37   \n",
       "221          32    7 2023-07-11 07:14:43 2023-07-11 13:20:52   \n",
       "223          32    9 2023-07-13 05:57:06 2023-07-13 13:20:52   \n",
       "224          32   10 2023-07-14 06:47:43 2023-07-14 14:12:48   \n",
       "234          35    2 2023-08-25 07:44:13 2023-08-25 12:49:44   \n",
       "238          35    6 2023-08-29 06:44:49 2023-08-29 13:16:52   \n",
       "241          35    9 2023-09-01 07:37:01 2023-09-01 13:16:52   \n",
       "243          36    2 2023-08-31 07:56:52 2023-08-31 12:14:53   \n",
       "244          36    3 2023-09-01 07:56:52 2023-09-01 11:59:45   \n",
       "252          38    2 2023-12-10 06:52:33 2023-12-10 12:00:25   \n",
       "268          41    9 2023-12-05 08:10:52 2023-12-05 12:06:21   \n",
       "272          42    4 2023-12-02 10:10:02 2023-12-02 12:20:55   \n",
       "274          42    6 2023-12-04 08:39:38 2023-12-04 12:20:55   \n",
       "275          42    7 2023-12-05 10:02:09 2023-12-05 12:20:55   \n",
       "277          42    9 2023-12-07 09:21:37 2023-12-07 13:11:17   \n",
       "278          42   10 2023-12-08 09:21:37 2023-12-08 12:20:55   \n",
       "280          44    3 2024-01-05 08:34:21 2024-01-05 13:00:04   \n",
       "284          44    7 2024-01-09 08:34:21 2024-01-09 12:37:20   \n",
       "289          45    3 2024-01-26 09:21:03 2024-01-26 12:49:27   \n",
       "294          45    8 2024-01-31 09:21:56 2024-01-31 12:49:27   \n",
       "295          45    9 2024-02-01 10:03:19 2024-02-01 12:49:27   \n",
       "296          45   10 2024-02-02 09:07:46 2024-02-02 12:49:27   \n",
       "298          48    3 2024-02-11 09:14:49 2024-02-11 13:08:14   \n",
       "301          48    6 2024-02-14 07:35:41 2024-02-14 13:08:14   \n",
       "311          49    7 2024-03-05 07:39:42 2024-03-05 12:16:15   \n",
       "314          49   10 2024-03-08 07:39:42 2024-03-08 13:10:28   \n",
       "\n",
       "                                              CGM Data  \n",
       "52   [('2021-12-21 08:10:00', 124.58), ('2021-12-21...  \n",
       "88   [('2022-03-02 11:00:00', 139.04), ('2022-03-02...  \n",
       "97   [('2022-03-12 12:40:00', 103.0), ('2022-03-12 ...  \n",
       "107  [('2022-04-08 08:15:00', 131.58), ('2022-04-08...  \n",
       "110  [('2022-04-02 09:20:00', 105.0), ('2022-04-02 ...  \n",
       "121  [('2022-04-07 07:45:00', 110.23666666666666), ...  \n",
       "139  [('2022-04-21 13:30:00', 117.0), ('2022-04-21 ...  \n",
       "172  [('2022-08-08 12:45:00', 116.0), ('2022-08-08 ...  \n",
       "187  [('2022-08-24 09:00:00', 143.28), ('2022-08-24...  \n",
       "189  [('2022-09-29 05:45:00', 131.68), ('2022-09-29...  \n",
       "195  [('2022-10-05 06:20:00', 106.77333333333333), ...  \n",
       "198  [('2022-12-01 11:50:00', 140.8), ('2022-12-01 ...  \n",
       "201  [('2022-12-04 12:00:00', 219.25), ('2022-12-04...  \n",
       "220  [('2023-07-10 04:25:00', 108.62666666666667), ...  \n",
       "221  [('2023-07-11 07:05:00', 119.94666666666667), ...  \n",
       "223  [('2023-07-13 05:35:00', 92.12), ('2023-07-13 ...  \n",
       "224  [('2023-07-14 05:15:00', 94.0), ('2023-07-14 0...  \n",
       "234  [('2023-08-25 12:15:00', 169.54333333333332), ...  \n",
       "238  [('2023-08-29 06:30:00', 175.36333333333334), ...  \n",
       "241  [('2023-09-01 06:40:00', 189.81666666666666), ...  \n",
       "243  [('2023-08-31 08:10:00', 126.27333333333333), ...  \n",
       "244  [('2023-09-01 08:00:00', 180.55333333333334), ...  \n",
       "252  [('2023-12-10 11:50:00', 108.04666666666667), ...  \n",
       "268  [('2023-12-05 08:00:00', 145.0), ('2023-12-05 ...  \n",
       "272  [('2023-12-02 08:30:00', 131.15), ('2023-12-02...  \n",
       "274  [('2023-12-04 08:40:00', 127.05), ('2023-12-04...  \n",
       "275  [('2023-12-05 08:45:00', 155.2), ('2023-12-05 ...  \n",
       "277  [('2023-12-07 12:55:00', 129.25), ('2023-12-07...  \n",
       "278  [('2023-12-08 10:30:00', 117.95), ('2023-12-08...  \n",
       "280  [('2024-01-05 09:00:00', 113.87707641196013), ...  \n",
       "284  [('2024-01-09 06:25:00', 112.64), ('2024-01-09...  \n",
       "289  [('2024-01-26 09:00:00', 130.74), ('2024-01-26...  \n",
       "294  [('2024-01-31 09:10:00', 150.98666666666668), ...  \n",
       "295  [('2024-02-01 09:45:00', 152.0), ('2024-02-01 ...  \n",
       "296  [('2024-02-02 08:50:00', 146.0), ('2024-02-02 ...  \n",
       "298  [('2024-02-11 10:30:00', 82.88666666666667), (...  \n",
       "301  [('2024-02-14 07:25:00', 111.33), ('2024-02-14...  \n",
       "311  [('2024-03-05 12:05:00', 85.0), ('2024-03-05 1...  \n",
       "314  [('2024-03-08 07:10:00', 152.16), ('2024-03-08...  "
      ]
     },
     "execution_count": 1585,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_values_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1586,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Function to check if CGM Data is an empty array\n",
    "# def is_cgm_data_empty(row):\n",
    "#     try:\n",
    "#         cgm_list = ast.literal_eval(row['CGM Data'])\n",
    "#         return len(cgm_list) == 0\n",
    "#     except:\n",
    "#         return True\n",
    "\n",
    "# # Function to filter out rows where CGM Data is empty\n",
    "# cgm_train = cgm_train[~cgm_train.apply(is_cgm_data_empty, axis=1)]\n",
    "\n",
    "# # Handle missing breakfast and lunch times\n",
    "# cgm_train['Breakfast Time'] = pd.to_datetime(cgm_train['Breakfast Time'], errors='coerce')\n",
    "# cgm_train['Lunch Time'] = pd.to_datetime(cgm_train['Lunch Time'], errors='coerce')\n",
    "\n",
    "# # Extract CGM data as list of tuples, convert to list of time series values\n",
    "# cgm_train['CGM Data'] = cgm_train['CGM Data'].apply(lambda x: eval(x) if isinstance(x, str) else [])\n",
    "\n",
    "# # Extract features from CGM data (flatten the time and glucose values)\n",
    "# def extract_cgm_features(cgm_data):\n",
    "#     times = [entry[0] for entry in cgm_data]\n",
    "#     glucose_levels = [entry[1] for entry in cgm_data]\n",
    "#     return times, glucose_levels\n",
    "\n",
    "# cgm_train['CGM Times'], cgm_train['CGM Levels'] = zip(*cgm_train['CGM Data'].apply(extract_cgm_features))\n",
    "\n",
    "# # Normalize glucose levels\n",
    "# scaler = StandardScaler()\n",
    "# cgm_train['CGM Levels'] = cgm_train['CGM Levels'].apply(lambda x: scaler.fit_transform(np.array(x).reshape(-1, 1)).flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rows with empty CGM data have been removed. TODO: Put in function to reuse for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1587,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # We need to pad the sequences to a fixed length for GRU input\n",
    "# max_sequence_length = 300  # Define a maximum length for the sequences\n",
    "# cgm_train['Padded CGM Levels'] = pad_sequences(cgm_train['CGM Levels'], maxlen=max_sequence_length, padding='post', value=0, dtype='float32').tolist()\n",
    "\n",
    "# # Mask labels: We will use NaN or a predefined mask value for missing times -- 1\n",
    "# cgm_train['Breakfast Time Masked'] = cgm_train['Breakfast Time'].isna().astype(int)\n",
    "# cgm_train['Lunch Time Masked'] = cgm_train['Lunch Time'].isna().astype(int)\n",
    "\n",
    "# # Prepare the target variable: encode the time values for breakfast and lunch\n",
    "# def encode_times(time_column):\n",
    "#     return (time_column - pd.Timestamp('2021-09-18')) // pd.Timedelta('1s')\n",
    "\n",
    "# # Filter rows where both Breakfast and Lunch times are missing (i.e., both masks are 0)\n",
    "# filtered_cgm_train = cgm_train[(cgm_train['Breakfast Time Masked'] == 0) & (cgm_train['Lunch Time Masked'] == 0)].copy()\n",
    "\n",
    "# # Encode breakfast and lunch times only for rows where both are missing\n",
    "# filtered_cgm_train['Breakfast Time Encoded'] = encode_times(filtered_cgm_train['Breakfast Time'])\n",
    "# filtered_cgm_train['Lunch Time Encoded'] = encode_times(filtered_cgm_train['Lunch Time'])\n",
    "\n",
    "# time_scaler = MinMaxScaler()\n",
    "\n",
    "# # Reshape and scale both 'Breakfast Time Encoded' and 'Lunch Time Encoded'\n",
    "# filtered_cgm_train[['Breakfast Time Encoded', 'Lunch Time Encoded']] = time_scaler.fit_transform(\n",
    "#     filtered_cgm_train[['Breakfast Time Encoded', 'Lunch Time Encoded']]\n",
    "# )\n",
    "\n",
    "# X_train = np.array(filtered_cgm_train['Padded CGM Levels'].tolist())\n",
    "# y_train = filtered_cgm_train[['Breakfast Time Encoded', 'Lunch Time Encoded']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1588,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Reshape X_train to (samples, time steps, features)\n",
    "# X_train_reshaped = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))  # (samples, time steps, features)\n",
    "\n",
    "# # Define the GRU model\n",
    "# def create_gru_model(input_shape):\n",
    "#     model = Sequential([\n",
    "#         Input(shape=input_shape),\n",
    "#         GRU(32, activation='relu'),\n",
    "#         Dense(2)  # Output two values: breakfast and lunch times\n",
    "#     ])\n",
    "#     model.compile(optimizer=Adam(learning_rate=0.001, clipvalue=1.0), loss='mse')\n",
    "#     return model\n",
    "\n",
    "# # Create and compile the model\n",
    "# model = create_gru_model((X_train_reshaped.shape[1], 1))\n",
    "\n",
    "# # Train the model\n",
    "# model.fit(X_train_reshaped, y_train, epochs=10, batch_size=32, validation_split=0.2, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1589,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def predict_meal_times(model, X):\n",
    "#     X = np.array(X.tolist()) if isinstance(X, pd.Series) else np.array(X)\n",
    "#     X_reshaped = X.reshape((X.shape[0], X.shape[1], 1))\n",
    "#     predictions = model.predict(X_reshaped)\n",
    "#     reference_date = pd.Timestamp('2021-09-18')\n",
    "\n",
    "#     # Decode predictions back to original scale using inverse transformation\n",
    "#     decoded_times = time_scaler.inverse_transform(predictions)\n",
    "\n",
    "#     # Add the decoded seconds back to the reference date\n",
    "#     decoded_breakfast_timestamps = reference_date + pd.to_timedelta(decoded_times[:, 0], unit='s')\n",
    "#     decoded_lunch_timestamps = reference_date + pd.to_timedelta(decoded_times[:, 1], unit='s')\n",
    "\n",
    "#     decoded_predictions = pd.DataFrame({\n",
    "#         'Predicted Breakfast Time': decoded_breakfast_timestamps,\n",
    "#         'Predicted Lunch Time': decoded_lunch_timestamps\n",
    "#     })\n",
    "\n",
    "#     return decoded_predictions\n",
    "\n",
    "# # Extract rows with missing breakfast or lunch times\n",
    "# missing_data = cgm_train[cgm_train['Breakfast Time'].isna() | cgm_train['Lunch Time'].isna()]\n",
    "\n",
    "# # Ensure that `Padded CGM Levels` is included in `missing_data`\n",
    "# predict_missing = missing_data['Padded CGM Levels']\n",
    "# missing_data_copy = missing_data.copy()\n",
    "\n",
    "# # Make predictions for missing breakfast and lunch times\n",
    "# predicted_times = predict_meal_times(model, predict_missing)\n",
    "\n",
    "# # Reset indices for both DataFrames to align by row order\n",
    "# missing_data_copy = missing_data_copy.reset_index(drop=True)\n",
    "# predicted_times = predicted_times.reset_index(drop=True)\n",
    "\n",
    "# # Add the 'Predicted Breakfast Time' column\n",
    "# missing_data_copy['Predicted Breakfast Time'] = predicted_times['Predicted Breakfast Time']\n",
    "# missing_data_copy['Predicted Lunch Time'] = predicted_times['Predicted Lunch Time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1590,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.savetxt('output.txt', y_breakfast_masked, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1591,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class GRUPredictor(nn.Module):\n",
    "#     def __init__(self, input_size, hidden_size, num_layers):\n",
    "#         super(GRUPredictor, self).__init__()\n",
    "#         self.hidden_size = hidden_size\n",
    "#         self.num_layers = num_layers\n",
    "#         self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n",
    "#         self.fc = nn.Linear(hidden_size, 1)\n",
    "    \n",
    "#     def forward(self, x):\n",
    "#         h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "#         out, _ = self.gru(x, h0)\n",
    "#         out = self.fc(out[:, -1, :])\n",
    "#         return out\n",
    "    \n",
    "# model = GRUPredictor(input_size=1, hidden_size=64, num_layers=2)\n",
    "# criterion = nn.MSELoss()\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# # Convert data to PyTorch tensors\n",
    "# X_tensor = torch.FloatTensor(X.reshape(-1, max_sequence_length, 1))\n",
    "# y_tensor = torch.FloatTensor(y_breakfast_masked_train)\n",
    "\n",
    "# # Train the model\n",
    "# num_epochs = 10\n",
    "# for epoch in range(num_epochs):\n",
    "#     outputs = model(X_tensor)\n",
    "#     loss = criterion(outputs, y_tensor)\n",
    "#     optimizer.zero_grad()\n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n",
    "#     print(f'Epoch: {epoch} Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1592,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import GRU, Dense, Masking\n",
    "\n",
    "# # Build the GRU model\n",
    "# model = Sequential()\n",
    "\n",
    "# # Masking layer to ignore padding during training\n",
    "# model.add(Masking(mask_value=0., input_shape=(max_sequence_length, 1)))\n",
    "\n",
    "# # GRU layers\n",
    "# model.add(GRU(128, return_sequences=False))\n",
    "# model.add(Dense(64, activation='relu'))\n",
    "\n",
    "# # Output layer for predicting breakfast and lunch times (regression problem)\n",
    "# model.add(Dense(1))\n",
    "\n",
    "# # Compile the model\n",
    "# model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# # Model summary\n",
    "# model.summary()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1593,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Prepare the data for training\n",
    "# X = np.expand_dims(X, axis=-1)  # Add a channel dimension for GRU input\n",
    "\n",
    "# # Split into training and validation sets\n",
    "# X_train, X_val, y_train, y_val = train_test_split(X, y_breakfast_masked, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Train the model\n",
    "# history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10, batch_size=32)\n",
    "\n",
    "# # Evaluate the model\n",
    "# loss = model.evaluate(X_val, y_val)\n",
    "# print(f'Validation Loss: {loss}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1594,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Predict missing breakfast times (masked values)\n",
    "# predicted_breakfast_times = model.predict(X_val)\n",
    "\n",
    "# predicted_breakfast_times\n",
    "\n",
    "# Convert the predicted time in seconds back to datetime format\n",
    "# predicted_breakfast_times = pd.to_datetime(predicted_breakfast_times, unit='s', origin='1970-01-01')\n",
    "\n",
    "# # You can use a similar approach for lunch time prediction\n",
    "# predicted_lunch_times = model.predict(X_val)\n",
    "# predicted_lunch_times = pd.to_datetime(predicted_lunch_times, unit='s', origin='1970-01-01')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1595,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "# from sklearn.impute import SimpleImputer\n",
    "\n",
    "# # Load dataset with proper delimiter (ensure '\\t' for tab-separated values)\n",
    "# file_path = 'demo_viome_train.csv'\n",
    "# data = pd.read_csv(file_path, delimiter='\\t')\n",
    "\n",
    "# # Recheck column parsing\n",
    "# if len(data.columns) == 1:\n",
    "#     # If all data is in a single column, try splitting with a comma\n",
    "#     data = pd.read_csv(file_path, delimiter=',')\n",
    "\n",
    "# # Verify column names\n",
    "# print(\"Columns in dataset after re-parsing:\", data.columns)\n",
    "\n",
    "# # Split the `Viome` column into individual features\n",
    "# viome_split = data['Viome'].str.split(',', expand=True).astype(float)\n",
    "# viome_split.columns = [f\"Viome_{i}\" for i in range(viome_split.shape[1])]\n",
    "\n",
    "# # Drop the original Viome column and merge new features\n",
    "# data = pd.concat([data.drop(columns=['Viome']), viome_split], axis=1)\n",
    "\n",
    "# # Impute missing values for numeric columns\n",
    "# numeric_cols = data.select_dtypes(include=[np.number]).columns\n",
    "# imputer = SimpleImputer(strategy='mean')\n",
    "# data[numeric_cols] = imputer.fit_transform(data[numeric_cols])\n",
    "\n",
    "# # Normalize numeric data\n",
    "# scaler = MinMaxScaler()\n",
    "# data[numeric_cols] = scaler.fit_transform(data[numeric_cols])\n",
    "\n",
    "\n",
    "# # Encode categorical columns\n",
    "# categorical_cols = ['Gender', 'Race', 'Diabetes Status']\n",
    "# encoder = OneHotEncoder(sparse_output=False, drop='first')  # Use sparse_output instead of sparse\n",
    "# encoded_cats = pd.DataFrame(\n",
    "#     encoder.fit_transform(data[categorical_cols]),\n",
    "#     columns=encoder.get_feature_names_out(categorical_cols)\n",
    "# )\n",
    "\n",
    "# # Drop original categorical columns and merge encoded ones\n",
    "# data = pd.concat([data.drop(columns=categorical_cols), encoded_cats], axis=1)\n",
    "\n",
    "# # Final processed data\n",
    "# print(\"Processed Data Shape:\", data.shape)\n",
    "# print(\"Processed Data Preview:\")\n",
    "# print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1596,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from PIL import Image\n",
    "\n",
    "# # Load the dataset\n",
    "# data = pd.read_csv(\"img_train.csv\")  # Adjust the file path as necessary\n",
    "\n",
    "# # Placeholder for missing images (a blank black image)\n",
    "# def create_placeholder_image(size=(64, 64, 3)):\n",
    "#     return np.zeros(size, dtype=np.float32)  # Normalized [0, 1] range\n",
    "\n",
    "# # Function to preprocess image data\n",
    "# def preprocess_image(img_data, size=(64, 64)):\n",
    "#     try:\n",
    "#         img_array = np.array(img_data, dtype=np.uint8)  # Ensure valid data type\n",
    "\n",
    "#         # Check for empty image\n",
    "#         if img_array.size == 0 or img_array.ndim != 3 or img_array.shape[2] != 3:\n",
    "#             raise ValueError(f\"Invalid or empty image dimensions: {img_array.shape}\")\n",
    "\n",
    "#         img_resized = np.array(Image.fromarray(img_array).resize(size))  # Resize\n",
    "#         img_normalized = img_resized / 255.0  # Normalize pixel values to [0, 1]\n",
    "#         return img_normalized\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error preprocessing image: {e}\")\n",
    "#         return create_placeholder_image(size)\n",
    "\n",
    "# # Preprocess the dataset\n",
    "# def preprocess_dataset(data):\n",
    "#     # Define placeholder image\n",
    "#     placeholder_image = create_placeholder_image()\n",
    "\n",
    "#     # Create missingness indicators\n",
    "#     data['Breakfast_Missing'] = data['Image Before Breakfast'].isnull().astype(int)\n",
    "#     data['Lunch_Missing'] = data['Image Before Lunch'].isnull().astype(int)\n",
    "\n",
    "#     # Iterate over rows to preprocess images\n",
    "#     breakfast_images = []\n",
    "#     lunch_images = []\n",
    "\n",
    "#     for index, row in data.iterrows():\n",
    "#         # Handle missing breakfast images\n",
    "#         if pd.isnull(row['Image Before Breakfast']) or row['Image Before Breakfast'] == '[]':  # Check for empty list or NaN\n",
    "#             breakfast_images.append(placeholder_image)\n",
    "#         else:\n",
    "#             try:\n",
    "#                 img_data = eval(row['Image Before Breakfast'])  # Convert string to list\n",
    "#                 breakfast_images.append(preprocess_image(img_data))\n",
    "#             except Exception as e:\n",
    "#                 print(f\"Error at index {index}, breakfast: {e}\")\n",
    "#                 breakfast_images.append(placeholder_image)\n",
    "\n",
    "#         # Handle missing lunch images\n",
    "#         if pd.isnull(row['Image Before Lunch']) or row['Image Before Lunch'] == '[]':  # Check for empty list or NaN\n",
    "#             lunch_images.append(placeholder_image)\n",
    "#         else:\n",
    "#             try:\n",
    "#                 img_data = eval(row['Image Before Lunch'])  # Convert string to list\n",
    "#                 lunch_images.append(preprocess_image(img_data))\n",
    "#             except Exception as e:\n",
    "#                 print(f\"Error at index {index}, lunch: {e}\")\n",
    "#                 lunch_images.append(placeholder_image)\n",
    "\n",
    "#     # Add preprocessed images back to the dataset\n",
    "#     data['Processed_Breakfast_Images'] = breakfast_images\n",
    "#     data['Processed_Lunch_Images'] = lunch_images\n",
    "\n",
    "#     return data\n",
    "\n",
    "# # Apply preprocessing\n",
    "# processed_data = preprocess_dataset(data)\n",
    "\n",
    "# # Save the processed dataset if needed\n",
    "# # processed_data.to_pickle(\"processed_img_train.pkl\")  # Save in pickle format for further use\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1597,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # Load the dataset\n",
    "# label_data = pd.read_csv(\"label_train.csv\")  # Adjust the file path as necessary\n",
    "\n",
    "# # Step 1: Extract Output Labels\n",
    "# output_labels = label_data[[\"Breakfast Calories\", \"Lunch Calories\"]]\n",
    "\n",
    "# # Step 2: Handle Missing Values in Labels\n",
    "# # Replace missing values (if any) with the median\n",
    "# output_labels = output_labels.fillna(output_labels.median())\n",
    "\n",
    "# print(output_labels)\n",
    "\n",
    "# # Step 3: Save the Extracted Labels\n",
    "# # output_labels.to_csv(\"output_labels.csv\", index=False)\n",
    "\n",
    "# print(\"Output Labels Extracted and Saved!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
